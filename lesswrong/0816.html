<html><head><title>Causal Reference</title></head><body><h1>Causal Reference</h1><p><i>Eliezer Yudkowsky, 20 October 2012 10:12PM</i></p><div><p><strong>Followup to:</strong>  <a href="0813.html">The Fabric of Real Things</a> [http://lesswrong.com/lw/eva/the_fabric_of_real_things/], <a href="0815.html">Stuff That Makes Stuff Happen</a> [http://lesswrong.com/lw/ezu/stuff_that_makes_stuff_happen/]</p> <p><em><a href="0813.html">Previous meditation</a> [http://lesswrong.com/lw/eva/the_fabric_of_real_things/#7lqi]:</em> "Does your rule forbid <a href="0309.html">epiphenomenalist theories of consciousness</a> [http://lesswrong.com/lw/p7/zombies_zombies/] that consciousness is caused by neurons, but doesn't affect those neurons in turn? The classic argument for epiphenomenal consciousness is that we can imagine a universe where people behave exactly the same way, but there's nobody home - no awareness, no consciousness, inside the brain. For all the atoms in this universe to be in the same place - for there to be no detectable difference <em>internally,</em> not just externally - 'consciousness' would have to be something created by the atoms in the brain, but which didn't affect those atoms in turn. It would be an effect of atoms, but not a cause of atoms. Now, I'm not so much interested in whether you think epiphenomenal theories of consciousness are true or false - rather, I want to know if you think they're impossible or meaningless <em>a priori</em> based on your rules."</p> <p>Is it coherent to imagine a universe in which a real entity can be an effect but not a cause?</p> <p>Well... there's a couple of senses in which it seems <em>imaginable. </em>It's important to remember that imagining things yields info primarily about what human brains can imagine. It only provides info about reality to the extent that we think imagination and reality are systematically correlated for some reason.</p> <p>That said, I can certainly write a computer program in which there's a tier of objects affecting each other, and a second tier - a lower tier - of epiphenomenal objects which are affected by them, but don't affect them. For example, I could write a program to simulate some balls that bounce off each other, and then some little shadows that follow the balls around.</p> <p>But then I only know about the shadows because I'm outside that whole universe, looking in. So <em>my mind</em> is being affected by both the balls and shadows - to observe something is to be affected by it. I know where the shadow is, because the shadow makes pixels be drawn on screen, which make my eye see pixels. If your universe has two tiers of causality - a tier with things that affect each other, and another tier of things that are affected by the first tier without affecting them - then could you know that fact from <em>inside</em> that universe?<a id="more"></a></p> <p>Again, this seems easy to <em>imagine</em> as long as objects in the second tier can affect <em>each other.</em> You'd just have to be living in the second tier! We can imagine, for example - this wasn't the way things worked out in <em>our</em> universe, but it might've seemed plausible to the ancient Greeks - that the stars in heaven (and the Sun as a special case) could affect <em>each other</em> and affect Earthly forces, but no Earthly force could affect them:</p> <p><img src="a20c4a4c.svg" alt="" height="160" width="216"></p> <p>(Here the X'd-arrow stands for 'cannot affect'.)</p> <p>The Sun's light would illuminate Earth, so it would cause plant growth. And sometimes you would see two stars crash into each other and explode, so you'd see they could affect each other. (And affect your brain, which was seeing them.) But the stars and Sun would be made out of a different substance, the 'heavenly material', and throwing any Earthly material at it would not cause it to change state in the slightest. The Earthly material might be burned up, but the Sun would occupy exactly the same position as before. It would affect us, but not be affected by us.</p> <p>(To clarify an important point raised in the comments: In standard causal diagrams and in standard physics, no two <em>individual events</em> ever affect <em>each other;</em> there's a causal arrow from the PAST to FUTURE but never an arrow from FUTURE to PAST. What we're talking about here is the sun and stars <em>over time,</em> and the <em>generalization over</em> causal arrows that point from Star-in-Past to Sun-in-Present and Sun-in-Present back to Star-in-Future. The standard formalism dealing with this would be Dynamic Bayesian Networks (DBNs) in which there are repeating nodes and repeating arrows for each successive timeframe: <strong>X</strong><sub>1</sub>, <strong>X</strong><sub>2</sub>, <strong>X</strong><sub>3</sub>, and causal laws F relating <strong>X</strong><sub>i</sub> to <strong>X</strong><sub>i+1</sub>. If the laws of physics did <em>not </em>repeat over time, it would be rather hard to learn about the universe! The Sun <em>repeatedly</em> sends out photons, and they obey the same laws each time they fall on Earth; rather than the F<sub>i</sub> being new transition tables each time, we see a constant F<sub>physics</sub> over and over. By saying that we live in a single-tier universe, we're observing that whenever there are F-arrows, causal-link-types, which (over repeating time) descend from variables-of-type-X to variables-of-type-Y (like present photons affecting future electrons), there are <em>also </em>arrows going back from Ys to Xs (like present electrons affecting future photons). If we <em>weren't </em>generalizing over time, it couldn't possibly make sense to speak of thingies that "affect each other" - causal diagrams don't allow directed cycles!)</p> <p>A two-tier causal universe seems easy to imagine, even easy to specify as a computer program. If you were arranging a Dynamic Bayes Net at random, would it <em>randomly </em>have everything in a single tier? If you were designing a causal universe at random, wouldn't there randomly be some things that appeared to us as causes but not effects? And yet our own physicists haven't discovered any upper-tier particles which can move us without being movable by us. There might be a hint here at what sort of thingies tend to be real in the first place - that, for whatever reasons, the Real Rules somehow mandate or suggest that all the causal forces in a universe be on the same level, capable of both affecting and being affected by each other.</p> <p>Still, we don't actually <em>know</em> the Real Rules are like that; and so it seems premature to assign <em>a priori</em> zero probability to hypotheses with multi-tiered causal universes. Discovering a class of upper-tier affect-only particles seems imaginable<a name="note1back"></a><a href="http://lesswrong.com/lw/f1u/causal_reference/#note1">[1]</a> [http://lesswrong.com/lw/f1u/causal_reference/#note1] - we can imagine which experiences would convince us that they existed. If we're in the Matrix, we can see how to program a Matrix like that. If there's some deeper reason why that's <em>impossible</em> in any base-level reality, we don't know it yet. So we probably want to call that a meaningful hypothesis for now.</p> <p>But what about lower-tier particles which can be affected by us, and yet never affect us?</p> <p><img src="5b624fb3.svg" alt="" height="160" width="264"></p> <p>Perhaps there are whole sentient Shadow Civilizations living on my nose hairs which can never <em>affect</em> those nose hairs, but find my nose hairs solid beneath their feet. (The solid Earth affecting them but not being affected, like the Sun's light affecting us in the 'heavenly material' hypothesis.) Perhaps I wreck their world every time I sneeze. It certainly seems imaginable - you could write a computer program simulating physics like that, given sufficient perverseness and computing power...</p> <p>And yet the fundamental question of rationality - "What do you think you know, and how do you think you know it?" - raises the question:</p> <p><em>How could you possibly know about the lower tier, even if it existed?</em></p> <p>To observe something is to be affected by it - to have your brain and beliefs take on different states, depending on that thing's state. How can you know about something that doesn't affect your brain?</p> <p>In fact there's an even deeper question, "How could you possibly <em>talk about</em> that lower tier of causality even if it existed?"</p> <p>Let's say you're a Lord of the Matrix. You write a computer program which first computes the physical universe as we know it (or a discrete approximation), and then you add a couple of lower-tier effects as follows:</p> <p>First, every time I sneeze, the binary variable YES_SNEEZE will be set to the second of its two possible values.</p> <p>Second, every time I sneeze, the binary variable NO_SNEEZE will be set to the first of its two possible values.</p> <p><img src="27caecc5.svg" alt="" height="291" width="427"></p> <p>Now let's say that - somehow - even though I've never caught any hint of the Matrix - I just <em>magically</em> think to myself one day, "What if there's a variable that watches when I sneeze, and gets set to 1?"</p> <p><img src="b70cb86a.jpg" alt="" height="313" width="300"></p> <p>It will be <a href="0809.html">all too easy</a> [http://lesswrong.com/lw/eqn/the_useful_idea_of_truth/] for me to imagine that this belief is meaningful and could be true or false:</p> <p><img src="e980e398.jpg" alt="" height="325" width="304"></p> <p>And yet in reality - as <em>you</em> know from outside the matrix - there are <em>two</em> shadow variables that get set when I sneeze. How can I talk about one of them, rather than the other? Why should my thought about '1' refer to their second possible value rather than their first possible value, inside the Matrix computer program? If we tried to establish a truth-value in this situation, to compare my <em>thought</em> to the reality inside the computer program - why compare my thought about SNEEZE_VAR to the variable YES_SNEEZE instead of NO_SNEEZE, or compare my thought '1' to the first possible value instead of the second possible value?</p> <p>Under more epistemically healthy circumstances, when you talk about things that are not directly sensory experiences, you will reference a causal model of the universe that you inducted to <em>explain </em>your sensory experiences. Let's say you repeatedly go outside at various times of day, and your eyes and skin directly experience BRIGHT-WARM, BRIGHT-WARM, BRIGHT-WARM, DARK-COOL, DARK-COOL, etc. To explain the patterns in your sensory experiences, you hypothesize a latent variable we'll call 'Sun', with some kind of state which can change between 1, which causes BRIGHTness and WARMness, and 0, which causes DARKness and COOLness. You believe that the state of the 'Sun' variable changes over time, but usually changes less frequently than you go outside.</p> <table cellpadding="5" border="0"> <tbody> <tr valign="middle"> <td><img src="0d83309a.jpg" alt="" height="350" width="435"></td> <td> <table border="1"> <tbody> <tr> <td>p(BRIGHT|Sun=1)</td> <td>0.9</td> </tr> <tr> <td>p(&#172;BRIGHT|Sun=1)</td> <td>0.1</td> </tr> <tr> <td>p(BRIGHT|Sun=0)</td> <td>0.1</td> </tr> <tr> <td>p(&#172;BRIGHT|Sun=0)</td> <td>0.9</td> </tr> </tbody> </table> </td> </tr> </tbody> </table> <p>Standing here <em>outside</em> the Matrix, we might be tempted to compare your <em>beliefs</em> about "Sun = 1", to the real universe's state regarding the visibility of the sun in the sky (or rather, the Earth's rotational position).</p> <p>But even if we compress the sun's visibility down to a binary categorization, how are we to know that your thought "Sun = 1" is meant to correspond to the sun being visible in the sky, rather than the sun being occluded by the Earth? Why the first state of the variable, rather than the second state?</p> <p>How indeed are we know that this thought "Sun = 1" is meant to compare to the sun at all, rather than an anteater in Venezuela?</p> <p>Well, because that 'Sun' thingy is supposed to be the <em>cause</em> of BRIGHT and WARM feelings, and if you trace back the cause of those sensory experiences <em>in reality</em> you'll arrive at the sun that the 'Sun' thought allegedly corresponds to. And to distinguish between whether the sun being visible in the sky is meant to correspond to 'Sun'=1 or 'Sun'=0, you check the conditional probabilities for that 'Sun'-state giving rise to BRIGHT - if the actual sun being visible has a 95% chance of causing the BRIGHT sensory feeling, then that true state of the sun is intended to correspond to the hypothetical 'Sun'=1, not 'Sun'=0.</p> <p>Or to put it more generally, in cases where we have...</p> <p><img src="4fe727b4.jpg" alt="" height="299" width="404"></p> <p>...then the correspondence between map and territory can at least <em>in principle</em> be point-wise evaluated by tracing causal links back from sensory experiences to reality, and tracing hypothetical causal links from sensory experiences back to hypothetical reality. We can't directly evaluate that truth-condition inside our own thoughts; but we can perform experiments and be corrected by them.</p> <p>Being able to <em>imagine</em> that your thoughts are meaningful and that a correspondence between map and territory is being maintained, is no guarantee that your thoughts are true. On the other hand, if you <em>can't even imagine within your own model </em>how a piece of your map could have a traceable correspondence to the territory, that is a very bad sign for the belief being meaningful, let alone true. Checking to see whether you can <em>imagine</em> a belief being meaningful is a test which will occasionally throw out bad beliefs, though it is no guarantee of a belief being good.</p> <hr> <p>Okay, but what about the idea that it should be meaningful to talk about whether or not a spaceship continues to exist after it travels over the cosmological horizon? Doesn't this theory of meaningfulness seem to claim that you can only sensibly imagine something that makes a difference to your sensory experiences?</p> <p>No. It says that you can only talk about events that your sensory experiences <em>pin down within the causal graph</em>. If you observe enough protons, electrons, neutrons, and so on, you can pin down the physical generalization which says, "Mass-energy is neither created nor destroyed; and in particular, particles don't vanish into nothingness without a trace." It is then an <em>effect</em> of that rule, combined with our previous observation of the ship itself, which tells us that there's a ship that went over the cosmological horizon and now we can't see it any more.</p> <p><img src="bf25251a.jpg" alt="" height="331" width="355"></p> <p>To navigate referentially to the fact that the ship continues to exist over the cosmological horizon, we navigate from our sensory experience <em>up to</em> the laws of physics, by talking about the <em>cause</em> of electrons not blinking out of existence; we also navigate <em>up to</em> the ship's existence by tracing back the cause of our observation of the ship being built. We can't <em>see</em> the future ship over the horizon - but the causal links <em>down</em> <em>from</em> the ship's construction, and from the laws of physics saying it doesn't disappear, are both <em>pinned down by observation</em> - there's no difficulty in figuring out which causes we're talking about, or what effects they have.<a name="note2back"></a><a href="http://lesswrong.com/lw/f1u/causal_reference/#note2">[2]</a> [http://lesswrong.com/lw/f1u/causal_reference/#note2]</p> <hr> <p>All righty-ighty, let's revisit that meditation:</p> <p>"Does your rule forbid <a href="0309.html">epiphenomenalist theories of consciousness</a> [http://lesswrong.com/lw/p7/zombies_zombies/] in which consciousness is caused by neurons, but doesn't affect those neurons in turn? The classic argument for epiphenomenal consciousness is that we can imagine a universe where people behave exactly the same way, but there's nobody home - no awareness, no consciousness, inside the brain. For all the atoms in this universe to be in the same place - for there to be no detectable difference <em>internally,</em> not just externally - 'consciousness' would have to be something created by the atoms in the brain, but which didn't affect those atoms in turn. It would be an effect of atoms, but not a cause of atoms. Now, I'm not so much interested in whether you think epiphenomenal theories of consciousness are true or false - rather, I want to know if you think they're impossible or meaningless <em>a priori</em> based on your rules."</p> <p>The closest theory to this which definitely <em>does</em> seem coherent - i.e., it's <em>imaginable</em> that it has a pinpointed meaning - would be if there was <em>another</em> little brain living inside my brain, made of shadow particles which could affect each other and be affected by my brain, but not affect my brain in turn. This brain would correctly hypothesize the reasons for its sensory experiences - that there was, from its perspective, an upper tier of particles interacting with each other that it couldn't affect. Upper-tier particles are observable, i.e., can affect lower-tier senses, so it would be possible to correctly induct a simplest explanation for them. And this inner brain would think, "I can imagine a Zombie Universe in which<em> I</em> am missing, but all the upper-tier particles go on interacting with each other as before." If we imagine that the upper-tier brain is just a robotic sort of agent, or a kitten, then the inner brain might justifiably imagine that the Zombie Universe would contain nobody to listen - no lower-tier brains to watch and be aware of events.</p> <p>We could write that computer program, given significantly more knowledge and vastly more computing power and zero ethics.</p> <p>But this inner brain composed of lower-tier shadow particles <em>cannot</em> write upper-tier philosophy papers about the Zombie universe. If the inner brain thinks, "I am aware of my own awareness", the upper-tier lips cannot move and say aloud, "I am aware of my own awareness" a few seconds later. That would require causal links from lower particles to upper particles.</p> <p>If we try to suppose that the lower tier isn't a complicated brain with an independent reasoning process that can imagine its own hypotheses, but just some shadowy pure experiences that don't affect anything in the upper tier, then clearly the <em>upper-tier brain</em> must be thinking meaningless gibberish when the <em>upper-tier lips</em> say, "I have a lower tier of shadowy pure experiences which did not affect in any way how I said these words." The deliberating upper brain that invents hypotheses for sense data, can only use sense data that affects the upper neurons carrying out the search for hypotheses that can be reported by the lips. Any shadowy pure experiences couldn't be inputs into the hypothesis-inventing cognitive process. So the upper brain would be talking nonsense.</p> <p>There's a version of this theory in which the part of our brain that we can report out loud, which invents hypotheses to explain sense data out loud and manifests physically visible papers about Zombie universes, <em>has for no explained reason</em> invented a meaningless theory of shadow experiences which is experienced <em>by the shadow part</em> as a meaningful and correct theory.  So that if we look at the "merely physical" slice of our universe, philosophy papers about consciousness are meaningless and the physical part of the philosopher is saying things their physical brain couldn't possibly know even if they were true.  And yet our inner experience of those philosophy papers is meaningful and true. In a way that couldn't possibly have caused me to physically write the previous sentence, mind you. And yet your experience of that sentence is also true even though, in the upper tier of the universe where that sentence was actually written, it is not only false but meaningless.</p> <p>I'm honestly not sure what to say when a conversation gets to that point. Mostly you just want to yell, "<a href="0325.html">Oh, for the love of Belldandy, will you just give up already?</a> [http://lesswrong.com/lw/pn/zombies_the_movie/]" or something about the <a href="0059.html">importance of saying oops</a> [http://lesswrong.com/lw/i9/the_importance_of_saying_oops/].</p> <p>(Oh, plus the unexplained correlation violates the <a href="0815.html">Markov condition for causal models</a> [http://lesswrong.com/lw/ezu/stuff_that_makes_stuff_happen/].)</p> <p>Maybe my reply would be something along the lines of, "Okay... look... I've given my account of a single-tier universe in which agents can invent meaningful explanations for sense data, and when they build accurate maps of reality there's a known reason for the correspondence... if you want to claim that a <em>different</em> kind of meaningfulness can hold within a <em>different</em> kind of agent divided into upper and lower tiers, it's up to <em>you</em> to explain what parts of the agent are doing which kinds of hypothesizing and how those hypotheses end up being meaningful and what causally explains their miraculous accuracy so that this all makes <em>sense</em>."</p> <p>But frankly, I think people would be wiser to just <em>give up </em>trying to write sensible philosophy papers about lower causal tiers of the universe that don't affect the philosophy papers in any way.</p> <hr> <p><strong><a href="http://lesswrong.com/lw/f1u/causal_reference/#7nyc">Meditation</a> [http://lesswrong.com/lw/f1u/causal_reference/#7nyc]: </strong>If we can only meaningfully talk about parts of the universe that can be pinned down inside the causal graph, where do we find the fact that 2 + 2 = 4? Or did I just make a meaningless noise, there? Or if you claim that "2 + 2 = 4" <em>isn't</em> meaningful or true, then what alternate property does the sentence "2 + 2 = 4" have which makes it so much more useful than the sentence "2 + 2 = 3"?</p> <hr> <p><strong><a href="http://lesswrong.com/lw/f1u/causal_reference/#7nyf">Mainstream status.</a> [http://lesswrong.com/lw/f1u/causal_reference/#7nyf]</strong></p> <hr> <p><a href="http://lesswrong.com/lw/f1u/causal_reference/#note1back"></a> [http://lesswrong.com/lw/f1u/causal_reference/#note1back]<a name="note1"></a> <a href="http://lesswrong.com/lw/f1u/causal_reference/#note1back">[1]</a> [http://lesswrong.com/lw/f1u/causal_reference/#note1back] Well, it seems imaginable so long as you toss most of quantum physics out the window and put us back in a classical universe. For particles to not be affected by us, they'd need their own configuration space such that "<a href="0317.html">which configurations are identical</a> [http://lesswrong.com/lw/pf/distinct_configurations/]" was determined by looking only at those particles, and not looking at any lower-tier particles entangled with them. If you <em>don't</em> want to toss QM out the window, it's actually pretty hard to imagine what an upper-tier particle would look like.</p> <p><a href="http://lesswrong.com/lw/f1u/causal_reference/#note2back"></a> [http://lesswrong.com/lw/f1u/causal_reference/#note2back]<a name="note2"></a> <a href="http://lesswrong.com/lw/f1u/causal_reference/#note2back">[2]</a> [http://lesswrong.com/lw/f1u/causal_reference/#note2back] This diagram treats the laws of physics as being just another node, which is a convenient shorthand, but probably not a good way to draw the graph. The laws of physics really correspond to the causal arrows F<sub>i</sub>, not the causal nodes X<sub>i</sub>. If you had the laws themselves - the function from past to future - be an X<sub>i</sub> of variable state, then you'd need meta-physics to describe the F<sub>physics</sub> arrows for how the physics-stuff X<sub>physics</sub> could affect us, followed promptly by a need for meta-meta-physics et cetera. If the laws of physics <em>were</em> a kind of causal stuff, they'd be an upper tier of causality - we can't appear to affect the laws of physics, but if you call them causes, they can affect us. In Matrix terms, this would correspond to our universe running on a computer that stored the laws of physics in one area of RAM and the state of the universe in another area of RAM, the first area would be an upper causal tier and the second area would be a lower causal tier. But the infinite regress from treating the laws of determination as causal stuff, makes me suspicious that it might be an error to treat the laws of physics as "stuff that makes stuff happen and happens because of other stuff". When we trust that the ship doesn't disappear when it goes over the horizon, we may not be navigating to a physics-node in the graph, so much as we're navigating to a single F<sub>physics</sub> that appears in many different places inside the graph, and whose previously unknown function we have inferred. But this is an unimportant technical quibble on Tuesdays, Thursdays, Saturdays, and Sundays. It is only an incredibly deep question about the nature of reality on Mondays, Wednesdays, and Fridays, i.e., less than half the time.</p> <p style="text-align:right">Part of the sequence <a href="http://wiki.lesswrong.com/wiki/Highly_Advanced_Epistemology_101_for_Beginners"><em>Highly Advanced Epistemology 101 for Beginners</em></a> [http://wiki.lesswrong.com/wiki/Highly_Advanced_Epistemology_101_for_Beginners]</p> <p style="text-align:right">Next post: "<a href="0817.html">Proofs, Implications, and Models</a> [http://lesswrong.com/lw/f43/proofs_implications_and_models/]"</p> <p style="text-align:right">Previous post: "<a href="0815.html">Stuff That Makes Stuff Happen</a> [http://lesswrong.com/lw/ezu/stuff_that_makes_stuff_happen/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq17.html">Sequence 17: Highly Advanced Epistemology 101 for Beginners</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0815.html">Stuff That Makes Stuff Happen</a></p></td><td><p><i>Next: </i><a href="0819.html">Causal Universes</a></p></td></tr></table><table><tr><th colspan="2"><a href="seq19.html">Sequence 19: Zombies</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0325.html">Zombies: The Movie</a></p></td><td><p><i>Next: </i><a href="seq20.html">Sequence 20: Evolution</a></p></td></tr></table><p><i>Referenced by: </i><a href="0815.html">Stuff That Makes Stuff Happen</a> &#8226; <a href="0817.html">Proofs, Implications, and Models</a> &#8226; <a href="0818.html">Logical Pinpointing</a> &#8226; <a href="0820.html">Mixed Reference: The Great Reductionist Project</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/f1u/causal_reference/">Causal Reference</a></p></body></html>