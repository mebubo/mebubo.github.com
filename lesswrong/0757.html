<html><head><title>Forcing Anthropics: Boltzmann Brains</title></head><body style="width: 600px; margin: 0 auto; font-family: Georgia, serif;"><h1>Forcing Anthropics: Boltzmann Brains</h1><p><i>Eliezer Yudkowsky, 07 September 2009 07:02PM</i></p><div><p><strong>Followup to</strong>:  <a href="http://lesswrong.com/lw/175/torture_vs_dust_vs_the_presumptuous_philosopher/">Anthropic Reasoning in UDT</a> [http://lesswrong.com/lw/175/torture_vs_dust_vs_the_presumptuous_philosopher/] by Wei Dai</p> <p>Suppose that I flip a logical coin - e.g. look at some binary digit of pi unknown to either of us - and depending on the result, either create a billion of you in green rooms and one of you in a red room if the coin came up 1; or, if the coin came up 0, create one of you in a green room and a billion of you in red rooms.  You go to sleep at the start of the experiment, and wake up in a red room.</p> <p>Do you reason that the coin very probably came up 0?  Thinking, perhaps:  "If the coin came up 1, there'd be a billion of me in green rooms and only one of me in a red room, and in that case, it'd be very <em>surprising</em> that I found myself in a red room."</p> <p>What is your degree of subjective credence - your posterior probability - that the logical coin came up 1?</p> <p>There are only two answers I can see that might in principle be coherent, and they are "50%" and "a billion to one against".</p> <p>Tomorrow I'll talk about what sort of trouble you run into if you reply "a billion to one".</p> <p>But for today, suppose you reply "50%".  Thinking, perhaps:  "I don't understand this whole <em>consciousness</em> rigamarole, I wouldn't try to program a computer to update on it, and I'm not going to update on it myself."</p> <p>In that case, why don't you believe you're a Boltzmann brain?<a id="more"></a></p> <p>Back when the laws of thermodynamics were being worked out, there was first asked the question:  "Why did the universe seem to start from a condition of low entropy?"  Boltzmann suggested that the larger universe <em>was</em> in a state of high entropy, but that, given a <em>long enough </em>time, regions of low entropy would spontaneously occur - wait long enough, and the egg will unscramble itself - and that our own universe was such a region.</p> <p>The problem with this explanation is now known as the "Boltzmann brain" problem; namely, while Hubble-region-sized low-entropy fluctuations will <em>occasionally</em> occur, it would be far more likely - though still not likely in any absolute sense - for a handful of particles to come together in a configuration performing a computation that lasted just long enough to think a single conscious thought (whatever that means) before dissolving back into chaos.  A random reverse-entropy fluctuation is exponentially vastly more likely to take place in a small region than a large one.</p> <p>So on Boltzmann's attempt to explain the low-entropy initial condition of the universe as a random statistical fluctuation, it's far more likely that we are a little blob of chaos temporarily hallucinating the <em>rest</em> of the universe, than that a multi-billion-light-year region spontaneously ordered itself.  And most such little blobs of chaos will dissolve in the next moment.</p> <p>"Well," you say, "that may be an <em>unpleasant </em>prediction, but that's no license to <em>reject </em>it."  But wait, it gets worse:  The vast majority of Boltzmann brains have experiences <em>much less ordered</em> than what you're seeing right now.  Even if a blob of chaos coughs up a visual cortex (or equivalent), that visual cortex is unlikely to see a highly ordered visual field - the vast majority of possible visual fields more closely resemble "static on a television screen" than "words on a computer screen".  So on the Boltzmann hypothesis, <em>highly ordered </em>experiences like the ones we are having now, constitute an exponentially infinitesimal fraction of all experiences.</p> <p>In contrast, suppose one more simple law of physics not presently understood, which forces the initial condition of the universe to be low-entropy.  Then the exponentially vast majority of brains occur as the result of ordered processes in ordered regions, and it's not at all surprising that we find ourselves having ordered experiences.</p> <p>But wait!  This is <em>just the same sort of logic </em>(is it?) that one would use to say, "Well, if the logical coin came up heads, then it's very surprising to find myself in a red room, since the vast majority of people-like-me are in green rooms; but if the logical coin came up tails, then most of me are in red rooms, and it's not surprising that I'm in a red room."</p> <p>If you reject that reasoning, saying, "There's only <em>one </em>me, and that person seeing a red room does exist, even if the logical coin came up heads" then you should have no trouble saying, "There's only one me, having a highly ordered experience, and that person exists even if all experiences are generated at random by a Boltzmann-brain process or something similar to it."  And furthermore, the Boltzmann-brain process is a much <em>simpler</em> process - it could occur with only the barest sort of causal structure, no need to postulate the full complexity of our own hallucinated universe.  So if you're not updating on the apparent conditional <em>rarity</em> of having a highly ordered experience of gravity, then you should just believe the very simple hypothesis of a high-volume random experience generator, which would necessarily create your current experiences - albeit with extreme relative infrequency, but you don't care about that.</p> <p>Now, doesn't the Boltzmann-brain hypothesis also predict that reality will dissolve into chaos in the next moment?  Well, it predicts that the <em>vast majority</em> of blobs who experience this moment, cease to exist after; and that among the few who <em>don't</em> dissolve, the vast majority of <em>those</em> experience chaotic successors.  But there would be an infinitesimal fraction of a fraction of successors, who experience ordered successor-states as well.  And you're not alarmed by the rarity of those successors, just as you're not alarmed by the rarity of waking up in a red room if the logical coin came up 1 - right?</p> <p>So even though your friend is standing right next to you, saying, "I predict the sky will <em>not</em> turn into green pumpkins and explode - oh, look, I was successful again!", you are not disturbed by their unbroken string of successes.  You just keep on saying, "Well, it was necessarily true that <em>someone</em> would have an ordered successor experience, on the Boltzmann-brain hypothesis, and that just <em>happens</em> to be us, but in the <em>next</em> instant I will sprout wings and fly away."</p> <p>Now this is not quite a <em>logical contradiction</em>.  But the total rejection of all science, induction, and inference in favor of an unrelinquishable faith that the next moment will dissolve into pure chaos, is sufficiently unpalatable that even I decline to bite that bullet.</p> <p>And so I still can't seem to dispense with anthropic reasoning - I can't seem to dispense with trying to think about <em>how many</em> of me or <em>how much</em> of me there are, which in turn requires that I think about what sort of process constitutes a <em>me</em>.  Even though I confess myself to be sorely confused, about what could possibly make a certain computation "real" or "not real", or how some universes and experiences could be quantitatively realer than others (possess more reality-fluid, as 'twere), and I still don't know what exactly makes a causal process count as something I might have been for purposes of being surprised to find myself as me, or for that matter, what exactly is a causal process.</p> <p>Indeed this is all greatly and terribly confusing unto me, and I would be less confused if I could go through life while only answering questions like "Given the Peano axioms, what is SS0 + SS0?"</p> <p>But then I have no defense against the one who says to me, "Why don't you think you're a Boltzmann brain?  Why don't you think you're the result of an all-possible-experiences generator?  Why don't you think that gravity is a matter of branching worlds in which all objects accelerate in all directions and in some worlds all the observed objects happen to be accelerating downward?  It <em>explains</em> all your observations, in the sense of logically necessitating them."</p> <p>I want to reply, "But then <em>most people</em> don't have experiences <em>this ordered,</em> so <em>finding myself </em>with an ordered experience is, on your hypothesis, very <em>surprising.</em>  Even if there are <em>some versions</em> of me that <em>exist</em> in regions or universes where they arose by chaotic chance, I <em>anticipate</em>, for purposes of predicting <em>my future experiences</em>, that <em>most of my existence</em> is <em>encoded </em>in regions and universes where I am the product of ordered processes."</p> <p>And I currently know of no way to reply thusly, that does not make use of poorly defined concepts like "number of real processes" or "amount of real processes"; and "people", and "me", and "anticipate" and "future experience".</p> <p>Of course confusion exists in the mind, not in reality, and it would not be the least bit surprising if a <em>resolution</em> of this problem were to dispense with such notions as "real" and "people" and "my future".  But I do not presently have that resolution.</p> <p>(Tomorrow I will argue that anthropic updates must be illegal and that the correct answer to the original problem must be "50%".)</p></div> <hr><p><i>Referenced by: </i><a href="0760.html">Outlawing Anthropics: An Updateless Dilemma</a> &#8226; <a href="0764.html">The Anthropic Trilemma</a> &#8226; <a href="0820.html">Mixed Reference: The Great Reductionist Project</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/17d/forcing_anthropics_boltzmann_brains/">Forcing Anthropics: Boltzmann Brains</a></p></body></html>