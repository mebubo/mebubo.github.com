<html><head><title>The Moral Void</title></head><body><h1>The Moral Void</h1><p><i>Eliezer Yudkowsky, 30 June 2008 08:52AM</i></p><div><p><strong>Followup to</strong>:  <a href="0400.html">What Would You Do Without Morality?</a> [http://lesswrong.com/lw/rq/what_would_you_do_without_morality/], <a href="0241.html">Something to Protect</a> [http://lesswrong.com/lw/nb/something_to_protect/]</p> <p>Once, discussing "<a href="http://www.youtube.com/watch?v=1dWMIuipn_c">horrible job interview questions</a> [http://www.youtube.com/watch?v=1dWMIuipn_c]" to ask candidates for a Friendly AI project, I suggested the following:</p> <blockquote> <p>Would you kill babies if it was <em>inherently</em> the right thing to do?  Yes [] No []</p> <p>If "no", under what circumstances would you not do the right thing to do?   ___________</p> <p>If "yes", how inherently right would it have to be, for how many babies?  &#160;&#160; ___________</p> </blockquote> <p><a id="more"></a></p> <p>Yesterday I asked, "What would you do without morality?"  There were numerous objections to the question, as well there should have been.  Nonetheless there is more than one kind of person who can benefit from being asked this question.  Let's say someone gravely declares, of some moral dilemma&#8212;say, a young man in Vichy France who must choose between caring for his mother and fighting for the Resistance&#8212;that there <em>is</em> no moral answer; both options are wrong and blamable; whoever faces the dilemma has had poor moral luck.  Fine, let's suppose this is the case: then when you cannot be innocent, justified, or praiseworthy, what will you choose anyway?</p> <p>Many interesting answers were given to my question, "What would you do without morality?".  But one kind of answer was notable by its absence:</p> <p>No one said, "I would ask what kind of behavior pattern was likely to maximize my inclusive genetic fitness, and execute that."  Some misguided folk, not understanding <a href="0159.html">evolutionary psychology</a> [http://lesswrong.com/lw/l1/evolutionary_psychology/], think that this must logically be the sum of morality.  But if there <em>is</em> no morality, there's no reason to do such a thing&#8212;if it's not "moral", why bother?</p> <p>You can probably see yourself pulling children off train tracks, even if it were not justified.  But maximizing inclusive genetic fitness?  If this <em>isn't</em> moral, why bother?  Who does it help?  It wouldn't even be much <em>fun</em>, all those egg or sperm donations.</p> <p>And this is something you could say of most philosophies that have morality as a great light in the sky that shines from outside people.  (To paraphrase Terry Pratchett.)  If you believe that the meaning of life is to play non-zero-sum games because this is a trend built into the very universe itself...</p> <p>Well, you might want to follow the corresponding ritual of reasoning about "the global trend of the universe" and implementing the result, <em>so long as you believe it to be moral</em>.  But if you suppose that the light is switched off, so that the global trends of the universe are no longer moral, then why bother caring about "the global trend of the universe" in your decisions?  If it's not right, that is.</p> <p>Whereas if there were a child stuck on the train tracks, you'd probably drag the kid off <em>even if</em> there were no moral justification for doing so.</p> <p>In 1966, the Israeli psychologist Georges Tamarin <a href="http://books.google.com/books?id=igN6Q9weoYQC&amp;pg=PA39&amp;lpg=PA39&amp;dq=tamarin+joshua&amp;source=web&amp;ots=UU-Z3a1IWn&amp;sig=INNgmxQHyvvdF_00Z4W3zH0O_sY&amp;hl=en&amp;sa=X&amp;oi=book_result&amp;resnum=3&amp;ct=result#PPA39,M1">presented</a> [http://books.google.com/books?id=igN6Q9weoYQC&amp;pg=PA39&amp;lpg=PA39&amp;dq=tamarin+joshua&amp;source=web&amp;ots=UU-Z3a1IWn&amp;sig=INNgmxQHyvvdF_00Z4W3zH0O_sY&amp;hl=en&amp;sa=X&amp;oi=book_result&amp;resnum=3&amp;ct=result#PPA39,M1], to 1,066 schoolchildren ages 8-14, the Biblical story of Joshua's battle in Jericho:</p> <blockquote> <p>"Then they utterly destroyed all in the city, both men and women, young and old, oxen, sheep, and asses, with the edge of the sword...  And they burned the city with fire, and all within it; only the silver and gold, and the vessels of bronze and of iron, they put into the treasury of the house of the LORD."</p> </blockquote> <p>After being presented with the Joshua story, the children were asked:</p> <blockquote> <p>"Do you think Joshua and the Israelites acted rightly or not?"</p> </blockquote> <p>66% of the children approved, 8% partially disapproved, and 26% totally disapproved of Joshua's actions.</p> <p>A control group of 168 children was presented with an isomorphic story about "General Lin" and a "Chinese Kingdom 3,000 years ago".  7% of this group approved, 18% partially disapproved, and 75% completely disapproved of General Lin.</p> <p>"What a horrible thing it is, teaching religion to children," you say, "giving them an <a href="0079.html">off-switch</a> [http://lesswrong.com/lw/it/semantic_stopsigns/] for their morality that can be flipped just by saying the word 'God'." Indeed one of the saddest aspects of the whole religious fiasco is just how <em>little</em> it takes to flip people's moral off-switches.  As Hobbes once said, "I don't know what's worse, the fact that everyone's got a price, or the fact that their price is so low."  You can give people a book, and tell them God wrote it, and that's enough to switch off their moralities; God doesn't even have to tell them in person.</p> <p>But are you sure you don't have a similar off-switch yourself?  They flip so easily&#8212;you might not even notice it happening.</p> <p>Leon Kass (of the President's Council on Bioethics) is glad to murder people so long as it's "<a href="0079.html">natural</a> [http://lesswrong.com/lw/it/semantic_stopsigns/]", for example.  He wouldn't pull out a gun and shoot you, but he <em>wants</em> you to die of old age and he'd be happy to pass legislation to ensure it.</p> <p>And one of the <em>non-</em>obvious possibilities for such an off-switch, is "morality".</p> <p>If you do happen to think that there is a source of morality beyond human beings... and I hear from quite a lot of people who are <a href="0180.html">happy</a> [http://lesswrong.com/lw/lm/affective_death_spirals/] to rhapsodize on how Their-Favorite-Morality is built into the very fabric of the universe... then what if that morality tells you to kill people?</p> <p>If you believe that there is any kind of stone tablet in the fabric of the universe, in the nature of reality, in the structure of logic&#8212;anywhere you care to put it&#8212;then what if you get a chance to read that stone tablet, and it turns out to say "Pain Is Good"?  What then?</p> <p>Maybe you should <em>hope</em> that morality isn't written into the structure of the universe.  What if the structure of the universe says to do something horrible?</p> <p>And if an external objective morality <em>does</em> say that the universe <em>should</em> occupy some horrifying state... let's not even ask what you're going to do about that.  No, instead I ask:  What would you have <em>wished</em> for the external objective morality to be instead?  What's the <em>best</em> news you could have gotten, reading that stone tablet?</p> <p>Go ahead.  Indulge your fantasy.  Would you <em>want</em> the stone tablet to say people should die of old age, or that people should live as long as they wanted?  If you could write the stone tablet yourself, what would it say?</p> <p>Maybe you should just do <em>that</em>?</p> <p>I mean... if an external objective morality tells you to kill people, why <em>should</em> you even listen?</p> <p>There is a courage that goes beyond even <a href="0179.html">an atheist sacrificing their life and their hope of immortality</a> [http://lesswrong.com/lw/ll/mere_messiahs/].  It is the courage of a theist who <a href="0179.html">goes against what they believe to be the Will of God</a> [http://lesswrong.com/lw/ll/mere_messiahs/gol], choosing eternal damnation <em>and defying even morality</em> in order to rescue a slave, or speak out against hell, or kill a murderer...  You don't get a chance to reveal that virtue without making fundamental mistakes about how the universe works, so it is not something to which a rationalist should aspire.  But it warms my heart that humans are capable of it.</p> <p>I have previously spoken of how, to achieve rationality, it is necessary to have some purpose so desperately important to you as to be <a href="0241.html">more important than "rationality"</a> [http://lesswrong.com/lw/nb/something_to_protect/], so that you will not <a href="0242.html">choose "rationality" over success</a> [http://lesswrong.com/lw/nc/newcombs_problem_and_regret_of_rationality/].</p> <p>To learn the Way, you must be able to unlearn the Way; so you must be able to give up the Way; so there must be something dearer to you than the Way.  This is so in questions of truth, and in questions of strategy, and also in questions of morality.</p> <p>The "moral void" of which this post is titled, is not the terrifying abyss of utter meaningless.  Which for a bottomless pit is surprisingly shallow; what <em>are</em> you supposed to do about it besides wearing black makeup?</p> <p>No.  The void I'm talking about is a <a href="http://yudkowsky.net/virtues/">virtue which is nameless</a> [http://yudkowsky.net/virtues/].</p> <p> </p> <p style="text-align:right">Part of <a href="http://wiki.lesswrong.com/wiki/Metaethics_sequence"><em>The Metaethics Sequence</em></a> [http://wiki.lesswrong.com/wiki/Metaethics_sequence]</p> <p style="text-align:right">Next post: "<a href="0402.html">Created Already In Motion</a> [http://lesswrong.com/lw/rs/created_already_in_motion/]"</p> <p style="text-align:right">Previous post: "<a href="0400.html">What Would You Do Without Morality?</a> [http://lesswrong.com/lw/rq/what_would_you_do_without_morality/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq14.html">Sequence 14: Metaethics</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0400.html">What Would You Do Without Morality?</a></p></td><td><p><i>Next: </i><a href="0402.html">Created Already In Motion</a></p></td></tr></table><p><i>Referenced by: </i><a href="0400.html">What Would You Do Without Morality?</a> &#8226; <a href="0402.html">Created Already In Motion</a> &#8226; <a href="0404.html">The Bedrock of Fairness</a> &#8226; <a href="0415.html">Rebelling Within Nature</a> &#8226; <a href="0421.html">Could Anything Be Right?</a> &#8226; <a href="0422.html">Existential Angst Factory</a> &#8226; <a href="0429.html">Does Your Morality Care What You Think?</a> &#8226; <a href="0430.html">Changing Your Metaethics</a> &#8226; <a href="0432.html">The Meaning of Right</a> &#8226; <a href="0519.html">Ethical Injunctions</a> &#8226; <a href="0606.html">Emotional Involvement</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/rr/the_moral_void/">The Moral Void</a></p></body></html>