<html><head><title>The Allais Paradox</title></head><body><h1>The Allais Paradox</h1><p><i>Eliezer Yudkowsky, 19 January 2008 03:05AM</i></p><div><p><strong>Followup to</strong>:  <a href="0215.html">But There's Still A Chance Right?</a> [http://lesswrong.com/lw/ml/but_theres_still_a_chance_right/], <a href="0223.html">Beautiful Probability</a> [http://lesswrong.com/lw/mt/beautiful_probability/]</p> <p>Choose between the following two options:</p><blockquote><p><strong>1A</strong>.  $24,000, with certainty.<br><strong>1B</strong>.  33/34 chance of winning $27,000, and 1/34 chance of winning nothing.</p></blockquote><p>Which seems more intuitively appealing?  And which one would you choose in real life?</p><a id="more"></a><p>Now which of these two options would you intuitively prefer, and which would you choose in real life?</p><blockquote><p><strong>2A</strong>. 34% chance of winning $24,000, and 66% chance of winning nothing.<br><strong>2B</strong>. 33% chance of winning $27,000, and 67% chance of winning nothing.</p></blockquote><p>The Allais Paradox - as Allais called it, though it's not really a paradox - was one of the first conflicts between decision theory and human reasoning to be experimentally exposed, in 1953.  I've <a href="http://en.wikipedia.org/wiki/Allais_paradox">modified it slightly</a> [http://en.wikipedia.org/wiki/Allais_paradox] for ease of math, but the essential problem is the same:  Most people prefer 1A &gt; 1B, and most people prefer 2B &gt; 2A.  Indeed, in within-subject comparisons, a majority of subjects express both preferences simultaneously.</p> <p>This is a problem because the 2s are equal to a one-third chance of playing the 1s.  That is, 2A is equivalent to playing gamble 1A with 34% probability, and 2B is equivalent to playing 1B with 34% probability.</p> <p>Among the axioms used to prove that "consistent" decisionmakers can be viewed as maximizing expected utility, is the <a href="http://cepa.newschool.edu/het/essays/uncert/vnmaxioms.htm">Axiom of Independence</a> [http://cepa.newschool.edu/het/essays/uncert/vnmaxioms.htm]:  If X is strictly preferred to Y, then a probability P of X and (1 - P) of Z should be strictly preferred to P chance of Y and (1 - P) chance of Z.</p> <p>All the axioms are consequences, as well as antecedents, of a consistent utility function.  So it must be possible to prove that the experimental subjects above <em>can't</em> have a consistent utility function over outcomes.  And indeed, you can't simultaneously have:</p> <ul><li>U($24,000)   &gt;   33/34 U($27,000) + 1/34 U($0)</li> <li>0.34 U($24,000) + 0.66 U($0)   &lt;   0.33 U($27,000) + 0.67 U($0)</li></ul> <p>These two equations are algebraically inconsistent, regardless of U, so the Allais Paradox has nothing to do with the diminishing marginal utility of money.</p> <p>Maurice Allais initially defended the revealed preferences of the experimental subjects - he saw the experiment as exposing a flaw in the conventional ideas of utility, rather than exposing a flaw in human psychology.  This was 1953, after all, and the heuristics-and-biases movement wouldn't really get started for another two decades.  Allais thought his experiment just showed that the Axiom of Independence clearly wasn't a good idea in real life.</p> <p>(<a href="0223.html">How naive, how foolish, how simplistic</a> [http://lesswrong.com/lw/mt/beautiful_probability/] is Bayesian decision theory...)</p> <p>Surely, the <em>certainty</em> of having $24,000 should count for <em>something.</em>  You can <em>feel</em> the difference, right?  The solid reassurance?</p> <p>(I'm starting to think of this as "naive philosophical realism" - supposing that our <a href="0124.html">intuitions directly expose truths</a> [http://lesswrong.com/lw/k2/a_priori/] about which strategies are wiser, as though it was a directly perceived fact that "1A is superior to 1B".  Intuitions <em>directly</em> expose truths about human cognitive functions, and only <em>indirectly</em> expose (after we <a href="0108.html">reflect on the cognitive functions</a> [http://lesswrong.com/lw/jm/the_lens_that_sees_its_flaws/] themselves) truths about rationality.)</p> <p>"But come now," you say, "is it really such a terrible thing, to depart from <a href="0223.html">Bayesian beauty</a> [http://lesswrong.com/lw/mt/beautiful_probability/]?"  Okay, so the subjects didn't follow the neat little "independence axiom" espoused by the likes of von Neumann and Morgenstern.  Yet who says that things <em>must</em> be neat and tidy?</p> <p>Why fret about elegance, if it makes us take risks we don't want?  <a href="0162.html">Expected utility</a> [http://lesswrong.com/lw/l4/terminal_values_and_instrumental_values/] tells us that we ought to assign some kind of number to an outcome, and then multiply that value by the outcome's probability, add them up, etc.  Okay, but why do we <em>have</em> to do that?  Why not make up more palatable rules instead?</p> <p>There is always a price for leaving the Bayesian Way.  That's what coherence and uniqueness theorems are all about.</p> <p>In this case, if an agent prefers 1A &gt; 1B, and 2B &gt; 2A, it introduces a form of <em>preference reversal -</em> a <em>dynamic inconsistency</em> in the agent's planning.  You become a <em>money pump.</em></p> <p>Suppose that at 12:00PM I roll a hundred-sided die.  If the die shows a number greater than 34, the game terminates.  Otherwise, at 12:05PM I consult a switch with two settings, A and B.  If the setting is A, I pay you $24,000.  If the setting is B, I roll a 34-sided die and pay you $27,000 unless the die shows "34", in which case I pay you nothing.</p> <p>Let's say you prefer 1A over 1B, and 2B over 2A, and you would pay a single penny to indulge each preference.  The switch starts in state A.  Before 12:00PM, you pay me a penny to throw the switch to B.  The die comes up 12.  After 12:00PM and before 12:05PM, you pay me a penny to throw the switch to A.</p> <p>I have taken your two cents on the subject.</p><p>If you indulge your intuitions, and dismiss mere elegance as a pointless obsession with neatness, then don't be surprised when your pennies get taken from you...</p> <p>(I think the same failure to <a href="0215.html">proportionally devalue the emotional impact of small probabilities</a> [http://lesswrong.com/lw/ml/but_theres_still_a_chance_right/] is responsible for the <a href="0036.html">lottery</a> [http://lesswrong.com/lw/hm/new_improved_lottery/].)<br></p> <hr> <p> Allais, M. (1953). Le comportement de l'homme rationnel devant le risque: Critique des postulats et axiomes de l'&#233;cole am&#233;ricaine.  <em>Econometrica,</em> <strong>21</strong>, 503-46.</p> <p> Kahneman, D. and Tversky, A. (1979.) Prospect Theory: An Analysis of Decision Under Risk. <em>Econometrica,</em> <strong>47</strong>, 263-92. </p></div> <hr><p><i>Referenced by: </i><a href="0229.html">Zut Allais!</a> &#8226; <a href="0231.html">Allais Malaise</a> &#8226; <a href="0232.html">Against Discount Rates</a> &#8226; <a href="0371.html">Timeless Identity</a> &#8226; <a href="0445.html">Moral Error and Moral Disagreement</a> &#8226; <a href="0599.html">Dunbar's Function</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/my/the_allais_paradox/">The Allais Paradox</a></p></body></html>