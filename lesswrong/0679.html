<html><head><title>What Do We Mean By "Rationality"?</title></head><body><h1>What Do We Mean By "Rationality"?</h1><p><i>Eliezer Yudkowsky, 16 March 2009 10:33PM</i></p><div><p>We mean:</p> <ol> <li><strong>Epistemic rationality</strong>: believing, and updating on evidence, so as to systematically improve the correspondence between <a href="http://yudkowsky.net/rational/the-simple-truth">your map and the territory</a> [http://yudkowsky.net/rational/the-simple-truth].  The art of obtaining beliefs that correspond to reality as closely as possible.  This correspondence is commonly termed "truth" or "accuracy", and we're happy to call it that.</li> <li><strong>Instrumental rationality</strong>: achieving your values.  <em>Not </em>necessarily "your values" in the sense of being <em>selfish </em>values or <em>unshared</em> values: "your values" means <em>anything you care about</em>.  The art of choosing actions that steer the future toward outcomes ranked higher in your preferences.  On LW we sometimes refer to this as "winning".</li> </ol> <p>If that seems like a perfectly good definition, you can stop reading here; otherwise continue.<a id="more"></a></p> <p>Sometimes experimental psychologists uncover human reasoning that seems very strange - <a href="0104.html">for example</a> [http://lesswrong.com/lw/ji/conjunction_fallacy/], someone rates the probability "Bill plays jazz" as <em>less</em> than the probability "Bill is an accountant who plays jazz".  This seems like an odd judgment, since any particular jazz-playing accountant is obviously a jazz player.  But to what higher vantage point do we appeal in saying that the judgment is <em>wrong?</em></p> <p>Experimental psychologists use two gold standards: <em>probability theory,</em> and <em>decision theory</em>.  Since it is a universal law of probability theory that P(A)&#160;&#8805; P(A &amp; B), the judgment P("Bill plays jazz") &lt; P("Bill plays jazz" &amp; "Bill is accountant") is labeled incorrect.</p> <p>To keep it technical, you would say that this probability judgment is <em>non-Bayesian.</em>  Beliefs that conform to a coherent probability distribution, and decisions that maximize the probabilistic expectation of a coherent utility function, are called "Bayesian".</p> <p>This does not quite exhaust the problem of what is meant in practice by "rationality", for two major reasons:</p> <p>First, the Bayesian formalisms in their full form are computationally intractable on most real-world problems.  No one can <em>actually</em> calculate and obey the math, any more than you can predict the stock market by calculating the movements of quarks.</p> <p>This is why we have a whole site called "Less Wrong", rather than simply stating the formal axioms and being done.  There's a whole further art to finding the truth and accomplishing value <em>from inside a human mind:</em> we have to learn our own flaws, overcome our biases, prevent ourselves from self-deceiving, get ourselves into good emotional shape to confront the truth and do what needs doing, etcetera etcetera and so on.</p> <p>Second, sometimes the meaning of the math itself is called into question.  The exact rules of probability theory are called into question by e.g. <a href="http://www.anthropic-principle.com/primer.html">anthropic problems</a> [http://www.anthropic-principle.com/primer.html] in which the number of observers is uncertain.  The exact rules of decision theory are called into question by e.g. <a href="0242.html">Newcomblike problems</a> [http://lesswrong.com/lw/nc/newcombs_problem_and_regret_of_rationality/] in which other agents may predict your decision before it happens.</p> <p>In cases like these, it is futile to try to settle the problem by coming up with some new definition of the word "rational", and saying, "Therefore my preferred answer, <em>by definition,</em> is what is meant by the word 'rational'."  This simply begs the question of why anyone should pay attention to your definition.  We aren't interested in probability theory because it is the holy word handed down from Laplace.  We're interested in Bayesian-style belief-updating (with Occam priors) because we expect that this style of thinking gets us systematically closer to, you know, <em>accuracy,</em> the map that reflects the territory.  (More on the futility of arguing "by definition" <a href="0245.html">here</a> [http://lesswrong.com/lw/nf/the_parable_of_hemlock/] and <a href="0265.html">here</a> [http://lesswrong.com/lw/nz/arguing_by_definition/].)</p> <p>And then there are questions of "How to think" that seem not quite answered by either probability theory or decision theory - like the question of <a href="0039.html">how to feel about the truth once we have it</a> [http://lesswrong.com/lw/hp/feeling_rational/].  Here again, trying to define "rationality" a particular way doesn't support an answer, merely presume it.</p> <p>From the <a href="http://yudkowsky.net/virtues/">Twelve Virtues of Rationality</a> [http://yudkowsky.net/virtues/]<em>:<br></em></p> <blockquote> <p style="padding-left: 30px;">How can you improve your conception of rationality?  Not by saying to yourself, &#8220;It is my duty to be rational.&#8221;&#160; By this you only enshrine your mistaken conception.  Perhaps your conception of rationality is that it is rational to believe the words of the Great Teacher, and the Great Teacher says, &#8220;The sky is green,&#8221; and you look up at the sky and see blue.  If you think:  &#8220;It may look like the sky is blue, but rationality is to believe the words of the Great Teacher,&#8221; you lose a chance to discover your mistake.</p> <p style="padding-left: 30px;">Do not ask whether it is &#8220;the Way&#8221; to do this or that.  Ask whether the sky is blue or green.  If you speak overmuch of the Way you will not attain it.</p> <p style="padding-left: 30px;">You may try to name the highest principle with names such as &#8220;the map that reflects the territory&#8221; or &#8220;experience of success and failure&#8221; or &#8220;Bayesian decision theory&#8221;.  But perhaps you describe incorrectly the nameless virtue.  How will you discover your mistake?  Not by comparing your description to itself, but by comparing it to that which you did not name.</p> </blockquote> <p>We are not here to argue <a href="0255.html">the meaning of a word</a> [http://lesswrong.com/lw/np/disputing_definitions/], not even if that word is "rationality".  The point of attaching sequences of letters to particular concepts is <a href="0257.html">to let two people <em>communicate</em></a> [http://lesswrong.com/lw/nr/the_argument_from_common_usage/] - to help transport thoughts from one mind to another.  You cannot change reality, or prove the thought, by manipulating which meanings go with which words.</p> <p>So if you understand what concept we are <em>generally getting at</em> with this word "rationality", and with the sub-terms "epistemic rationality" and "instrumental rationality", we <em>have communicated:</em> we have accomplished everything there is to accomplish by talking about how to define "rationality".  What's left to discuss is not <em>what meaning</em> to attach to the syllables "ra-tio-na-li-ty"; what's left to discuss is <em>what is a good way to think.</em></p> <p>With that said, you should be aware that many of us will regard as <em>controversial</em> - at the very least - any construal of "rationality" that makes it <em>non-normative:</em></p> <p>For example, if you say, "The rational belief is X, but the true belief is Y" then you are probably using the word "rational" in a way that means something other than what most of us have in mind.  (E.g. some of us expect "rationality" to be <em>consistent under reflection</em> - "rationally" looking at the evidence, and "rationally" considering how your mind processes the evidence, shouldn't lead to two different conclusions.)  Similarly, if you find yourself saying "The rational thing to do is X, but the right thing to do is Y" then you are almost certainly using one of the words "rational" or "right" in a way that a huge chunk of readers won't agree with.</p> <p>In this case - or in any other case where controversy threatens - you should <a href="0260.html">substitute more specific language</a> [http://lesswrong.com/lw/nu/taboo_your_words/]:  "The self-benefiting thing to do is to run away, but I hope I would at least try to drag the girl off the railroad tracks" or "Causal decision theory as usually formulated says you should two-box on <a href="0242.html">Newcomb's Problem</a> [http://lesswrong.com/lw/nc/newcombs_problem_and_regret_of_rationality/], but I'd rather have a million dollars."</p> <p>"X is rational!" is usually just a more strident way of saying "I think X is true" or "I think X is good".  So why have an additional word for "rational" as well as "true" and "good"?  Because we want to talk about <em>systematic methods </em>for obtaining truth and winning.</p> <p>The word "rational" has potential pitfalls, but there are plenty of <em>non</em>-borderline cases where "rational" works fine to <em>communicate</em> what one is getting at, likewise "irrational".  In these cases we're not afraid to use it.</p> <p>Yet one should also be careful not to <em>overuse</em> that word.  One receives no points merely for pronouncing it loudly.  If you speak overmuch of the Way you will not attain it.</p></div> <hr><table><tr><th colspan="2"><a href="seq01.html">Sequence 01: Map and Territory</a>:</th></tr><tr><td></td><td><p><i>Next: </i><a href="0002.html">Why truth? And...</a></p></td></tr></table><p><i>Referenced by: </i><a href="0680.html">Comments for "Rationality"</a> &#8226; <a href="0682.html">Why Our Kind Can't Cooperate</a> &#8226; <a href="0715.html">Of Gender and Rationality</a> &#8226; <a href="0747.html">Of Exclusionary Speech and Gender Politics</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/31/what_do_we_mean_by_rationality/">What Do We Mean By "Rationality"?</a></p></body></html>