<html><head><title>Hold Off On Proposing Solutions</title></head><body><h1>Hold Off On Proposing Solutions</h1><p><i>Eliezer Yudkowsky, 17 October 2007 03:16AM</i></p><div><p>From pp. 55-56 of Robyn Dawes's <em>Rational Choice in an Uncertain World.</em>  Bolding added.</p> <blockquote> <p>Norman R. F. Maier noted that when a group faces a problem, the natural tendency of its members is to propose possible solutions as they begin to discuss the problem.  Consequently, the group interaction focuses on the merits and problems of the proposed solutions, people become emotionally attached to the ones they have suggested, and superior solutions are not suggested.  Maier enacted an edict to enhance group problem solving: "<strong>Do not propose solutions until the problem has been discussed as thoroughly as possible without suggesting any.</strong>"  It is easy to show that this edict works in contexts where there are objectively defined good solutions to problems.</p> </blockquote> <p><a id="more"></a></p> <blockquote> <p>Maier devised the following "role playing" experiment to demonstrate his point.  Three employees of differing ability work on an assembly line.  They rotate among three jobs that require different levels of ability, because the most able&#8212;who is also the most dominant&#8212;is strongly motivated to avoid boredom.  In contrast, the least able worker, aware that he does not perform the more difficult jobs as well as the other two, has agreed to rotation because of the dominance of his able co-worker.  An "efficiency expert" notes that if the most able employee were given the most difficult task and the least able the least difficult, productivity could be improved by 20%, and the expert recommends that the employees stop rotating.  The three employees and the a fourth person designated to play the role of foreman are asked to discuss the expert's recommendation.  Some role-playing groups are given Maier's edict not to discuss solutions until having discussed the problem thoroughly, while others are not.  Those who are not given the edict immediately begin to argue about the importance of productivity versus worker autonomy and the avoidance of boredom.  Groups presented with the edict have a much higher probability of arriving at the solution that the two more able workers rotate, while the least able one sticks to the least demanding job&#8212;a solution that yields a 19% increase in productivity.</p> <p>I have often used this edict with groups I have led&#8212;<strong>particularly when they face a very tough problem, which is when group members are most apt to propose solutions immediately.</strong>  While I have no objective criterion on which to judge the quality of the problem solving of the groups, Maier's edict appears to foster better solutions to problems.</p> </blockquote> <p>This is so true it's not even funny.  And it gets worse and worse the tougher the problem becomes.  Take Artificial Intelligence, for example.  A surprising number of people I meet seem to know exactly how to build an Artificial General Intelligence, without, say, knowing how to build an optical character recognizer or a collaborative filtering system (much easier problems).  And as for building an AI with a positive impact on the world&#8212;a <a href="http://intelligence.org/AIRisk.pdf">Friendly AI</a> [http://intelligence.org/AIRisk.pdf], loosely speaking&#8212;why, <em>that</em> problem is so incredibly difficult that an actual <em>majority</em> resolve the whole issue within 15 seconds.  <em>Give</em> me a <em>break.</em></p> <p>(<strong>Added</strong>:  This problem is by no means unique to AI.  Physicists encounter plenty of nonphysicists with their own theories of physics, economists get to hear lots of amazing new theories of economics.  If you're an evolutionary biologist, anyone you meet can instantly solve any open problem in your field, usually by postulating group selection.  Et cetera.)</p> <p>Maier's advice echoes the principle of <a href="0114.html">the bottom line</a> [http://lesswrong.com/lw/js/the_bottom_line/], that the effectiveness of our decisions is determined only by whatever evidence and processing we did in first arriving at our decisions&#8212;after you write the bottom line, it is too late to <a href="0116.html">write more reasons</a> [http://lesswrong.com/lw/ju/rationalization/] above.  If you make your decision very early on, it will, in fact, be based on very little thought, no matter how many amazing arguments you come up with afterward.</p> <p>And consider furthermore that <a href="0119.html">We Change Our Minds Less Often Than We Think</a> [http://lesswrong.com/lw/jx/we_change_our_minds_less_often_than_we_think/]:  24 people assigned an average 66% probability to the future choice thought more probable, but only 1 in 24 actually chose the option thought less probable.  <strong>Once you can guess what your answer will be, you have probably already decided.</strong>  If you can guess your answer half a second after hearing the question, then you have half a second in which to be intelligent.  It's not a lot of time.</p> <p><a href="0123.html">Traditional Rationality</a> [http://lesswrong.com/lw/k1/no_one_can_exempt_you_from_rationalitys_laws/] emphasizes <em>falsification&#8212;</em> the ability to <em>relinquish</em> an initial opinion when confronted by clear evidence against it.  But once an idea gets into your head, it will probably require way too much evidence to get it out again.  Worse, we don't always have the luxury of overwhelming evidence.</p> <p>I suspect that a more powerful (and more difficult) method is to <em>hold off on thinking of an answer</em>.  To suspend, draw out, that tiny moment when we can't yet guess what our answer will be; thus giving our intelligence a longer time in which to act.</p> <p>Even half a minute would be an improvement over half a second.</p> <p> </p> <p style="text-align:right">Part of the <a href="http://wiki.lesswrong.com/wiki/Seeing_with_Fresh_Eyes"><em>Seeing With Fresh Eyes</em></a> [http://wiki.lesswrong.com/wiki/Seeing_with_Fresh_Eyes] subsequence of <a href="http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind"><em>How To Actually Change Your Mind</em></a> [http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind]</p> <p style="text-align:right">Next post: "<a href="0204.html">On Expressing Your Concerns</a> [http://lesswrong.com/lw/ma/on_expressing_your_concerns/]"</p> <p style="text-align:right">Previous post: "<a href="0119.html">We Change Our Minds Less Often Than We Think</a> [http://lesswrong.com/lw/jx/we_change_our_minds_less_often_than_we_think/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq05.html">Sequence 05: Seeing with Fresh Eyes</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0119.html">We Change Our Minds Less Often Than We Think</a></p></td><td><p><i>Next: </i><a href="0203.html">Asch's Conformity Experiment</a></p></td></tr></table><p><i>Referenced by: </i><a href="0119.html">We Change Our Minds Less Often Than We Think</a> &#8226; <a href="0144.html">Motivated Stopping and Motivated Continuation</a> &#8226; <a href="0146.html">A Case Study of Motivated Continuation</a> &#8226; <a href="0184.html">Fake Utility Functions</a> &#8226; <a href="0204.html">On Expressing Your Concerns</a> &#8226; <a href="0390.html">LA-602 vs. RHIC Review</a> &#8226; <a href="0436.html">A Genius for Destruction</a> &#8226; <a href="0481.html">My Best and Worst Mistake</a> &#8226; <a href="0503.html">My Bayesian Enlightenment</a> &#8226; <a href="0509.html">Crisis of Faith</a> &#8226; <a href="0538.html">Back Up and Ask Whether, Not Why</a> &#8226; <a href="0708.html">That Crisis thing seems pretty useful</a> &#8226; <a href="0754.html">Working Mantras</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/ka/hold_off_on_proposing_solutions/">Hold Off On Proposing Solutions</a></p></body></html>