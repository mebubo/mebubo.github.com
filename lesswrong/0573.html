<html><head><title>Is That Your True Rejection?</title></head><body style="width: 600px; margin: 0 auto; font-family: Georgia, serif;"><h1>Is That Your True Rejection?</h1><p><i>Eliezer Yudkowsky, 06 December 2008 02:26PM</i></p><div><p>It happens every now and then, that the one encounters some of my transhumanist-side beliefs&#8212;as opposed to my ideas having to do with human rationality&#8212;strange, exotic-sounding ideas like superintelligence and Friendly AI.  And the one rejects them.</p> <p>If the one is called upon to explain the rejection, not uncommonly the one says,</p> <p>"Why should I believe anything Yudkowsky says?  He doesn't have a PhD!"</p> <p>And occasionally someone else, hearing, says, "Oh, you should get a PhD, so that people will listen to you."  Or this advice may even be offered by the same one who disbelieved, saying, "Come back when you have a PhD."</p> <p>Now there are good and bad reasons to get a PhD, but this is one of the bad ones.</p> <p>There's many reasons why someone <em>actually</em> has an adverse reaction to transhumanist theses.  Most are matters of pattern recognition, rather than verbal thought: the thesis <a href="0077.html">matches</a> [http://lesswrong.com/lw/ir/science_as_attire/] against "strange weird idea" or "science fiction" or "end-of-the-world cult" or "overenthusiastic youth".</p> <p>So immediately, at the speed of perception, the idea is rejected.  If, afterward, someone says "Why not?", this lanches a search for justification.  But this search will not necessarily hit on the true reason&#8212;by "true reason" I mean not the <em>best</em> reason that could be offered, but rather, whichever causes were <a href="0114.html">decisive as a matter of historical fact</a> [http://lesswrong.com/lw/js/the_bottom_line/], <a href="0119.html">at the <em>very first</em> moment the rejection occurred</a> [http://lesswrong.com/lw/jx/we_change_our_minds_less_often_than_we_think/].</p> <p>Instead, the search for justification hits on the justifying-sounding fact, "This speaker does not have a PhD."</p> <p>But I also don't have a PhD when I talk about human rationality, so <a href="0207.html">why is the same objection not raised there</a> [http://lesswrong.com/lw/md/cultish_countercultishness/]?</p> <p>And more to the point, if I <em>had</em> a PhD, people would not treat this as a decisive factor indicating that they ought to believe everything I say.  Rather, the same initial rejection would occur, for the same reasons; and the search for justification, afterward, would terminate at a different stopping point.</p> <p>They would say, "Why should I believe <em>you?</em>  You're just some guy with a PhD! There are lots of those.  Come back when you're well-known in your field and tenured at a major university."</p> <p><a id="more"></a></p> <p>But do people <em>actually</em> believe arbitrary professors at Harvard who say weird things?  Of course not.  (But if I were a professor at Harvard, it would in fact be easier to get <em>media attention.</em>  Reporters initially disinclined to believe me&#8212;who would probably be equally disinclined to believe a random PhD-bearer&#8212;would still report on me, because it would be news that a Harvard professor believes such a weird thing.)</p> <p>If you are saying things that sound <em>wrong</em> to a novice, as opposed to just rattling off magical-sounding technobabble about leptical quark braids in N+2 dimensions; and the hearer is a stranger, unfamiliar with you personally <em>and</em> with the subject matter of your field; then I suspect that the point at which the average person will <em>actually</em> start to grant credence overriding their initial impression, purely <em>because</em> of academic credentials, is somewhere around the Nobel Laureate level.  If that.  Roughly, you need whatever level of academic credential qualifies as "beyond the mundane".</p> <p>This is more or less what happened to Eric Drexler, as far as I can tell.  He presented his vision of nanotechnology, and people said, "Where are the technical details?" or "Come back when you have a PhD!"  And Eric Drexler spent six years writing up technical details and got his PhD under Marvin Minsky for doing it.  And <em>Nanosystems</em> is a great book.  But did the same people who said, "Come back when you have a PhD", actually change their minds at all about molecular nanotechnology?  Not so far as I ever heard.</p> <p>It has similarly been a general rule with the Singularity Institute that, whatever it is we're supposed to do to be more credible, when we actually do it, nothing much changes.  "Do you do any sort of code development?  I'm not interested in supporting an organization that doesn't develop code"&#8212;&gt; OpenCog&#8212;&gt; nothing changes.  "Eliezer Yudkowsky lacks academic credentials"&#8212;&gt; Professor Ben Goertzel installed as Director of Research&#8212;&gt; nothing changes.  The one thing that actually <em>has</em> seemed to raise credibility, is famous people associating with the organization, like Peter Thiel funding us, or Ray Kurzweil on the Board.</p> <p>This might be an important thing for young businesses and new-minted consultants to keep in mind&#8212;that what your failed prospects <em>tell</em> you is the reason for rejection, may not make the <em>real</em> difference; and you should ponder that carefully before spending huge efforts.  If the venture capitalist says "If only your sales were growing a little faster!", if the potential customer says "It seems good, but you don't have feature X", that may not be the <em>true</em> rejection.  Fixing it may, or may not, change anything.</p> <p>And it would also be something to keep in mind during disagreements.  Robin and I share a belief that two rationalists should not <a href="http://www.overcomingbias.com/2006/12/agreeing_to_agr.html">agree to disagree</a> [http://www.overcomingbias.com/2006/12/agreeing_to_agr.html]: they should not have common knowledge of epistemic disagreement unless something is very wrong.</p> <p>I suspect that, in general, if two rationalists set out to resolve a disagreement that persisted past the first exchange, they should expect to find that the true sources of the disagreement are either hard to communicate, or hard to expose.  E.g:</p> <ul> <li>Uncommon, but well-supported, scientific knowledge or math;</li> <li>Long <a href="0138.html">inferential distances</a> [http://lesswrong.com/lw/kg/expecting_short_inferential_distances/];</li> <li>Hard-to-verbalize intuitions, perhaps stemming from specific visualizations;</li> <li>Zeitgeists inherited from a profession (that may have good reason for it);</li> <li>Patterns perceptually recognized from experience;</li> <li>Sheer habits of thought;</li> <li>Emotional commitments to believing in a particular outcome;</li> <li>Fear of a past mistake being disproven;</li> <li>Deep self-deception for the sake of pride or other personal benefits.</li> </ul> <p>If the matter were one in which <em>all</em> the true rejections could be <em>easily</em> laid on the table, the disagreement would probably be so straightforward to resolve that it would never have lasted past the first meeting.</p> <p>"Is this my true rejection?" is something that both disagreers should surely be asking <em>themselves,</em> to make things easier on the Other Fellow.  However, attempts to directly, publicly psychoanalyze the Other may cause the conversation to degenerate <em>very</em> fast, in my observation.</p> <p>Still&#8212;"Is that your true rejection?" should be fair game for Disagreers to humbly ask, if there's any productive way to pursue that sub-issue.  Maybe the rule could be that you can openly ask, "Is that simple straightforward-sounding reason your <em>true</em> rejection, or does it come from intuition-X or professional-zeitgeist-Y?"  While the more embarrassing possibilities lower on the table are left to the Other's conscience, as their own responsibility to handle.</p> <p><strong>Post scriptum:</strong></p> <p>This post is not <em>really</em> about PhDs in general, or their credibility value in particular.  But I've always figured that to the extent this was a strategically important consideration, it would make more sense to recruit an academic of existing high status, than spend a huge amount of time trying to achieve low or moderate academic status.</p> <p>However, if any professor out there wants to let me come in and <em>just</em> do a PhD in analytic philosophy&#8212;<em>just</em> write the thesis and defend it&#8212;then I have, for my own use, worked out a general and mathematically elegant theory of <a href="0242.html">Newcomblike decision problems</a> [http://lesswrong.com/lw/nc/newcombs_problem_and_regret_of_rationality/].  I think it would make a fine PhD thesis, and it is ready to be written&#8212;if anyone has the power to let me do things the old-fashioned way.</p> <p> </p> <p style="text-align:right">Part of the <a href="http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind#Against_Rationalization"><em>Against Rationalization</em></a> [http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind#Against_Rationalization] subsequence of <a href="http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind"><em>How To Actually Change Your Mind</em></a> [http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind]</p> <p style="text-align:right">Next post: "<a href="0514.html">Entangled Truths, Contagious Lies</a> [http://lesswrong.com/lw/uw/entangled_truths_contagious_lies/]"</p> <p style="text-align:right">Previous post: "<a href="0157.html">Fake Optimization Criteria</a> [http://lesswrong.com/lw/kz/fake_optimization_criteria/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq07.html">Sequence 07: Against Rationalization</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0157.html">Fake Optimization Criteria</a></p></td><td><p><i>Next: </i><a href="0514.html">Entangled Truths, Contagious Lies</a></p></td></tr></table><p><i>Referenced by: </i><a href="0157.html">Fake Optimization Criteria</a> &#8226; <a href="0514.html">Entangled Truths, Contagious Lies</a> &#8226; <a href="0575.html">True Sources of Disagreement</a> &#8226; <a href="0689.html">Your Price for Joining</a> &#8226; <a href="0787.html">Logical Rudeness</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/wj/is_that_your_true_rejection/">Is That Your True Rejection?</a></p></body></html>