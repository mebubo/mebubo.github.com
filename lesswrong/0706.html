<html><head><title>Mandatory Secret Identities</title></head><body style="width: 600px; margin: 0 auto; font-family: Georgia, serif;"><h1>Mandatory Secret Identities</h1><p><i>Eliezer Yudkowsky, 08 April 2009 06:10PM</i></p><div><p><strong>Previously in series</strong>:  <a href="0704.html">Whining-Based Communities</a> [http://lesswrong.com/lw/8t/whiningbased_communities/]</p> <blockquote> <p>"But there is a reason why many of my students have achieved great things; and by that I do not mean high rank in the Bayesian Conspiracy.  I expected much of them, and they came to expect much of themselves." &#8212;<a href="0367.html">Jeffreyssai</a> [http://lesswrong.com/lw/qt/class_project/]</p> </blockquote> <p>Among the <a href="0676.html">failure modes of martial arts dojos</a> [http://lesswrong.com/lw/2i/epistemic_viciousness/], I suspect, is that a sufficiently <em>dedicated </em>martial arts student, will dream of...</p> <p>...becoming a teacher and having their own martial arts dojo someday.</p> <p>To see what's wrong with this, imagine going to a class on literary criticism, falling in love with it, and dreaming of someday becoming a famous literary critic <em>just like your professor,</em> but <em>never actually writing anything.</em>  Writers tend to look down on literary critics' understanding of the art form itself, for just this reason.  (Orson Scott Card uses the analogy of a wine critic who listens to a wine-taster saying "This wine has a great bouquet", and goes off to tell their students "You've got to make sure your wine has a great bouquet".  When the student asks, "How?  Does it have anything to do with grapes?" the critic replies disdainfully, "That's for <em>grape-growers!</em>  I teach <em>wine.</em>")</p> <p>Similarly, I propose, no student of rationality should study with the purpose of becoming a rationality instructor in turn.  You do that on Sundays, or full-time after you retire.</p> <p>And to place a go stone blocking this failure mode, I propose a requirement that all rationality instructors must have secret identities.  They must have a life <em>outside</em> the Bayesian Conspiracy, which would be worthy of respect even if they were not rationality instructors.  And to enforce this, I suggest the rule:</p> <p style="padding-left: 30px;">  Rationality_Respect<sub>1</sub>(Instructor) = <em>min</em>(Rationality_Respect<sub>0</sub>(Instructor), Non_Rationality_Respect<sub>0</sub>(Instructor))</p> <p>That is, you can't respect someone <em>as </em>a rationality instructor, <em>more</em> than you would respect them if they were <em>not </em>rationality instructors.<a id="more"></a></p> <p>Some notes:</p> <p>&#8226; This doesn't set Rationality_Respect<sub>1</sub> <em>equal</em> to Non_Rationality_Respect<sub>0</sub>.  It establishes an <em>upper bound.</em>  This doesn't mean you can find random awesome people and expect them to be <a href="0664.html">able to teach you</a> [http://lesswrong.com/lw/m/unteachable_excellence/].  Explicit, abstract, cross-domain understanding of rationality and the ability to teach it to others <em>is</em>, unfortunately, an additional discipline on top of domain-specific life success.  Newton was a Christian etcetera.  I'd rather hear what Laplace had to say about rationality&#8212;Laplace wasn't as famous <em>as Newton</em>, but Laplace was a great mathematician, physicist, and astronomer in his own right, <em>and</em> he was the one said "I have no need of that hypothesis" (when Napoleon asked why Laplace's works on celestial mechanics did not mention God).  So I would respect Laplace as a rationality instructor well above Newton, by the <em>min</em>() function given above.</p> <p>&#8226; We should be generous about what counts as a secret identity <em>outside </em>the Bayesian Conspiracy.  If it's something that outsiders do in fact see as impressive, then it's "outside" regardless of how much Bayesian content is in the job.  An experimental psychologist who writes good papers on heuristics and biases, a successful trader who uses Bayesian algorithms, a well-selling author of a general-audiences popular book on atheism&#8212;all of these have worthy secret identities.  None of this contradicts the spirit of being <em>good at something besides rationality</em>&#8212;no, not even the last, because <em>writing books that sell </em>is a further difficult skill!  At the same time, you don't want to be too lax and start respecting the instructor's ability to put up probability-theory equations on the blackboard&#8212;it has to be visibly <em>outside</em> the walls of the dojo and nothing that could be systematized <em>within</em> the Conspiracy as a token requirement.</p> <p>&#8226; Apart from this, I shall not try to specify what exactly is worthy of respect.  A creative mind may have good reason to depart from any criterion I care to describe.  I'll just stick with the idea that "Nice rationality instructor" should be bounded above by "Nice secret identity".</p> <p>&#8226; <em>But </em>if the Bayesian Conspiracy is ever to populate itself with instructors, this criterion should not be too strict.  A simple test to see whether you live inside an elite bubble is to ask yourself whether the percentage of PhD-bearers in your apparent world exceeds the 0.25% rate at which they are found in the general population.  Being a math professor at a small university who has published a few original proofs, or a successful day trader who retired after five years to become an organic farmer, or a serial entrepreneur who lived through three failed startups before going back to a more ordinary job as a senior programmer&#8212;that's nothing to sneeze at.  The vast majority of people go through their whole lives without being that interesting.  Any of these three would have some tales to tell of real-world use, on Sundays at the small rationality dojo where they were instructors.  What I'm trying to say here is: don't demand that everyone be Robin Hanson in their secret identity, that is setting the bar too high.  Selective reporting makes it seem that fantastically high-achieving people have a far higher relative frequency than their real occurrence.  So if you ask for your rationality instructor to be <em>as interesting as the sort of people you read about in the newspapers</em>&#8212;and a master rationalist on top of that&#8212;and a good teacher on top of <em>that</em>&#8212;then you're going to have to join one of three famous dojos in New York, or something.  <em>But </em>you don't want to be too lax and start respecting things that others wouldn't respect if they weren't specially looking for reasons to praise the instructor.  "Having a good secret identity" should require <em>way</em> more effort than anything that could become a token requirement.</p> <p>Now I put to you:  If the instructors all have real-world anecdotes to tell of using their knowledge, and all of the students know that the desirable career path can't <em>just</em> be to become a rationality instructor, doesn't that sound healthier?</p> <p> </p> <p style="text-align:right">Part of the sequence <a href="0726.html"><em>The Craft and the Community</em></a> [http://lesswrong.com/lw/cz/the_craft_and_the_community/]</p> <p style="text-align:right">Next post: "<a href="0707.html">Beware of Other-Optimizing</a> [http://lesswrong.com/lw/9v/beware_of_otheroptimizing/]"</p> <p style="text-align:right">Previous post: "<a href="0704.html">Whining-Based Communities</a> [http://lesswrong.com/lw/8t/whiningbased_communities/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq16.html">Sequence 16: The Craft and the Community</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0704.html">Whining-Based Communities</a></p></td><td><p><i>Next: </i><a href="0707.html">Beware of Other-Optimizing</a></p></td></tr></table><p><i>Referenced by: </i><a href="0704.html">Whining-Based Communities</a> &#8226; <a href="0707.html">Beware of Other-Optimizing</a> &#8226; <a href="0713.html">Collective Apathy and the Internet</a> &#8226; <a href="0722.html">Go Forth and Create the Art!</a> &#8226; <a href="0726.html">The Craft and the Community</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/9c/mandatory_secret_identities/">Mandatory Secret Identities</a></p></body></html>