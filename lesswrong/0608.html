<html><head><title>Serious Stories</title></head><body><h1>Serious Stories</h1><p><i>Eliezer Yudkowsky, 08 January 2009 11:49PM</i></p><div><p><strong></strong>Every Utopia ever constructed&#8212;in philosophy, fiction, or religion&#8212;has been, to one degree or another, a place where you wouldn't <em>actually want</em> to live.  I am not alone in this <a href="0602.html">important</a> [http://lesswrong.com/lw/xc/the_uses_of_fun_theory/] observation:  George Orwell said much the same thing in "<a href="http://www.k-1.com/Orwell/site/work/essays/fun.html">Why Socialists Don't Believe In Fun</a> [http://www.k-1.com/Orwell/site/work/essays/fun.html]", and I expect that many others said it earlier.</p> <p>If you read books on How To Write&#8212;and there are a <em>lot</em> of books out there on How To Write, because amazingly a lot of book-writers think they know something about writing&#8212;these books will tell you that stories must contain "conflict".</p> <p>That is, the more <em>lukewarm </em>sort of instructional book will tell you that stories contain "conflict".  But some authors speak more plainly.</p> <p>"Stories are about people's pain."  Orson Scott Card.</p> <p>"Every scene must end in disaster."  Jack Bickham.</p> <p>In the age of my <a href="0480.html">youthful folly</a> [http://lesswrong.com/lw/ty/my_childhood_death_spiral/], I took for granted that <em>authors</em> were excused from the search for true Eutopia, because if you constructed a Utopia that <em>wasn't</em> flawed... what stories could you write, set there?  "Once upon a time they lived happily ever after."  What use would it be for a science-fiction author to try to depict a positive Singularity, when a positive Singularity would be...</p> <p>...the end of all stories?</p> <p>It seemed like a reasonable framework with which to examine the literary problem of Utopia, but something about that final conclusion produced a quiet, nagging doubt.</p> <p><a id="more"></a></p> <p>At that time I was thinking of an AI as being something like a safe wish-granting genie for the use of individuals.  So the conclusion did make a kind of sense.  If there was a problem, you would just wish it away, right?  Ergo&#8212;no stories.  So I ignored the quiet, nagging doubt.</p> <p>Much later, after I concluded that even a safe genie <a href="0586.html">wasn't such a good idea</a> [http://lesswrong.com/lw/ww/high_challenge/], it also seemed in retrospect that "no stories" could have been a productive indicator.  On this particular occasion, "I can't think of a single story I'd <em>want to read</em> about this scenario", might indeed have pointed me toward the reason "I wouldn't want to <em>actually live</em> in this scenario".</p> <p>So I swallowed my <a href="0190.html">trained-in revulsion</a> [http://lesswrong.com/lw/lw/reversed_stupidity_is_not_intelligence/] of <a href="0130.html">Luddism</a> [http://lesswrong.com/lw/k8/how_to_seem_and_be_deep/] and <a href="0502.html">theodicy</a> [http://lesswrong.com/lw/uk/beyond_the_reach_of_god/], and at least <em>tried </em>to contemplate the argument:</p> <ul> <li>A world in which nothing ever goes wrong, or no one ever experiences any pain or sorrow, is a world containing no stories worth reading about.</li> <li>A world that you wouldn't want to read about is a world where you wouldn't want to live.</li> <li>Into each eudaimonic life a little pain must fall.  QED.</li> </ul> <p>In one sense, it's clear that we do <em>not</em> want to live the sort of lives that are depicted in most stories that human authors have written so far.  Think of the truly great stories, the ones that have become legendary for being the very best of the best of their genre:  The <em>Iliiad, Romeo and Juliet, The Godfather, Watchmen, </em><em>Planescape: Torment</em>, the second season of <em>Buffy the Vampire Slayer</em>, or<em> that ending </em>in <em>Tsukihime</em>.  Is there a single story on the list that <em>isn't</em> tragic?</p> <p>Ordinarily, we prefer pleasure to pain, joy to sadness, and life to death.  Yet it seems we prefer to empathize with hurting, sad, dead characters.  Or stories about happier people <em>aren't serious, </em>aren't artistically great enough to be worthy of praise&#8212;but then why selectively praise stories containing unhappy people?  Is there some hidden benefit to us in it?  It's a puzzle either way you look at it.</p> <p>When I was a child I couldn't write fiction because I wrote things to go <em>well</em> for my characters&#8212;just like I wanted things to go well in real life.  Which I was cured of by Orson Scott Card:  <em>Oh,</em> I said to myself, <em>that's what I've been doing wrong, my characters aren't hurting</em>.  Even then, I didn't realize that the microstructure of a plot works the same way&#8212;until Jack Bickham said that every scene must end in disaster.  Here I'd been trying to set up problems and <em>resolve</em> them, instead of making them <em>worse...</em></p> <p>You simply don't <em>optimize </em>a story the way you optimize a real life.  The <em>best </em>story and the <em>best </em>life will be produced by different criteria.</p> <p>In the real world, people can go on living for quite a while without any major disasters, and still seem to do pretty okay.  When was the last time you were shot at by assassins?  Quite a while, right?  Does your life seem emptier for it?</p> <p>But on the other hand...</p> <p>For some odd reason, when authors get too old or too successful, they revert to my childhood.  Their stories start going <em>right.</em>  They stop doing horrible things to their characters, with the result that they start doing horrible things to their readers.  It seems to be a regular part of Elder Author Syndrome.  Mercedes Lackey, Laurell K. Hamilton, Robert Heinlein, even Orson Scott bloody Card&#8212;they all went that way.  They forgot how to hurt their characters.  I don't know why.</p> <p>And when you read a story by an Elder Author or a pure novice&#8212;a story where things just <em>relentlessly go right</em> one after another&#8212;where the main character defeats the supervillain with a snap of the fingers, or even worse, before the final battle, the supervillain <em>gives up and apologizes and then they're friends again&#8212;</em></p> <p>It's like a fingernail scraping on a blackboard at the base of your spine.  If you've never actually read a story like that (or worse, written one) then count yourself lucky.</p> <p>That fingernail-scraping quality&#8212;would it transfer over from the story to real life, if you tried living real life without a single drop of rain?</p> <p>One answer might be that what a story really needs is not "disaster", or "pain", or even "conflict", but simply <em>striving.</em>  That the problem with Mary Sue stories is that there's not enough <a href="0586.html">striving</a> [http://lesswrong.com/lw/ww/high_challenge/] in them, but they wouldn't actually need <em>pain</em>.  This might, perhaps, be tested.</p> <p>An alternative answer might be that this <em>is</em> the transhumanist version of Fun Theory we're talking about.  So we can reply, "Modify brains to eliminate that fingernail-scraping feeling", unless there's some justification for keeping it.  If the fingernail-scraping feeling is a pointless random bug getting in the way of Utopia, delete it.</p> <p>Maybe we <em>should</em>.  Maybe all the Great Stories are tragedies because... well...</p> <p>I once read that in the BDSM community, "intense sensation" is a euphemism for pain.  Upon reading this, it occurred to me that, the way humans are constructed now, it is just <em>easier </em>to produce pain than pleasure.  Though I speak here somewhat outside my experience, I expect that it takes a highly talented and experienced sexual artist working for hours to produce a <em>good </em>feeling as intense as the pain of one strong kick in the testicles&#8212;which is doable in seconds by a novice.</p> <p>Investigating the life of the priest and proto-rationalist <a href="0068.html">Friedrich Spee von Langenfeld</a> [http://lesswrong.com/lw/ii/conservation_of_expected_evidence/], who heard the confessions of accused witches, I looked up some of the instruments that had been used to produce confessions.  There is no ordinary way to make a human being feel as <em>good </em>as those instruments would make you hurt.  I'm not sure even drugs would do it, though my experience of drugs is as nonexistent as my experience of torture.</p> <p>There's something imbalanced about that.</p> <p>Yes, human beings are too optimistic in their planning.  If losses weren't more aversive than gains, we'd go broke, the way we're constructed now.  The experimental rule is that losing a desideratum&#8212;$50, a coffee mug, whatever&#8212;hurts between 2 and 2.5 times as much as the equivalent gain.</p> <p>But this is a deeper imbalance than that.  The effort-in/intensity-out difference between sex and torture is not a mere factor of 2.</p> <p>If someone goes in search of sensation&#8212;in this world, the way human beings are constructed now&#8212;it's not surprising that they should arrive at pains to be mixed into their pleasures as a source of <em>intensity</em> in the combined experience.</p> <p>If only people were constructed differently, so that you could produce pleasure as intense and in <a href="0588.html">as many different flavors</a> [http://lesswrong.com/lw/wy/sensual_experience/] as pain!  If only you could, with the same ingenuity and effort as a torturer of the Inquisition, make someone feel as <em>good</em> as the Inquisition's victims felt <em>bad</em>&#8212;</p> <p>But then, what <em>is</em> the analogous pleasure that feels that good?  A victim of skillful torture will do anything to stop the pain and anything to prevent it from being repeated.  Is the equivalent pleasure one that overrides everything with the demand to continue and repeat it?  If people are stronger-willed to bear the pleasure, is it really the same pleasure?</p> <p>There is another rule of writing which states that stories have to <em>shout</em>.  A human brain is a long way off those printed letters.  Every event and feeling needs to take place at ten times natural volume in order to have any impact at all.  You must not try to make your characters behave or feel <em>realistically </em>&#8212;especially, you must not faithfully reproduce your own past experiences&#8212;because <em>without exaggeration</em>, they'll be too quiet to rise from the page.</p> <p>Maybe all the Great Stories are tragedies because happiness can't shout loud enough&#8212;to a human reader.</p> <p>Maybe that's what needs fixing.</p> <p>And if it were fixed... would there be any use left for pain or sorrow?  For even the <em>memory </em>of sadness, if all things were already as good as they could be, and every remediable ill already remedied?</p> <p><em>Can</em> you just delete pain outright?  Or does removing the old floor of the utility function just create a new floor?  Will any pleasure less than 10,000,000 hedons be the new unbearable pain?</p> <p>Humans, built the way we are now, do seem to have hedonic scaling tendencies.  Someone who can remember starving will appreciate a loaf of bread more than someone who's never known anything but cake.  This was <a href="http://www.k-1.com/Orwell/site/work/essays/fun.html">George Orwell's hypothesis for why Utopia is impossible</a> [http://www.k-1.com/Orwell/site/work/essays/fun.html] in literature and reality:</p> <p style="margin-left: 40px;">"It would seem that human beings are not able to describe, nor perhaps to imagine, happiness except in terms of contrast...  The inability of mankind to imagine happiness except in the form of relief, either from effort or pain, presents Socialists with a serious problem. Dickens can describe a poverty-stricken family tucking into a roast goose, and can make them appear happy; on the other hand, the inhabitants of perfect universes seem to have no spontaneous gaiety and are usually somewhat repulsive into the bargain."</p> <p>For an expected utility maximizer, rescaling the utility function to add a trillion to all outcomes is meaningless&#8212;it's literally the same utility function, as a mathematical object.  A utility function describes the <em>relative </em>intervals between outcomes; that's what it is, mathematically speaking.</p> <p>But the human brain has distinct neural circuits for positive feedback and negative feedback, and different varieties of positive and negative feedback.  There are people today who "suffer" from congenital analgesia&#8212;a total absence of pain.  I never heard that <em>insufficient pleasure</em> becomes intolerable to them.</p> <p>Congenital analgesics do have to inspect themselves carefully and frequently to see if they've cut themselves or burned a finger.  Pain serves a purpose in the human mind design...</p> <p>But that does not show there's <a href="0044.html">no alternative</a> [http://lesswrong.com/lw/hu/the_third_alternative/] which could serve the same purpose.  Could you delete pain and replace it <em>with an urge not to do certain things</em> that lacked the intolerable subjective quality of pain?  I do not know all the Law that governs here, but I'd have to guess that yes, you could; you could replace that side of yourself with something more akin to an expected utility maximizer.</p> <p>Could you delete the human tendency to scale pleasures&#8212;delete the accomodation, so that each new roast goose is as delightful as the last?  I would guess that you could.  This verges perilously close to deleting Boredom, which is right up there with Sympathy as an absolute indispensable... but to say that an old solution remains as pleasurable, is not to say that you will lose the urge to seek new and better solutions.</p> <p>Can you make every roast goose as pleasurable as it would be in contrast to starvation, without ever having starved?</p> <p>Can you prevent the pain of a dust speck irritating your eye from being the new torture, if you've literally <em>never experienced</em> anything <em>worse</em> than a dust speck irritating your eye?</p> <p>Such questions begin to exceed my grasp of the Law, but I would guess that the answer is: yes, it can be done.  It is my experience in such matters that once you do learn the Law, you can usually see how to do weird-seeming things.</p> <p>So far as I know or can guess, David Pearce (<em>The Hedonistic Imperative</em>) is very probably right about the <em>feasibility</em> part, when he says:</p> <p style="margin-left: 40px;">"Nanotechnology and genetic engineering will abolish suffering in all sentient life.  The abolitionist project is hugely ambitious but technically feasible.  It is also instrumentally rational and morally urgent.  The metabolic pathways of pain and malaise evolved because they served the fitness of our genes in the ancestral environment.  They will be replaced by a different sort of neural architecture&#8212;a motivational system based on heritable gradients of bliss.  States of sublime well-being are destined to become the genetically pre-programmed norm of mental health.  It is predicted that the world's last unpleasant experience will be a precisely dateable event."</p> <p>Is that... what we <em>want?</em></p> <p>To just wipe away the last tear, and be done?</p> <p>Is there any good reason <em>not </em>to, except status quo bias and a handful of worn rationalizations?</p> <p>What would be the <em>alternative?  </em>Or alternatives?</p> <p>To leave things as they are?  Of course not.  <a href="0502.html">No God designed this world</a> [http://lesswrong.com/lw/uk/beyond_the_reach_of_god/]; we have no reason to think it exactly optimal on any dimension.  If this world does not contain too much pain, then it must not contain enough, and the latter seems unlikely.</p> <p>But perhaps...</p> <p>You could cut out just the <em>intolerable </em>parts of pain?</p> <p>Get rid of the Inquisition.  Keep the sort of pain that tells you not to stick your finger in the fire, or the pain that tells you that you shouldn't have put your friend's finger in the fire, or even the pain of breaking up with a lover.</p> <p>Try to get rid of the sort of pain that <em>grinds down and destroys</em> a mind.  Or configure minds to be harder to damage.</p> <p>You could have a world where there were broken legs, or even broken hearts, but no broken <em>people</em>.  No child sexual abuse that turns out more abusers.  No people ground down by weariness and drudging minor inconvenience to the point where they contemplate suicide.  No random meaningless endless sorrows like starvation or AIDS.</p> <p>And if even a broken leg still seems too scary&#8212;</p> <p>Would we be less frightened of pain, if we were stronger, if our daily lives did not already exhaust so much of our reserves?</p> <p>So that would be one alternative to the Pearce's world&#8212;if there are yet other alternatives, I haven't thought them through in any detail.</p> <p>The path of courage, you might call it&#8212;the idea being that if you eliminate the destroying kind of pain and strengthen the people, then what's left shouldn't be <em>that</em> scary.</p> <p>A world where there is sorrow, but not massive systematic <em>pointless </em>sorrow, like we see on the evening news.  A world where pain, if it is not eliminated, at least does not <em>overbalance pleasure</em>.  You could write stories about that world, and they could read our stories.</p> <p>I do tend to be rather conservative around the notion of deleting large parts of human nature.  I'm not sure how many major chunks you can delete until that balanced, conflicting, dynamic structure collapses into something simpler, like an expected pleasure maximizer.</p> <p>And so I do admit that it is the path of courage that appeals to me.</p> <p>Then again, I haven't lived it both ways.</p> <p>Maybe I'm just <em>afraid</em> of a world so different as Analgesia&#8212;wouldn't that be an ironic reason to walk "the path of courage"?</p> <p>Maybe the path of courage just seems like the <em>smaller change</em>&#8212;maybe I just have trouble empathizing over a larger gap.</p> <p>But "change" is a moving target.</p> <p>If a human child grew up in a <em>less</em> painful world&#8212;if they had never lived in a world of AIDS or cancer or slavery, and so did not know these things as evils that had <em>been triumphantly eliminated</em>&#8212;and so did not feel that they were "already done" or that the world was "already changed enough"...</p> <p>Would they take the next step, and try to eliminate the unbearable pain of broken hearts, when someone's lover stops loving them?</p> <p>And then what?  Is there a point where <em>Romeo and Juliet</em> just seems less and less relevant, more and more a relic of some distant forgotten world?  Does there come some point in the transhuman journey where the whole business of the negative reinforcement circuitry, can't possibly seem like anything except a pointless hangover to wake up from?</p> <p>And if so, is there any point in <em>delaying </em>that last step?  Or should we just throw away our fears and... throw away our fears?</p> <p>I don't know.</p> <p> </p> <p style="text-align:right">Part of <a href="0624.html"><em>The Fun Theory Sequence</em></a> [http://lesswrong.com/lw/xy/the_fun_theory_sequence/]</p> <p style="text-align:right">Next post: "<a href="0611.html">Eutopia is Scary</a> [http://lesswrong.com/lw/xl/eutopia_is_scary/]"</p> <p style="text-align:right">Previous post: "<a href="0606.html">Emotional Involvement</a> [http://lesswrong.com/lw/xg/emotional_involvement/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq15.html">Sequence 15: Fun Theory</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0606.html">Emotional Involvement</a></p></td><td><p><i>Next: </i><a href="0611.html">Eutopia is Scary</a></p></td></tr></table><p><i>Referenced by: </i><a href="0606.html">Emotional Involvement</a> &#8226; <a href="0610.html">Continuous Improvement</a> &#8226; <a href="0611.html">Eutopia is Scary</a> &#8226; <a href="0624.html">The Fun Theory Sequence</a> &#8226; <a href="0626.html">31 Laws of Fun</a> &#8226; <a href="0641.html">(Moral) Truth in Fiction?</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/xi/serious_stories/">Serious Stories</a></p></body></html>