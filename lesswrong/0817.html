<html><head><title>Proofs, Implications, and Models</title></head><body style="width: 600px; margin: 0 auto; font-family: Georgia, serif;"><h1>Proofs, Implications, and Models</h1><p><i>Eliezer Yudkowsky, 30 October 2012 01:02PM</i></p><div><p><strong>Followup to</strong>: <a href="0816.html">Causal Reference</a> [http://lesswrong.com/lw/f1u/causal_reference/]</p> <p>From a <a href="http://mathbabe.org/2012/07/11/mathematicians-know-how-to-admit-theyre-wrong/">math professor's blog</a> [http://mathbabe.org/2012/07/11/mathematicians-know-how-to-admit-theyre-wrong/]:</p> <p style="padding-left: 30px; ">One thing I discussed with my students here at HCSSiM yesterday is the question of what is a proof.</p> <p style="padding-left: 30px; ">They&#8217;re smart kids, but completely new to proofs, and they often have questions about whether what they&#8217;ve written down constitutes a proof. Here&#8217;s what I said to them.</p> <p style="padding-left: 30px; ">A proof is a social construct &#8211; it is what we need it to be in order to be convinced something is true. If you write something down and you want it to count as a proof, the only real issue is whether you&#8217;re completely convincing.</p> <p>This is not quite the definition I would give of what constitutes "proof" in mathematics - perhaps because I am so used to isolating arguments that are convincing, but ought not to be.</p> <p>Or here again, from "<a href="http://math.ucsd.edu/~sbuss/ResearchWeb/handbookI/ChapterI.pdf">An Introduction to Proof Theory</a> [http://math.ucsd.edu/~sbuss/ResearchWeb/handbookI/ChapterI.pdf]" by Samuel R. Buss:</p> <p style="padding-left: 30px; ">There are two distinct viewpoints of what a mathematical proof is. The first view is that proofs are social conventions by which mathematicians convince one another of the truth of theorems. That is to say, a proof is expressed in natural language plus possibly symbols and figures, and is sufficient to convince an expert of the correctness of a theorem. Examples of social proofs include the kinds of proofs that are presented in conversations or published in articles. Of course, it is impossible to precisely define what constitutes a valid proof in this social sense; and, the standards for valid proofs may vary with the audience and over time. The second view of proofs is more narrow in scope: in this view, a proof consists of a string of symbols which satisfy some precisely stated set of rules and which prove a theorem, which itself must also be expressed as a string of symbols. According to this view, mathematics can be regarded as a 'game' played with strings of symbols according to some precisely defined rules. Proofs of the latter kind are called "formal" proofs to distinguish them from "social" proofs.</p> <p>In modern mathematics there is a much better answer that could be given to a student who asks, "What exactly is a proof?", which does not match <em>either</em> of the above ideas. So:</p> <p><a href="http://wiki.lesswrong.com/wiki/Meditation">Meditation</a> [http://wiki.lesswrong.com/wiki/Meditation]: What distinguishes a correct mathematical proof from an incorrect mathematical proof - what does it mean for a mathematical proof to be good? And why, in the real world, would anyone ever be interested in a mathematical proof of this type, or obeying whatever goodness-rule you just set down? How could you use your notion of 'proof' to improve the real-world efficacy of an Artificial Intelligence?<a id="more"></a></p> <p>...<br>...<br>...</p> <p>Consider the following syllogism:</p> <ol> <li>All kittens are little;</li> <li>Everything little is innocent;</li> <li>Therefore all kittens are innocent.</li> </ol> <p>Here's four mathematical universes, aka "models", in which the objects collectively obey or disobey these three rules:</p> <table cellpadding="5" border="0"> <tbody> <tr> <td><img src="6764049f.jpg" alt="little innocent kitten, little innocent kitten, big evil dog, little innocent dog" height="181" width="300"></td> <td><img src="e6729312.jpg" alt="little innocent kitten, big evil kitten, big evil dog, little innocent dog" height="181" width="300"></td> </tr> <tr> <td><img src="16dd4267.jpg" alt="little innocent kitten, little evil kitten, big innocent dog, little innocent dog" height="181" width="300"></td> <td><img src="50154ac6.jpg" alt="little innocent kitten, big innocent kitten, big evil dog, little evil dog" height="181" width="300"></td> </tr> </tbody> </table> <p>There are some models where not all kittens are little, like models B and D. And there are models where not everything little is innocent, like models C and D. But there are no models where all kittens are little, <em>and</em> everything little is innocent, and yet there exists a guilty kitten. Try as you will, you won't be able to imagine a model like that. Any model containing a guilty kitten has at least one kitten that isn't little, or at least one little entity that isn't innocent - no way around it.</p> <p>Thus, the jump from 1 &amp; 2, to 3, is <em>truth-preserving: </em>in any universe where premises (1) and (2) are true to start with, the conclusion (3) is true of the same universe at the end.</p> <p>Which is what makes the following implication <em>valid</em>, or, as people would usually just say, "true":</p> <p>"If all kittens are little and everything little is innocent, then all kittens are innocent."</p> <p>The <em>advanced </em>mainstream view of logic and mathematics (i.e., the mainstream view among professional scholars of logic as such, not necessarily among all mathematicians in general) is that when we talk about math, we are talking about <em>which conclusions follow from which premises</em>. The "truth" of a mathematical theorem - or to not overload the word 'true' meaning <a href="0813.html">comparison-to-causal-reality</a> [http://lesswrong.com/lw/eva/the_fabric_of_real_things/], the <em>validity</em> of a mathematical theorem - has nothing to do with the physical truth or falsity of the conclusion in our world, and everything to do with the inevitability of the <em>implication.</em> From the standpoint of <em>validity</em>, it doesn't matter a fig whether or not all kittens are innocent in our <em>own</em> universe, the connected causal fabric within which we are embedded. What matters is whether or not you can prove the implication, starting from the premises; whether or not, if all kittens <em>were</em> little and all little things <em>were</em> innocent, it would follow <em>inevitably</em> that all kittens were innocent.</p> <hr> <p>To paraphrase Mayor Daley, logic is not there to <em>create</em> truth, logic is there to <em>preserve</em> truth. Let's illustrate this point by assuming the following equation:</p> <pre style="padding-left: 30px;">x = y = 1</pre> <p>...which is true in at least some cases.  E.g. 'x' could be the number of thumbs on my right hand, and 'y' the number of thumbs on my left hand.</p> <p>Now, starting from the above, we do a little algebra:</p> <table cellpadding="1" border="1"> <tbody> <tr> <td> <pre><strong>1</strong></pre> </td> <td> <pre>x = y = 1</pre> </td> <td> <pre>starting premise</pre> </td> </tr> <tr> <td> <pre><strong>2</strong></pre> </td> <td> <pre>x<sup>2</sup> = xy</pre> </td> <td> <pre>multiply both sides by x</pre> </td> </tr> <tr> <td> <pre><strong>3</strong></pre> </td> <td> <pre>x<sup>2</sup> - y<sup>2</sup> = xy - y<sup>2</sup></pre> </td> <td> <pre>subtract y<sup>2</sup> from both sides</pre> </td> </tr> <tr> <td> <pre><strong>4</strong></pre> </td> <td> <pre>(x + y)(x - y) = y(x - y)</pre> </td> <td> <pre>factor</pre> </td> </tr> <tr> <td> <pre><strong>5</strong></pre> </td> <td> <pre>x + y = y</pre> </td> <td> <pre>cancel</pre> </td> </tr> <tr> <td> <pre><strong>6</strong></pre> </td> <td> <pre>2 = 1</pre> </td> <td> <pre>substitute 1 for x and 1 for y</pre> </td> </tr> </tbody> </table> <p> </p> <p>We have reached the conclusion that in every case where x and y are equal to 1, 2 is equal to 1. This does not seem like it should follow inevitably.</p> <p>You could try to find the flaw just by staring at the lines... maybe you'd suspect that the error was between line 3 and line 4, following the heuristic of first mistrusting what looks like the most complicated step... but another way of doing it would be to try <em>evaluating</em> each line to see what it said concretely, for example, multiplying out x<sup>2</sup> = xy in line 2 to get (1<sup>2</sup>) = (1 * 1) or 1 = 1. Let's try doing this for each step, and then afterward mark whether each equation looks <em>true</em> or <em>false:</em></p> <table border="1"> <tbody> <tr> <td> <pre><strong>1</strong></pre> </td> <td> <pre>x = y = 1</pre> </td> <td> <pre>1 = 1</pre> </td> <td> <pre><strong>true</strong></pre> </td> </tr> <tr> <td> <pre><strong>2</strong></pre> </td> <td> <pre>x<sup>2</sup> = xy</pre> </td> <td> <pre>1 = 1</pre> </td> <td> <pre><strong>true</strong></pre> </td> </tr> <tr> <td> <pre><strong>3</strong></pre> </td> <td> <pre>x<sup>2</sup> - y<sup>2</sup> = xy - y<sup>2</sup></pre> </td> <td> <pre>0 = 0</pre> </td> <td> <pre><strong>true</strong></pre> </td> </tr> <tr> <td> <pre><strong>4</strong></pre> </td> <td> <pre>(x + y)(x - y) = y(x - y)</pre> </td> <td> <pre>0 = 0</pre> </td> <td> <pre><strong>true</strong></pre> </td> </tr> <tr> <td> <pre><strong>5</strong></pre> </td> <td> <pre>x + y = y</pre> </td> <td> <pre>2 = 1</pre> </td> <td> <pre><strong>false</strong></pre> </td> </tr> <tr> <td> <pre><strong>6</strong></pre> </td> <td> <pre>2 = 1</pre> </td> <td> <pre>2 = 1</pre> </td> <td> <pre><strong>false</strong></pre> </td> </tr> </tbody> </table> <p> </p> <p>Logic is there to preserve truth, not to create truth. Whenever we take a logically valid step, we can't guarantee that the premise is true to start with, but <em>if</em> the premise is true the conclusion should always be true. Since we went from a true equation to a false equation between step 4 and step 5, we must've done something that is <em>in general</em> invalid.</p> <p>In <em>particular, </em>we divided both sides of the equation by (x - y).</p> <p>Which is invalid, i.e. <em>not universally truth-preserving,</em> because (x - y) might be equal to 0.</p> <p>And if you divide both sides by 0, you can get a false statement from a true statement. 3 * 0 = 2 * 0 is a true equation, but 3 = 2 is a false equation, so it is not allowable in general to cancel <em>any</em> factor if the factor might equal zero.</p> <p>On the other hand, adding 1 to both sides of an equation is <em>always</em> truth-preserving. We can't guarantee as a matter of logic that x = y to start with - for example, x might be my number of ears and y might be my number of fingers.  But <em>if</em> x = y <em>then</em> x + 1 = y + 1, always. Logic is not there to create truth; logic is there to preserve truth. <em>If </em>a scale <em>starts out</em> balanced, then adding the same weight to both sides will result in a scale that is <em>still </em>balanced:</p> <p><img src="70e0c599.jpg" alt="" height="340" width="680"></p> <p>I will remark, in some horror and exasperation with the modern educational system, that I do not recall any math-book of my youth ever once explaining that the reason why you are always allowed to add 1 to both sides of an equation is that it is a kind of step which always produces true equations from true equations.</p> <p>What is a valid proof in algebra? It's a proof where, in each step, we do something that is<em> universally allowed,</em> something which can only produce true equations from true equations, and so the proof gradually transforms the starting equation into a final equation which must be true if the starting equation was true. Each step should also - this is part of what makes proofs <em>useful in reasoning</em> - be <em>locally verifiable</em> as allowed, by looking at only a small number of previous points, not the entire past history of the proof. If in some previous step I believed x<sup>2</sup> - y = 2, I only need to look at that single step to get the conclusion x<sup>2</sup> = 2 + y, because I am always allowed to add y to both sides of the equation; because I am always allowed to add any quantity to both sides of the equation; because if the two sides of an equation are in balance to start with, adding the same quantity to both sides of the balance will preserve that balance. I can know the inevitability of this implication without considering all the surrounding circumstances; it's a step which is <em>locally</em> guaranteed to be <em>valid</em>. (Note the similarity - and the differences - to how we can compute a causal entity <a href="0814.html">knowing only its immediate parents</a> [http://lesswrong.com/lw/ev3/causal_diagrams_and_causal_models/], and no other ancestors.)</p> <hr> <p>You may have read - I've certainly read - some philosophy which endeavors to score points for counter-intuitive cynicism by saying that all mathematics is a <em>mere game of tokens; </em>that we start with a meaningless string of symbols like:</p> <p><img src="903d7d89" alt="" height="19" width="285"></p> <p>...and we follow some symbol-manipulation rules like "If you have the string 'A &#8743; (A &#8594; B)' you are allowed to go to the string 'B'", and so finally end up with the string:</p> <p><img src="76119898" alt="" height="19" width="136"></p> <p>...and this activity of string-manipulation is all there is to what mathematicians call "theorem-proving" - all there is to the glorious human endeavor of mathematics.</p> <p>This, like a lot of other <a href="0648.html">cynicism</a> [http://lesswrong.com/lw/ym/cynical_about_cynicism/] out there, is <em>needlessly</em> <a href="0290.html">deflationary</a> [http://lesswrong.com/lw/oo/explaining_vs_explaining_away/].</p> <p>There's a family of techniques in machine learning known as "<a href="http://en.wikipedia.org/wiki/Monte_Carlo_method">Monte Carlo methods</a> [http://en.wikipedia.org/wiki/Monte_Carlo_method]" or "Monte Carlo simulation", one of which says, roughly, "To find the probability of a proposition Q given a set of premises P, simulate random models that obey P, and then count how often Q is true." Stanislaw Ulam invented the idea after trying for a while to calculate the probability that a random Canfield solitaire layout would be solvable, and finally realizing that he could get better information by trying it a hundred times and counting the number of successful plays. This was during the era when computers were first becoming available, and the thought occurred to Ulam that the same technique might work on a current neutron diffusion problem as well.</p> <p>Similarly, to answer a question like, "What is the probability that a random Canfield solitaire is solvable, given that the top card in the deck is a king?" you might imagine simulating many 52-card layouts, throwing <em>away</em> all the layouts where the top card in the deck was not a king, using a computer algorithm to solve the remaining layouts, and counting what percentage of those were solvable. (It would be more efficient, in this case, to start by directly placing a king on top and then randomly distributing the other 51 cards; but this is not always efficient in Monte Carlo simulations when the condition to be fulfilled is more complex.)</p> <p><img src="c3afd679.jpg" alt="" height="345" width="635"></p> <p>Okay, now for a harder problem. Suppose you've wandered through the world a bit, and you've observed the following:</p> <p>(1) So far I've seen 20 objects which have been kittens, and on the 6 occasions I've paid a penny to observe the size of something that's a kitten, all 6 kitten-objects have been little.</p> <p>(2) So far I've seen 50 objects which have been little, and on the 30 occasions where I've paid a penny to observe the morality of something little, all 30 little objects have been innocent.</p> <p>(3) This object happens to be a kitten. I want to know whether it's innocent, but I don't want to pay a cent to find out directly. (E.g., if it's an innocent kitten, I can buy it for a cent, sell it for two cents, and make a one-cent profit. But if I pay a penny to observe directly whether the kitten is innocent, I won't be able to make a profit, since gathering evidence is costly.)</p> <p>Your previous experiences have led you to suspect the general rule "All kittens are little" and also the rule "All little things are innocent", even though you've never before <em>directly</em> checked whether a kitten is innocent.</p> <p>Furthermore...</p> <p>You've <em>never heard of logic,</em> and you have no idea how to play that 'game of symbols' with K(x), I(x), and L(x) that we were talking about earlier.</p> <p>But that's all right. The problem is still solvable by Monte Carlo methods!</p> <p>First we'll generate a large set of random universes. Then, for each universe, we'll check whether that universe obeys all the rules we currently suspect or believe to be true, like "All kittens are little" and "All little things are innocent" and "The force of gravity goes as the square of the distance between two objects and the product of their masses".  If a universe passes this test, we'll check to see whether the inquiry of interest, "Is the kitten in front of me innocent?", also happens to be true in that universe.</p> <p>We shall repeat this test <em>a large number of times</em>, and at the end we shall have an approximate estimate of the probability that the kitten in front of you is innocent.</p> <p><img src="eea28b9d.jpg" alt="" height="266" width="643"></p> <p>On this algorithm, you perform inference by visualizing many possible universes, throwing out universes that disagree with generalizations you already believe in, and then checking what's true (probable) in the universes that remain. This algorithm doesn't tell you the state of the real physical world with certainty. Rather, it gives you a measure of probability - i.e., the probability that the kitten is innocent - <em>given everything else you already believe to be true</em>.</p> <p>And if, instead of visualizing many imaginable universes, you checked <em>all possible logical models</em> - which would take something beyond magic, because that would include models containing uncountably large numbers of objects - and the inquiry-of-interest was true in <em>every</em> model matching your previous beliefs, you would have found that the conclusion followed <em>inevitably</em> if the generalizations you already believed were true.</p> <p>This might take a whole lot of reasoning, but at least you wouldn't have to pay a cent to observe the kitten's innocence directly.</p> <p>But it would also <em>save you some computation</em> if you could play that<em> game of symbols</em> we talked about earlier - a game which does not create truth, but <em>preserves</em> truth. In this game, the steps can be <em>locally</em> pronounced valid by a mere 'syntactic' check that doesn't require us to visualize all possible models. Instead, if the mere <em>syntax</em> of the proof checks out, we know that the conclusion is always true in a model whenever the premises are true in that model.</p> <p>And that's a mathematical proof:  A conclusion which is true in any model where the axioms are true, which we know because we went through a series of transformations-of-belief, each step being licensed by some rule which guarantees that such steps never generate a false statement from a true statement.</p> <p>The way we would say it in standard mathematical logic is as follows:</p> <p>A collection of axioms X <em>semantically</em> implies a theorem Y, if Y is true in all models where X are true. We write this as X <span style="color: #222222; font-family: arial, sans-serif; line-height: 16px;">&#8872;</span> Y.</p> <p>A collection of axioms X <em>syntactically</em> implies a theorem Y within a system S, if we can get to Y from X using transformation steps allowed within S. We write this as X <span style="color: #222222; font-family: arial, sans-serif; line-height: 16px;">&#8866;</span> Y.</p> <p>The point of the system S known as "classical logic" is that its syntactic transformations preserve semantic implication, so that any syntactically allowed proof is semantically valid:</p> <p>If X <span style="color: #222222; font-family: arial, sans-serif; line-height: 16px;">&#8866;&#160;</span>Y, then X <span style="color: #222222; font-family: arial, sans-serif; line-height: 16px;">&#8872;</span> Y.</p> <p>If you make this idea be about proof steps in algebra doing things that always preserve the balance of a previously balanced scale, I see no reason why this idea couldn't be presented in eighth grade or earlier.</p> <p>I can attest by spot-checking for small N that even most <em>mathematicians</em> have not been exposed to this idea. It's the standard concept in mathematical logic, but for some odd reason, the knowledge seems <em>constrained </em>to the study of "mathematical logic" as a separate field, which not all mathematicians are interested in (many just want to do Diophantine analysis or whatever).</p> <hr> <p>So far as real life is concerned, mathematical logic only tells us the implications of what we already believe or suspect, but this is a computational problem of supreme difficulty and importance. After the first thousand times we observe that objects in Earth gravity accelerate downward at 9.8 m/s<sup>2</sup>, we can suspect that this will be true on the next occasion - which is a matter of probabilistic induction, not valid logic. But then to go from that suspicion, <em>plus</em> the observation that a building is 45 meters tall, to a <em>specific</em> prediction of how long it takes the object to hit the ground, is a matter of logic - what will happen if everything we else we already believe, is actually true. It requires computation to make this conclusion transparent.  We are not 'logically omniscient' - the technical term for the impossible dreamlike ability of knowing all the implications of everything you believe.</p> <p>The great virtue of logic in <em>argument</em> is not that you can prove things by logic that are absolutely certain. Since logical implications are valid in every possible world, "observing" them never tells us <em>anything</em> about <em>which</em> possible world we live in. Logic can't tell you that you won't suddenly float up into the atmosphere. (What if we're in the Matrix, and the Matrix Lords decide to do that to you on a whim as soon as you finish reading this sentence?) Logic can only tell you that, if that <em>does</em> happen, you were wrong in your extremely strong suspicion about gravitation being always and everywhere true in our universe.</p> <p>The great virtue of valid logic in <em>argument,</em> rather, is that logical argument exposes premises, so that anyone who disagrees with your conclusion has to (a) point out a premise they disagree with or (b) point out an invalid step in reasoning which is strongly liable to generate false statements from true statements.</p> <p>For example: Nick Bostrom put forth the Simulation Argument, which is that <em>you must disagree with either statement (1) or (2) or else agree with statement (3):</em></p> <p>(1) Earth-originating intelligent life will, in the future, acquire vastly greater computing resources.</p> <p>(2) Some of these computing resources will be used to run many simulations of ancient Earth, aka "ancestor simulations".</p> <p>(3) We are almost certainly living in a computer simulation.</p> <p>...but unfortunately it appears that not only do most respondents decline to say <em>why</em> they disbelieve in (3), most are unable to understand the distinction between the Simulation <em>Hypothesis</em> that we are living in a computer simulation, versus Nick Bostrom's actual support for the Simulation <em> Argument</em> that "You must either disagree with (1) or (2) or agree with (3)".  They just treat Nick Bostrom as having claimed that we're all living in the Matrix. Really. Look at the media coverage.</p> <p>I would seriously generalize that the mainstream media only understands the "and" connective, not the "or" or "implies" connective. I.e., it is impossible for the media to report on a discovery that one of two things must be true, or a discovery that <em>if</em> X is true then Y must be true (when it's not known that X is true). Also, the media only understands the "not" prefix when applied to atomic facts; it should go without saying that "not (A and B)" cannot be reported-on.</p> <p>Robin Hanson sometimes complains that when he tries to argue that conclusion X follows from reasonable-sounding premises Y, his colleagues disagree with X while refusing to say which premise Y they think is false, or else say which step of the reasoning seems like an invalid implication.  Such behavior is not only annoying, but <a href="http://wiki.lesswrong.com/wiki/Logical_rudeness">logically rude</a> [http://wiki.lesswrong.com/wiki/Logical_rudeness], because someone else went out of their way and put in extra effort to make it <em>as easy as possible</em> for you to explain why you disagreed, and <em>you </em>couldn't be bothered to pick one item off a multiple-choice menu.</p> <p>The inspiration of logic for argument is to lay out a modular debate, one which conveniently breaks into smaller pieces that can examined with smaller conversations.&#160;&#160;At least when it comes to trying to have a real conversation with a respected partner - I wouldn't necessarily advise a teenager to try it on their oblivious parents - that is the great inspiration we can take from the study of mathematical logic: <em>An argument is a succession of statements each allegedly following with high probability from previous statements or shared background knowledge.</em> Rather than, say, snowing someone under with as much fury and as many demands for applause as you can fit into sixty seconds.</p> <p>Michael Vassar is fond of claiming that most people don't have the concept of an argument, and that it's pointless to try and teach them anything else until you can convey an intuitive sense for what it means to argue. I <em>think</em> that's what he's talking about.</p> <hr> <p><strong><a href="http://lesswrong.com/lw/f43/proofs_implications_and_models/#7ors">Meditation</a> [http://lesswrong.com/lw/f43/proofs_implications_and_models/#7ors]</strong>: It has been claimed that logic and mathematics is the study of which conclusions follow from which premises. But when we say that 2 + 2 = 4, are we really just <em>assuming</em> that? It seems like 2 + 2 = 4 was true well before anyone was around to assume it, that two apples equaled two apples before there was anyone to count them, and that we couldn't make it 5 just by assuming differently.</p> <hr> <p><strong><a href="http://lesswrong.com/lw/f43/proofs_implications_and_models/#7ort">Mainstream status.</a> [http://lesswrong.com/lw/f43/proofs_implications_and_models/#7ort]</strong></p> <p style="text-align:right">Part of the sequence <a href="http://wiki.lesswrong.com/wiki/Highly_Advanced_Epistemology_101_for_Beginners"><em>Highly Advanced Epistemology 101 for Beginners</em></a> [http://wiki.lesswrong.com/wiki/Highly_Advanced_Epistemology_101_for_Beginners]</p> <p style="text-align:right">Next post: "<a href="0818.html">Logical Pinpointing</a> [http://lesswrong.com/lw/f4e/logical_pinpointing/]"</p> <p style="text-align:right">Previous post: "<a href="0816.html">Causal Reference</a> [http://lesswrong.com/lw/f1u/causal_reference/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq17.html">Sequence 17: Highly Advanced Epistemology 101 for Beginners</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0819.html">Causal Universes</a></p></td><td><p><i>Next: </i><a href="0818.html">Logical Pinpointing</a></p></td></tr></table><p><i>Referenced by: </i><a href="0310.html">Zombie Responses</a> &#8226; <a href="0816.html">Causal Reference</a> &#8226; <a href="0818.html">Logical Pinpointing</a> &#8226; <a href="0820.html">Mixed Reference: The Great Reductionist Project</a> &#8226; <a href="0822.html">Standard and Nonstandard Numbers</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/f43/proofs_implications_and_models/">Proofs, Implications, and Models</a></p></body></html>