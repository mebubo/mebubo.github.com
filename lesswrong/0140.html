<html><head><title>Double Illusion of Transparency</title></head><body><h1>Double Illusion of Transparency</h1><p><i>Eliezer Yudkowsky, 24 October 2007 11:06PM</i></p><div><p><strong>Followup to:</strong>  <a href="0139.html">Explainers Shoot High</a> [http://lesswrong.com/lw/kh/explainers_shoot_high_aim_low/], <a href="0136.html">Illusion of Transparency </a> [http://lesswrong.com/lw/ke/illusion_of_transparency_why_no_one_understands/]</p> <p>My first true foray into Bayes For Everyone was writing <a href="http://yudkowsky.net/bayes/bayes.html">An Intuitive Explanation of Bayesian Reasoning</a> [http://yudkowsky.net/bayes/bayes.html], still one of my most popular works.  This is the <em>Intuitive Explanation's</em> origin story.</p> <p>In December of 2002, I'd been sermonizing in a habitual IRC channels about what seemed to me like a very <a href="0138.html">straightforward</a> [http://lesswrong.com/lw/kg/expecting_short_inferential_distances/] idea:  How words, like all other useful forms of thought, are secretly a disguised form of Bayesian inference.  I thought I was explaining clearly, and yet there was one fellow, it seemed, who didn't get it.  This worried me, because this was someone who'd been very enthusiastic about my Bayesian sermons up to that point.  He'd gone around telling people that Bayes was "the secret of the universe", a phrase I'd been known to use.</p> <p>So I went into a private IRC conversation to clear up the sticking point.</p> <p><a id="more"></a></p> <p>And he still didn't get it.</p> <p>I took a step back and explained the immediate prerequisites, which I had thought would be obvious -</p> <p>He didn't understand my explanation of the prerequisites.</p> <p>In desperation, I recursed all the way back to Bayes's Theorem, the ultimate foundation stone of -</p> <p>He didn't know how to apply Bayes's Theorem to update the probability that a fruit is a banana, after it is observed to be yellow.  He kept mixing up p(b|y) and p(y|b).</p> <p>It seems like a small thing, I know.  It's strange how small things can trigger major life-realizations.  Any former TAs among my readers are probably laughing:  I hadn't realized, until then, that instructors got misleading feedback.  Robin commented yesterday that the best way to <a href="0139.html">aim your explanations</a> [http://lesswrong.com/lw/kh/explainers_shoot_high_aim_low/fr4] is feedback from the intended audience, "an advantage teachers often have".  But what if <a href="0137.html">self-anchoring</a> [http://lesswrong.com/lw/kf/selfanchoring/] <em>also</em> causes you to overestimate how much understanding appears in your feedback?</p> <p>I fell prey to a <em>double</em> illusion of transparency.  First, I assumed that my words meant what I intended them to mean - that my listeners heard my intentions as though they were transparent.  Second, when someone repeated back my sentences using slightly different word orderings, I assumed that what <em>I</em> heard was what <em>they</em> had intended to say.  As if all words were transparent windows into thought, in both directions.</p> <p>I thought that if I said, "Hey, guess what I noticed today!  Bayes's Theorem is the secret of the universe!", and someone else said, "<a href="http://www.youtube.com/watch?v=LQqq3e03EBQ">Yes!</a> [http://www.youtube.com/watch?v=LQqq3e03EBQ] Bayes's Theorem is the secret of the universe!", then this was what a successful teacher-student interaction looked like: <a href="0076.html">knowledge</a> [http://lesswrong.com/lw/iq/guessing_the_teachers_password/] conveyed and verified<em>.  </em>I'd read <a href="0129.html">Pirsig</a> [http://lesswrong.com/lw/k7/original_seeing/] and I knew, in theory, about how students learn to repeat back what the teacher says in slightly different words.  But I thought of that as a deliberate tactic to get good grades, and <em>I</em> wasn't grading anyone.</p> <p>This may sound odd, but until that very day, I hadn't realized <em>why</em> there were such things as universities.  I'd thought it was just rent-seekers who'd gotten a lock on the credentialing system.  Why would you need teachers to learn?  That was what books were for.</p> <p>But now a great and terrible light was dawning upon me.  <em>Genuinely <strong>explaining</strong> complicated things took months or years, and an entire university infrastructure with painstakingly crafted textbooks and professional instructors.  You couldn't just <strong>tell</strong> people.</em></p> <p><em></em></p> <p>You're laughing at me right now, academic readers; but think back and you'll realize that academics are generally very careful <em>not</em> to tell the general population how difficult it is to explain things, because it would come across as condescending.  Physicists can't just say, "What we do is beyond your comprehension, foolish mortal" when Congress is considering their funding.  Richard Feynman once said that if you really understand something in physics you should be able to explain it to your grandmother.  I believed him.  I was <em>shocked</em> to discover it wasn't true.</p> <p>But once I realized, it became horribly clear why no one had picked up and run with any of the wonderful ideas I'd been <em>telling</em> about Artificial Intelligence.<em> </em></p> <p>If I wanted to explain all these marvelous ideas I had, I'd have to go back, and back, and back.  I'd have to start with the things I'd figured out <em>before I was even thinking about Artificial Intelligence,</em> the foundations without which nothing else would make sense.</p> <p>Like all that stuff I'd worked out about human rationality, back at the dawn of time.</p> <p>Which I'd considerably reworked after receiving my Bayesian Enlightenment.  But either way, I had to start with the foundations.  Nothing I said about AI was going to make sense unless I started at the beginning.  My listeners would just decide that <a href="0081.html">emergence</a> [http://lesswrong.com/lw/iv/the_futility_of_emergence/] was a better explanation.</p> <p>And the beginning of all things in the reworked version was Bayes, to which there didn't seem to be any decent online introduction for newbies.  Most sources just stated Bayes's Theorem and defined the terms.  This, I now realized, was <em>not</em> going to be sufficient.  The online sources I saw didn't even say why Bayes's Theorem was important.  E. T. Jaynes seemed to get it, but Jaynes spoke only in calculus - no hope for novices there.</p> <p>So I mentally consigned everything I'd written before 2003 to the trash heap - it was mostly obsolete in the wake of my Bayesian Enlightenment, anyway - and started over at what I fondly conceived to be the beginning.</p> <p>(It wasn't.)</p> <p>And I would explain it so clearly that even grade school students would get it.</p> <p>(They didn't.)</p> <p>I had, and have, much left to learn about explaining.  But that's how it all began.</p></div> <hr><p><i>Referenced by: </i><a href="0141.html">No One Knows What Science Doesn't Know</a> &#8226; <a href="0724.html">Practical Advice Backed By Deep Theories</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/ki/double_illusion_of_transparency/">Double Illusion of Transparency</a></p></body></html>