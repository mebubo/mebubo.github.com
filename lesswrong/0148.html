<html><head><title>Fake Justification</title></head><body><h1>Fake Justification</h1><p><i>Eliezer Yudkowsky, 01 November 2007 03:57AM</i></p><div><p>Many Christians who've stopped <a href="0054.html">really believing</a> [http://lesswrong.com/lw/i4/belief_in_belief/] now insist that they revere the Bible as a source of ethical advice.  The standard atheist reply is given by <a href="http://homepage.mac.com/pmcarlton/Harris_Sullivan_CompleteDebate.pdf">Sam Harris</a> [http://homepage.mac.com/pmcarlton/Harris_Sullivan_CompleteDebate.pdf]:  "You and I both know that it would take us five minutes to produce a book that offers a more coherent and compassionate morality than the Bible does."  Similarly, one may try to insist that the Bible is valuable as a literary work.  Then why not revere <em>Lord of the Rings,</em> a vastly superior literary work?  And despite the standard criticisms of Tolkien's morality, <em>Lord of the Rings</em> is at least superior to the Bible as a source of ethics.  So why don't people wear little rings around their neck, instead of crosses?  Even <em>Harry Potter</em> is superior to the Bible, both as a work of literary art and as moral philosophy.  If I really wanted to be cruel, I would compare the Bible to Jacqueline Carey's <em>Kushiel</em> series.</p> <p>"How can you justify buying a <a href="http://hardware.slashdot.org/article.pl?sid=07/03/26/197253">$1 million gem-studded laptop</a> [http://hardware.slashdot.org/article.pl?sid=07/03/26/197253]," you ask your friend, "when so many people have no laptops at all?"  And your friend says, "But think of the employment that this will provide&#8212;to the laptop maker, the laptop maker's advertising agency&#8212;and then they'll buy meals and haircuts&#8212;it will stimulate the economy and eventually many people will get their own laptops."  But it would be even <em>more</em> efficient to buy 5,000 OLPC laptops, thus providing employment to the OLPC manufacturers <em>and</em> giving out laptops directly.</p> <p>I've touched before on the failure to look for <a href="0044.html">third alternatives</a> [http://lesswrong.com/lw/hu/the_third_alternative/].  But this is not really <a href="0144.html">motivated stopping</a> [http://lesswrong.com/lw/km/motivated_stopping_and_motivated_continuation/].  Calling it "motivated stopping" would imply that there was a search carried out in the first place.</p> <p><a id="more"></a></p> <p>In <a href="0114.html">The Bottom Line</a> [http://lesswrong.com/lw/js/the_bottom_line/], I observed that only the real determinants of our beliefs can ever influence our real-world accuracy, only the real determinants of our actions can influence our effectiveness in achieving our goals.  Someone who buys a million-dollar laptop was really thinking, "Ooh, shiny" and that was the one true causal history of their decision to buy a laptop.  No amount of "justification" can change this, unless the justification is a genuine, newly running search process that can change the conclusion.  <em>Really</em> change the conclusion.  Most criticism <a href="0121.html">carried out from a sense of duty</a> [http://lesswrong.com/lw/jz/the_meditation_on_curiosity/] is more of a token inspection than anything else.  Free elections in a one-party country.</p> <p>To genuinely justify the Bible as a lauding-object by reference to its literary quality, you would have to somehow perform a neutral reading through candidate books until you found the book of highest literary quality.  Renown is one reasonable criteria for generating candidates, so I suppose you could legitimately end up reading Shakespeare, the Bible, and <em>Godel, Escher, Bach</em>.  (Otherwise it would be quite a coincidence to find the Bible as a candidate, among a million other books.)  The real difficulty is in that "neutral reading" part.  Easy enough if you're not a Christian, but if you are...</p> <p>But of course nothing like this happened.  No search ever occurred.  Writing the justification of "literary quality" above the <a href="0114.html">bottom line</a> [http://lesswrong.com/lw/js/the_bottom_line/] of "I &lt;heart&gt; the Bible" is a historical misrepresentation of how the <a href="0114.html">bottom line</a> [http://lesswrong.com/lw/js/the_bottom_line/] really got there, like selling cat milk as cow milk.  That is just not where the <a href="0114.html">bottom line</a> [http://lesswrong.com/lw/js/the_bottom_line/] really came from.  That is just not what originally happened to produce that conclusion.</p> <p>If you genuinely subject your conclusion to a criticism that can potentially de-conclude it&#8212;if the criticism <em>genuinely</em> has that power&#8212;then that does modify "the real algorithm behind" your conclusion.  It changes the entanglement of your conclusion over possible worlds.  But people overestimate, by far, how likely they <em>really</em> are to <a href="0119.html">change their minds</a> [http://lesswrong.com/lw/jx/we_change_our_minds_less_often_than_we_think/].</p> <p>With all those open minds out there, you'd think there'd be more belief-updating.</p> <p>Let me guess:  Yes, you admit that you originally decided you wanted to buy a million-dollar laptop by thinking, "Ooh, shiny".  Yes, you concede that this isn't a decision process consonant with your stated goals.  But since then, you've decided that you really ought to spend your money in such fashion as to provide laptops to as many laptopless wretches as possible.  And yet you just <em>couldn't</em> find any more efficient way to do this than buying a million-dollar diamond-studded laptop&#8212;because, hey, you're giving money to a laptop store and stimulating the economy!  Can't beat that!</p> <p>My friend, I am damned suspicious of this amazing coincidence.  I am damned suspicious that the best answer under this lovely, rational, altruistic criterion X, is also the idea that just happened to originally pop out of the unrelated indefensible process Y.  If you don't think that rolling dice would have been likely to produce the correct answer, then how likely is it to pop out of any other irrational cognition?</p> <p>It's improbable that you used mistaken reasoning, yet made no mistakes.</p> <p> </p> <p style="text-align:right">Part of the <a href="http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind#Against_Rationalization"><em>Against Rationalization</em></a> [http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind#Against_Rationalization] subsequence of <a href="http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind"><em>How To Actually Change Your Mind</em></a> [http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind]</p> <p style="text-align:right">Next post: "<a href="0157.html">Fake Optimization Criteria</a> [http://lesswrong.com/lw/kz/fake_optimization_criteria/]"</p> <p style="text-align:right">Previous post: "<a href="0144.html">Motivated Stopping and Motivated Continuation</a> [http://lesswrong.com/lw/km/motivated_stopping_and_motivated_continuation/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq07.html">Sequence 07: Against Rationalization</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0146.html">A Case Study of Motivated Continuation</a></p></td><td><p><i>Next: </i><a href="0157.html">Fake Optimization Criteria</a></p></td></tr></table><p><i>Referenced by: </i><a href="0144.html">Motivated Stopping and Motivated Continuation</a> &#8226; <a href="0149.html">An Alien God</a> &#8226; <a href="0154.html">The Tragedy of Group Selectionism</a> &#8226; <a href="0155.html">Fake Selfishness</a> &#8226; <a href="0157.html">Fake Optimization Criteria</a> &#8226; <a href="0172.html">Lost Purposes</a> &#8226; <a href="0183.html">Fake Fake Utility Functions</a> &#8226; <a href="0184.html">Fake Utility Functions</a> &#8226; <a href="0439.html">Anthropomorphic Optimism</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/kq/fake_justification/">Fake Justification</a></p></body></html>