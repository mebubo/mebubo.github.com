<html><head><title>Higher Purpose</title></head><body><h1>Higher Purpose</h1><p><i>Eliezer Yudkowsky, 23 January 2009 09:58AM</i></p><div><p><strong>Followup to</strong>:  <a href="0241.html">Something to Protect</a> [http://lesswrong.com/lw/nb/something_to_protect/], <a href="0178.html">Superhero Bias</a> [http://lesswrong.com/lw/lk/superhero_bias/]</p> <p>Long-time readers will recall that I've long been <a href="0241.html">uncomfortable</a> [http://lesswrong.com/lw/nb/something_to_protect/] with the idea that you can adopt a Cause as a hedonic accessory:</p> <p style="margin-left: 40px;">"Unhappy people are told that they need a 'purpose in life', so they should pick out an altruistic cause that goes well with their personality, like picking out nice living-room drapes, and this will brighten up their days by adding some color, like nice living-room drapes."</p> <p>But conversely it's also a fact that having a Purpose In Life consistently shows up as something that increases happiness, as measured by reported subjective well-being.</p> <p>One presumes that this works equally well <em>hedonically </em>no matter how <em>misguided </em>that Purpose In Life may be&#8212;no matter if it is <a href="0133.html">actually doing harm</a> [http://lesswrong.com/lw/kb/cant_say_no_spending/]&#8212;no matter if the means are <a href="http://miscellanea.wellingtongrey.net/2008/12/01/prayer-vs-hard-work/">as cheap as prayer</a> [http://miscellanea.wellingtongrey.net/2008/12/01/prayer-vs-hard-work/].  Presumably, all that matters for <em>your </em>happiness is that <em>you </em>believe in it.  So you had better not question overmuch whether you're really being effective; that would disturb <a href="0046.html">the warm glow of satisfaction you paid for.</a> [http://lesswrong.com/lw/hw/scope_insensitivity/]</p> <p>And here we verge on <a href="0201.html">Zen</a> [http://lesswrong.com/lw/m7/zen_and_the_art_of_rationality/], because you can't deliberately pursue "a purpose that takes you outside yourself", <em>in order to take yourself outside yourself.</em>  That's still all about <em>you.</em></p> <p>Which is the whole Western concept of "spirituality" that I despise:  <em>You</em> need a higher purpose so that <em>you</em> can be emotionally healthy.  The external world is just a stream of victims for <em>you </em>to rescue.</p> <p><a id="more"></a></p> <p>Which is not to say that you can <a href="0178.html">become more noble by being less happy</a> [http://lesswrong.com/lw/lk/superhero_bias/].  To <em>deliberately </em>sacrifice more, so that <em>you </em>can appear more virtuous to yourself, is also not a purpose outside yourself.</p> <p>The way someone ends up with a real purpose outside themselves, is that they're walking along one day and see an elderly women passing by, and they realize "Oh crap, a hundred thousand people are dying of old age every day, what an awful way to die" and then they set out to do something about it.</p> <p>If you want a purpose like that, then by <em>wanting</em> it, you're just circling back into <em>yourself </em>again.  Thinking about <em>your </em>need to be "useful".  Stop searching for <em>your purpose</em>.  Turn your eyes <em>outward </em>to look at things outside yourself, and <em>notice </em>when you care about them; and then figure out how to be <em>effective, </em>instead of priding yourself on how much spiritual benefit you're getting <a href="0499.html">just for trying</a> [http://lesswrong.com/lw/uh/trying_to_try/].</p> <p>With that said:</p> <p>In today's world, most of the highest-priority legitimate Causes are about large groups of people in extreme jeopardy.  (Wide scope * high severity.)  Aging threatens the old, starvation threatens the poor, <a href="http://www.nickbostrom.com/existential/risks.html">existential risks</a> [http://www.nickbostrom.com/existential/risks.html] threaten humankind as a whole.</p> <p>But some of the potential <em>solutions </em>on the table are, arguably, so powerful that they could solve almost the entire list.  Some argue that nanotechnology would take almost all our current problems off the table.  (I agree but reply that nanotech would create other problems, like unstable military balances, crazy uploads, and brute-forced AI.)</p> <p>I sometimes describe the <em>purpose </em>(if not the actual <a href="http://intelligence.org/upload/CEV.html">decision criterion</a> [http://intelligence.org/upload/CEV.html]) of <a href="http://yudkowsky.net/singularity/ai-risk">Friendly superintelligence</a> [http://yudkowsky.net/singularity/ai-risk] as "Fix all fixable problems such that it is more important for the problem to be fixed <em>immediately </em>than fixed by our own efforts."</p> <p>Wouldn't you then run out of victims with which to feed your higher purpose?</p> <p>"Good," you say, "I should sooner step in front of a train, than ask that there be more victims just to keep myself occupied."</p> <p>But do altruists then have little to look forward to, in the Future?  Will we, deprived of victims, find our higher purpose shriveling away, and have to make a new life for ourselves as self-absorbed creatures?</p> <p>"That unhappiness is relatively small compared to the unhappiness of a mother watching their child die, so screw it."</p> <p>Well, but like it or not, the presence or absence of higher purpose <em>does</em> have hedonic effects on human beings, configured as we are now.  And to reconfigure ourselves so that we no longer need to care about anything outside ourselves... does sound a little sad.  I don't practice altruism <em>for the sake of being virtuous</em>&#8212;but I also recognize that "altruism" is part of what I value in humanity, part of what I want to save.  If you save everyone, have you <a href="0606.html">obsoleted</a> [http://lesswrong.com/lw/xg/emotional_involvement/] the will to save them?</p> <p>But I think it's a false dilemma.  Right now, in this world, any halfway capable rationalist who looks outside themselves, will find their eyes immediately drawn to large groups of people in extreme jeopardy.  Wide scope * great severity = big problem.  It doesn't mean that if one were to <em>solve </em>all those Big Problems, we would have nothing <em>left </em>to care about except ourselves.</p> <p>Friends?  Family?  Sure, and also more abstract ideals, like Truth or Art or Freedom.  The change that altruists may have to get used to, is the absence of any solvable problems so <em>urgent</em> that it doesn't matter whether they're solved by a person or an <a href="0595.html">unperson</a> [http://lesswrong.com/lw/x5/nonsentient_optimizers/].  That <em>is </em>a change and a major one&#8212;which I am not going to go into, because <a href="0615.html">we don't yet live in that world</a> [http://lesswrong.com/lw/xp/seduced_by_imagination/].  But it's not so sad a change, as having nothing to care about outside yourself.  It's not the end of purpose.  It's not even a descent into "spirituality": people might still look around outside themselves to see what needs doing, thinking more of effectiveness than of emotional benefits.</p> <p>But I <em>will </em>say this much:</p> <p>If all goes well, there will come a time when you could search the whole of civilization and never find a single person so much in need of help, as dozens you now pass on the street.</p> <p>If you do want to save someone from death, or help a great many people&#8212;if you want to have that memory for yourself, later&#8212;then you'd better get your licks in <em>now.</em></p> <p>I say this, because although that is not the <em>purest</em> motive, it is a <em>useful</em> motivation.</p> <p>And for now&#8212;in this world&#8212;it is the <em>usefulness </em>that matters.  That is the Art we are to practice <em>today</em>, however we <a href="0615.html">imagine</a> [http://lesswrong.com/lw/xp/seduced_by_imagination/] the world might change tomorrow.  We are not here to be our hypothetical selves of tomorrow.  <em>This </em>world is our charge and our challenge; we must adapt ourselves to live <em>here</em>, not somewhere else.</p> <p>After all&#8212;to care whether your motives were sufficiently "high", would just turn your eyes inward.</p> <p> </p> <p style="text-align:right">Part of <a href="0624.html"><em>The Fun Theory Sequence</em></a> [http://lesswrong.com/lw/xy/the_fun_theory_sequence/]</p> <p style="text-align:right">Next post: "<a href="0626.html">31 Laws of Fun</a> [http://lesswrong.com/lw/y0/31_laws_of_fun/]" (sequence guide)</p> <p style="text-align:right">Previous post: "<a href="0602.html">The Uses of Fun (Theory)</a> [http://lesswrong.com/lw/xc/the_uses_of_fun_theory/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq15.html">Sequence 15: Fun Theory</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0602.html">The Uses of Fun (Theory)</a></p></td><td><p><i>Next: </i><a href="seq16.html">Sequence 16: The Craft and the Community</a></p></td></tr></table><p><i>Referenced by: </i><a href="0602.html">The Uses of Fun (Theory)</a> &#8226; <a href="0624.html">The Fun Theory Sequence</a> &#8226; <a href="0626.html">31 Laws of Fun</a> &#8226; <a href="0691.html">Church vs. Taskforce</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/xw/higher_purpose/">Higher Purpose</a></p></body></html>