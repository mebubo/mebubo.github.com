<html><head><title>Abstracted Idealized Dynamics</title></head><body><h1>Abstracted Idealized Dynamics</h1><p><i>Eliezer Yudkowsky, 12 August 2008 01:00AM</i></p><div><p><strong>Followup to</strong>:  <a href="0442.html">Morality as Fixed Computation</a> [http://lesswrong.com/lw/sw/morality_as_fixed_computation/]</p> <p>I keep trying to describe morality as a "<a href="0442.html">computation</a> [http://lesswrong.com/lw/sw/morality_as_fixed_computation/]", but people don't stand up and say "Aha!"</p> <p>Pondering the surprising <a href="0138.html">inferential distances</a> [http://lesswrong.com/lw/kg/expecting_short_inferential_distances/] that seem to be at work here, it occurs to me that when I say "computation", some of my listeners may not hear the <a href="0138.html">Word of Power</a> [http://lesswrong.com/lw/kg/expecting_short_inferential_distances/] that I <a href="0136.html">thought I was emitting</a> [http://lesswrong.com/lw/ke/illusion_of_transparency_why_no_one_understands/]; but, rather, may think of some complicated boring unimportant thing like Microsoft Word.</p> <p>Maybe I should have said that morality is an <em>abstracted i</em><em>dealized dynamic</em>.  This might not have meant anything to start with, but at least it wouldn't sound like I was describing Microsoft Word.</p> <p>How, oh how, am I to describe the awesome import of this concept, "computation"?</p> <p>Perhaps I can display the inner nature of computation, in its most general form, by showing how that inner nature manifests in something that seems very unlike Microsoft Word&#8212;namely, morality.</p> <p>Consider certain features we might wish to ascribe to that-which-we-call "morality", or "should" or "right" or "good":</p> <p>&#8226; It seems that we sometimes think about morality in our armchairs, without further peeking at the state of the outside world, and arrive at some previously unknown conclusion.</p> <p>Someone sees a slave being whipped, and it doesn't occur to them right away that slavery is wrong.  But they go home and think about it, and imagine themselves in the slave's place, and finally think, "No."</p> <p>Can you think of anywhere else that something like this happens?</p> <p><a id="more"></a></p> <p>Suppose I tell you that I am making a rectangle of pebbles.  You look at the rectangle, and count 19 pebbles on one side and 103 dots pebbles on the other side.  You don't know right away how many pebbles there are.  But you go home to your living room, and draw the blinds, and sit in your armchair and think; and without further looking at the physical array, you come to the conclusion that the rectangle contains 1957 pebbles.</p> <p>Now, I'm not going to say the word "computation".  But it seems like that-which-is "morality" should have the property of <em>latent development of answers</em>&#8212;that you may not know right away, everything that you have sufficient in-principle information to know.  All the ingredients are present, but it takes additional time to bake the pie.</p> <p>You can specify a Turing machine of <a href="http://en.wikipedia.org/wiki/Busy_beaver#current_6-state.2C_2-symbol_best_contender">6 states and 2 symbols</a> [http://en.wikipedia.org/wiki/Busy_beaver#current_6-state.2C_2-symbol_best_contender] that unfolds into a string of 4.6 &#215; 10<sup>1439</sup> <strong>1</strong>s after 2.5 &#215; 10<sup>2879</sup> steps.  A machine I could describe aloud in ten seconds, runs longer and produces a larger state than the whole observed universe to date. </p> <p>When you distinguish between the program <em>description</em> and the program's <em>executing state,</em> between the process specification and the final outcome, between the question and the answer, you can see why even certainty about a program description does not imply human certainty about the executing program's outcome.  See also <a href="0167.html">Artificial Addition</a> [http://lesswrong.com/lw/l9/artificial_addition/] on the difference between a compact specification versus a flat list of outputs.</p> <p>Morality, likewise, is something that unfolds, through arguments, through discovery, through thinking; from a bounded set of intuitions and beliefs that animate our initial states, to a potentially much larger set of specific moral judgments we may have to make over the course of our lifetimes.</p> <p>&#8226; When two human beings both think about the same moral question, even in a case where they both start out uncertain of the answer, it is not unknown for them to come to the same conclusion.  It seems to happen more often than chance alone would allow&#8212;though the <a href="0091.html">biased focus of reporting and memory</a> [http://lesswrong.com/lw/j5/availability/] is on the shouting and the arguments.  And this is so, even if both humans remain in their armchairs and do not peek out the living-room blinds while thinking.</p> <p>Where else does this happen?  It happens when trying to guess the number of pebbles in a rectangle of sides 19 and 103.  Now this does not <a href="0393.html">prove by Greek analogy</a> [http://lesswrong.com/lw/rj/surface_analogies_and_deep_causes/] that morality is multiplication.  If A has property X and B has property X it does not follow that A is B.  But it seems that morality ought to have the property of <em>expected agreement about unknown latent answers</em>, which, please note, generally implies that <em>similar questions are being asked in different places.</em></p> <p>This is part of what is conveyed by the Word of Power, "computation": the notion of similar questions being asked in different places and having similar answers.  Or as we might say in the business, the same computation can have multiple instantiations.</p> <p>If we know the structure of calculator 1 and calculator 2, we can decide that they are "asking the same question" and that we ought to see the "same result" flashing on the screen of calculator 1 and calculator 2 after pressing the Enter key.  We decide this in advance of seeing the actual results, which is what makes the concept of "computation" predictively useful.</p> <p>And in fact, we can make this deduction even without knowing the exact circuit diagrams of calculators 1 and 2, so long as we're told that the circuit diagrams are the same.</p> <p>And then when we see the result "1957" flash on the screen of calculator 1, we know that the same "1957" can be expected to flash on calculator 2, and we even expect to count up 1957 pebbles in the array of 19 by 103.</p> <p>A hundred calculators, performing the same multiplication in a hundred different ways, can be expected to arrive at the same answer&#8212;and this is not a vacuous expectation adduced after seeing similar answers.  We can form the expectation in <em>advance</em> of seeing the actual answer.</p> <p>Now this does not show that morality is in fact a little electronic calculator.  But it highlights the notion of something that <em>factors out</em> of different physical phenomena in different physical places, even phenomena as physically different as a calculator and an array of pebbles&#8212;a common answer to a common question.  (Where is this factored-out thing?  Is there an Ideal Multiplication Table written on a stone tablet somewhere outside the universe? But we are not concerned with that for now.)</p> <p>Seeing that one calculator outputs "1957", we infer that <em>the answer</em>&#8212;the <em>abstracted</em> answer&#8212;is 1957; and from there we make our predictions of what to see on all the other calculator screens, and what to see in the array of pebbles.</p> <p>So that-which-we-name-morality seems to have the further properties of <em>agreement about developed latent answers,</em> which we may as well think of in terms of <em>abstract answers;</em> and note that such agreement is unlikely in the absence of <em>similar questions.</em></p> <p>&#8226; We sometimes look back on our own past moral judgments, and say "Oops!"  E.g., "Oops!  Maybe in retrospect I shouldn't have killed all those guys when I was a teenager."</p> <p>So by now it seems easy to extend the analogy, and say:  "Well, maybe a cosmic ray hits one of the transistors in the calculator and it says '1959' instead of 1957&#8212;that's an error."</p> <p>But this notion of "error", like the notion of "computation" itself, is more subtle than it appears.</p> <p>Calculator Q says '1959' and calculator X says '1957'.  Who says that calculator Q is wrong, and calculator X is right?  Why not say that calculator X is wrong and calculator Q is right?  Why not just say, "the results are different"?</p> <p>"Well," you say, drawing on your store of common sense, "if it was just those two calculators, I wouldn't know for sure which was right.  But here I've got nine other calculators that all say '1957', so it certainly seems <em>probable</em> that 1957 is the correct answer."</p> <p>What's this business about "correct"?  Why not just say "different"?</p> <p>"Because if I have to predict the outcome of any other calculators that compute 19 x 103, or the number of pebbles in a 19 x 103 array, I'll predict 1957&#8212;or whatever observable outcome corresponds to the abstract number 1957."</p> <p>So perhaps 19 x 103 = 1957 only most of the time.  Why call the answer 1957 the <em>correct</em> one, rather than the mere fad among calculators, the majority vote?</p> <p>If I've got a hundred calculators, all of them rather error-prone&#8212;say a 10% probability of error&#8212;then there is no <em>one</em> calculator I can point to and say, "This is the standard!"  I might pick a calculator that would happen, on this occasion, to vote with ten other calculators rather than ninety other calculators.  This is why I have to <em>idealize</em> the answer, to talk about this <em>ethereal</em> thing that is not associated with any particular physical process known to me&#8212;not even arithmetic done in my own head, which can also be "incorrect".</p> <p>It is this ethereal process, this idealized question, to which we compare the results of any one particular calculator, and say that the result was "right" or "wrong".</p> <p>But how can we obtain information about this perfect and un-physical answer, when all that we can ever observe, are merely physical phenomena?  Even doing "mental" arithmetic <a href="0124.html">just tells you about the result in your own, merely physical brain</a> [http://lesswrong.com/lw/k2/a_priori/].</p> <p>"Well," you say, "the pragmatic answer is that we can obtain extremely strong evidence by looking at the results of a hundred calculators, even if they are only 90% likely to be correct on any one occasion."</p> <p>But wait:  When do electrons or quarks or magnetic fields ever make an "error"?  If no individual particle can be mistaken, how can any collection of particles be mistaken?  The concept of an "error", though humans may take it for granted, is hardly something that would be mentioned in a fully reductionist view of the universe.</p> <p>Really, what happens is that we have a certain model in mind of the calculator&#8212;the model that we looked over and said, "This implements 19 * 103"&#8212;and then other physical events caused the calculator to depart from this model, so that the final outcome, while physically lawful, did not correlate with that mysterious abstract thing, and the other physical calculators, in the way we had in mind.  Given our mistaken beliefs about the physical process of the first calculator, we would look at its output '1959', and make mistaken predictions about the other calculators (which do still hew to the model we have in mind).</p> <p>So "incorrect" cashes out, naturalistically, as "physically departed from the model that I had of it" or "physically departed from the idealized question that I had in mind".  A calculator struck by a cosmic ray, is not 'wrong' in any physical sense, not an unlawful event in the universe; but the outcome is not the answer to the question you had in mind, the question that you believed empirically-falsely the calculator would correspond to.</p> <p>The calculator's "incorrect" answer, one might say, is an answer to a different question than the one you had in mind&#8212;it is an empirical fact about the calculator that it implements a different computation.</p> <p>&#8226; The 'right' act or the 'should' option sometimes seem to depend on the state of the physical world.  For example, should you cut the red wire or the green wire to disarm the bomb?</p> <p>Suppose I show you a long straight line of pebbles, and ask you, "How many pebbles would I have, if I had a rectangular array of six lines like this one?"  You start to count, but only get up to 8 when I suddenly blindfold you.</p> <p>Now you are not completely ignorant of the answer to this question.  You know, for example, that the result will be even, and that it will be greater than 48.  But you can't answer the question until you know how many pebbles were in the original line.</p> <p>But mark this about the question:  It wasn't a question about anything you could directly see in the world, at that instant.  There was not in fact a rectangular array of pebbles, six on a side.  You <em>could</em> perhaps lay out an array of such pebbles and count the results&#8212;but then there are more complicated computations that we could run on the unknown length of a line of pebbles.  For example, we could treat the line length as the start of a <a href="http://en.wikipedia.org/wiki/Goodstein%27s_theorem">Goodstein sequence</a> [http://en.wikipedia.org/wiki/Goodstein%27s_theorem], and ask whether the sequence halts.  To physically play out this sequence would require many more pebbles than exist in the universe.  Does it make sense to ask if the Goodstein sequence which starts with the length of this line of pebbles, "would halt"?  Does it make sense to talk about <em>the answer,</em> in a case like this?</p> <p>I'd say yes, personally.</p> <p>But meditate upon the etherealness of the answer&#8212;that we talk about idealized abstract processes that never really happen; that we talk about what <em>would</em> happen if the law of the Goodstein sequence came into effect upon this line of pebbles, even though the law of the Goodstein sequence will never physically come into effect.</p> <p>It is the same sort of etherealness that accompanies the notion of a proposition that 19 * 103 = 1957 which factors out of any particular physical calculator and is not identified with the result of any particular physical calculator.</p> <p>Only now that etherealness has been mixed with physical things; we talk about the effect of an ethereal operation on a physical thing.  We talk about what would happen if we ran the Goodstein process on <em>the number of pebbles in this line here,</em> which we have not counted&#8212;we do not know exactly how many pebbles there are.  There is no tiny little XML tag upon the pebbles that says "Goodstein halts", but we still think&#8212;or at least I still think&#8212;that it makes sense to say of the pebbles that they have the property of their Goodstein sequence terminating.</p> <p>So computations can be, as it were, idealized abstract <em>dynamics</em>&#8212;idealized abstract applications of idealized abstract laws, iterated over an imaginary causal-time that could go on for quite a number of steps (as Goodstein sequences often do). </p> <p>So when we wonder, "<em>Should</em> I cut the red wire or the green wire?", we are not multiplying or simulating the Goodstein process, in particular.  But we are wondering about something that is not physically immanent in the red wires or the green wires themselves; there is no little XML tag on the green wire, saying, "This is the wire that <em>should</em> be cut."</p> <p>We may not know which wire defuses the bomb, but say, "Whichever wire does in fact defuse the bomb, that is the wire that <em>should</em> be cut."</p> <p>Still, there are no little XML tags on the wires, and we may not even have any way to look inside the bomb&#8212;we may just have to guess, in real life.</p> <p>So if we try to cash out this notion of a definite wire that <em>should</em> be cut, it's going to come out as...</p> <p>...some rule that would tell us which wire to cut, if we knew the exact state of the physical world...</p> <p>...which is to say, some kind of idealized abstract process into which we feed the state of the world as an input, and get back out, "cut the green wire" or "cut the red wire"...</p> <p>...which is to say, the output of a computation that would take the world as an input.</p> <p>&#8226; And finally I note that from the twin phenomena of <em>moral agreement</em> and <em>moral error,</em> we can construct the notion of <em>moral disagreement.</em></p> <p>This adds nothing to our understanding of "computation" as a Word of Power, but it's helpful in putting the pieces together.</p> <p>Let's say that Bob and Sally are talking about an abstracted idealized dynamic they call "Enamuh".</p> <p>Bob says "The output of Enamuh is 'Cut the blue wire'," and Sally says "The output of Enamuh is 'Cut the brown wire'."</p> <p>Now there are several non-exclusive possibilities:</p> <p>Either Bob or Sally could have committed an error in applying the rules of Enamuh&#8212;they could have done the equivalent of mis-multiplying known inputs.</p> <p>Either Bob or Sally could be mistaken about some empirical state of affairs upon which Enamuh depends&#8212;the wiring of the bomb.</p> <p>Bob and Sally could be talking about different things when they talk about Enamuh, in which case both of them are committing an error when they refer to Enamuh_Bob and Enamuh_Sally by the same name.  (However, if Enamuh_Bob and Enamuh_Sally differ in the sixth decimal place in a fashion that doesn't change the output about which wire gets cut, Bob and Sally can quite legitimately gloss the difference.)</p> <p>Or if Enamuh itself is defined by some other abstracted idealized dynamic, a Meta-Enamuh whose output is Enamuh, then either Bob or Sally could be mistaken about Meta-Enamuh in any of the same ways they could be mistaken about Enamuh.  (But in the case of morality, we have an abstracted idealized dynamic that includes a specification of how it, itself, changes.  Morality is <em>self</em>-renormalizing&#8212;it is not a guess at the product of some different and outside source.)</p> <p>To sum up:</p> <ul> <li>Morality, like computation, involves <em>latent development of answers</em>;</li> <li>Morality, like computation, permits <em>expected agreement of unknown latent answers</em>;</li> <li>Morality, like computation, reasons about <em>abstract results apart from any particular physical implementation</em>;</li> <li>Morality, like computation, <em>unfolds from bounded initial state</em> into something <em>potentially much larger</em>;</li> <li>Morality, like computation, can be viewed as <em>an idealized dynamic that would operate on the true state of the physical world</em>&#8212;permitting us to speak about idealized answers of which we are physically uncertain;</li> <li>Morality, like computation, lets us to speak of such un-physical stuff as "error", by <em>comparing a physical outcome to an abstract outcome</em>&#8212;presumably in a case where there was previously reason to believe or desire that the physical process was isomorphic to the abstract process, yet this was not actually the case.</li> </ul> <p>And so with all that said, I hope that the word "computation" has come to convey something other than Microsoft Word.</p> <p> </p> <p style="text-align:right">Part of <a href="http://wiki.lesswrong.com/wiki/Metaethics_sequence"><em>The Metaethics Sequence</em></a> [http://wiki.lesswrong.com/wiki/Metaethics_sequence]</p> <p style="text-align:right">Next post: "<a href="0447.html">'Arbitrary'</a> [http://lesswrong.com/lw/t1/arbitrary/]"</p> <p style="text-align:right">Previous post: "<a href="0445.html">Moral Error and Moral Disagreement</a> [http://lesswrong.com/lw/sz/moral_error_and_moral_disagreement/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq14.html">Sequence 14: Metaethics</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0445.html">Moral Error and Moral Disagreement</a></p></td><td><p><i>Next: </i><a href="0447.html">"Arbitrary"</a></p></td></tr></table><p><i>Referenced by: </i><a href="0445.html">Moral Error and Moral Disagreement</a> &#8226; <a href="0447.html">"Arbitrary"</a> &#8226; <a href="0449.html">The Bedrock of Morality: Arbitrary?</a> &#8226; <a href="0450.html">Hot Air Doesn't Disagree</a> &#8226; <a href="0454.html">You Provably Can't Trust Yourself</a> &#8226; <a href="0459.html">Magical Categories</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/t0/abstracted_idealized_dynamics/">Abstracted Idealized Dynamics</a></p></body></html>