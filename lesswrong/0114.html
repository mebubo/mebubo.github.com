<html><head><title>The Bottom Line</title></head><body style="width: 600px; margin: 0 auto; font-family: Georgia, serif;"><h1>The Bottom Line</h1><p><i>Eliezer Yudkowsky, 28 September 2007 05:47PM</i></p><div><p>There are two sealed boxes up for auction, box A and box B.  One and only one of these boxes contains a valuable diamond.  There are all manner of signs and portents indicating whether a box contains a diamond; but I have no sign which I <em>know</em> to be perfectly reliable.  There is a blue stamp on one box, for example, and I know that boxes which contain diamonds are more likely than empty boxes to show a blue stamp.  Or one box has a shiny surface, and I have a suspicion&#8212;I am not sure&#8212;that no diamond-containing box is ever shiny.</p> <p>Now suppose there is a clever arguer, holding a sheet of paper, and he says to the owners of box A and box B:  "Bid for my services, and whoever wins my services, I shall argue that their box contains the diamond, so that the box will receive a higher price."  So the box-owners bid, and box B's owner bids higher, winning the services of the clever arguer.</p> <p>The clever arguer begins to organize his thoughts.  First, he writes, "And <em>therefore,</em> box B contains the diamond!" at the bottom of his sheet of paper.  Then, at the top of the paper, he writes, "Box B shows a blue stamp," and beneath it, "Box A is shiny", and then, "Box B is lighter than box A", and so on through many signs and portents; yet the clever arguer neglects all those signs which might argue in favor of box A.  And then the clever arguer comes to me and recites from his sheet of paper:  "Box B shows a blue stamp, and box A is shiny," and so on, until he reaches:  "And <em>therefore,</em> box B contains the diamond."</p> <p><a id="more"></a></p> <p>But consider:  At the moment when the clever arguer wrote down his conclusion, at the moment he put ink on his sheet of paper, the <a href="0107.html">evidential entanglement</a> [http://lesswrong.com/lw/jl/what_is_evidence/] of that physical ink with the physical boxes became fixed.</p> <p>It may help to visualize a collection of worlds&#8212;Everett branches or <a href="http://arxiv.org/abs/astro-ph/0302131">Tegmark duplicates</a> [http://arxiv.org/abs/astro-ph/0302131]&#8212;within which there is some objective frequency at which box A or box B contains a diamond.  There's likewise some objective frequency within the subset "worlds with a shiny box A" where box B contains the diamond; and some objective frequency in "worlds with shiny box A and blue-stamped box B" where box B contains the diamond.</p> <p>The ink on paper is formed into odd shapes and curves, which look like this text:  "And <em>therefore,</em> box B contains the diamond."  If you happened to be a literate English speaker, you might become confused, and think that this shaped ink somehow <em>meant</em> that box B contained the diamond.  Subjects instructed to say the color of printed pictures and shown the picture "<span style="color: #ff3300;">green</span>" often say "green" instead of "red".  It helps to be illiterate, so that you are not confused by the shape of the ink.</p> <p>To us, the true import of a thing is its entanglement with other things.  Consider again the collection of worlds, Everett branches or Tegmark duplicates.  At the moment when all clever arguers in all worlds put ink to the bottom line of their paper&#8212;let us suppose this is a single moment&#8212;it fixed the correlation of the ink with the boxes.  The clever arguer writes in non-erasable pen; the ink will not change.  The boxes will not change.  Within the subset of worlds where the ink says "And therefore, box B contains the diamond," there is already some fixed percentage of worlds where box A contains the diamond.  This will not change regardless of what is written in on the blank lines above.</p> <p>So the evidential entanglement of the ink is fixed, and I leave to you to decide what it might be.  Perhaps box owners who believe a better case can be made for them are more liable to hire advertisers; perhaps box owners who fear their own deficiencies bid higher.  If the box owners do not themselves understand the signs and portents, then the ink will be completely unentangled with the boxes' contents, though it may tell you something about the owners' finances and bidding habits.</p> <p>Now suppose another person present is genuinely curious, and she <em>first</em> writes down all the distinguishing signs of <em>both</em> boxes on a sheet of paper, and then applies her knowledge and the laws of probability and writes down at the bottom:  "<em>Therefore,</em> I estimate an 85% probability that box B contains the diamond."  Of what is this handwriting evidence?  Examining the chain of cause and effect leading to this physical ink on physical paper, I find that the chain of causality wends its way through all the signs and portents of the boxes, and is dependent on these signs; for in worlds with different portents, a different probability is written at the bottom.</p> <p>So the handwriting of the curious inquirer is entangled with the signs and portents and the contents of the boxes, whereas the handwriting of the clever arguer is evidence only of which owner paid the higher bid.  There is a great difference in the indications of ink, though one who foolishly read aloud the ink-shapes might think the English words sounded similar.</p> <p>Your effectiveness as a rationalist is determined by whichever algorithm actually writes the bottom line of your thoughts.  If your car makes metallic squealing noises when you brake, and you aren't willing to face up to the financial cost of getting your brakes replaced, you can decide to look for reasons why your car might not need fixing.  But the actual percentage of you that survive in Everett branches or Tegmark worlds&#8212;which we will take to describe your effectiveness as a rationalist&#8212;is determined by the algorithm that decided <em>which</em> conclusion you would seek arguments for.  In this case, the real algorithm is "Never repair anything expensive."  If this is a good algorithm, fine; if this is a bad algorithm, oh well.  The arguments you write afterward, above the bottom line, will not change anything either way.</p> <p><strong>Addendum:</strong>  This is intended as a caution for your own thinking, not a Fully General Counterargument against conclusions you don't like.  For it is indeed a clever argument to say "My opponent is a clever arguer", if you are paying yourself to retain whatever beliefs you had at the start.  The world's cleverest arguer may point out that the sun is shining, and yet it is still probably daytime.  See <a href="0115.html">What Evidence Filtered Evidence?</a> [http://lesswrong.com/lw/jt/what_evidence_filtered_evidence/] for more on this topic.</p> <p> </p> <p style="text-align:right">Part of the <a href="http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind#Against_Rationalization"><em>Against Rationalization</em></a> [http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind#Against_Rationalization] subsequence of <a href="http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind"><em>How To Actually Change Your Mind</em></a> [http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind]</p> <p style="text-align:right">Next post: "<a href="0115.html">What Evidence Filtered Evidence?</a> [http://lesswrong.com/lw/jt/what_evidence_filtered_evidence/]"</p> <p style="text-align:right">Previous post: "<a href="0070.html">One Argument Against An Army</a> [http://lesswrong.com/lw/ik/one_argument_against_an_army/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq07.html">Sequence 07: Against Rationalization</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0070.html">One Argument Against An Army</a></p></td><td><p><i>Next: </i><a href="0115.html">What Evidence Filtered Evidence?</a></p></td></tr></table><p><i>Referenced by: </i><a href="0070.html">One Argument Against An Army</a> &#8226; <a href="0115.html">What Evidence Filtered Evidence?</a> &#8226; <a href="0116.html">Rationalization</a> &#8226; <a href="0118.html">A Rational Argument</a> &#8226; <a href="0119.html">We Change Our Minds Less Often Than We Think</a> &#8226; <a href="0124.html">A Priori</a> &#8226; <a href="0125.html">Priming and Contamination</a> &#8226; <a href="0132.html">Hold Off On Proposing Solutions</a> &#8226; <a href="0148.html">Fake Justification</a> &#8226; <a href="0149.html">An Alien God</a> &#8226; <a href="0154.html">The Tragedy of Group Selectionism</a> &#8226; <a href="0157.html">Fake Optimization Criteria</a> &#8226; <a href="0335.html">Decoherent Essences</a> &#8226; <a href="0390.html">LA-602 vs. RHIC Review</a> &#8226; <a href="0428.html">Math is Subjunctively Objective</a> &#8226; <a href="0436.html">A Genius for Destruction</a> &#8226; <a href="0439.html">Anthropomorphic Optimism</a> &#8226; <a href="0509.html">Crisis of Faith</a> &#8226; <a href="0538.html">Back Up and Ask Whether, Not Why</a> &#8226; <a href="0553.html">The Weak Inside View</a> &#8226; <a href="0573.html">Is That Your True Rejection?</a> &#8226; <a href="0656.html">Formative Youth</a> &#8226; <a href="0674.html">Raising the Sanity Waterline</a> &#8226; <a href="0708.html">That Crisis thing seems pretty useful</a> &#8226; <a href="0724.html">Practical Advice Backed By Deep Theories</a> &#8226; <a href="0806.html">SotW: Avoid Motivated Cognition</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/js/the_bottom_line/">The Bottom Line</a></p></body></html>