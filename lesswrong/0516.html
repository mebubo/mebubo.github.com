<html><head><title>Dark Side Epistemology</title></head><body style="width: 600px; margin: 0 auto; font-family: Georgia, serif;"><h1>Dark Side Epistemology</h1><p><i>Eliezer Yudkowsky, 17 October 2008 11:55PM</i></p><div><p><strong>Followup to</strong>:  <a href="0514.html">Entangled Truths, Contagious Lies</a> [http://lesswrong.com/lw/uw/entangled_truths_contagious_lies/]</p> <p>If you once tell a lie, the truth is ever after your enemy.</p> <p>I have <a href="0514.html">previously spoken</a> [http://lesswrong.com/lw/uw/entangled_truths_contagious_lies/] of the notion that, the truth being entangled, lies are contagious.  If you pick up a pebble from the driveway, and tell a geologist that you found it on a beach&#8212;well, do <em>you</em> know what a geologist knows about rocks?  I don't.  But I can suspect that a water-worn pebble wouldn't look like a droplet of frozen lava from a volcanic eruption.  Do you know where the pebble in your driveway really came from?  Things bear the marks of their places in a lawful universe; in that web, a lie is out of place.  [Edit:  Geologist in comments says that most pebbles in driveways are taken <em>from</em> beaches, so they couldn't tell the difference between a driveway pebble and a beach pebble, but they could tell the difference between a mountain pebble and a driveway/beach pebble.  Case in point...]</p> <p>What sounds like an arbitrary truth to one mind&#8212;one that could easily be replaced by a plausible lie&#8212;might be nailed down by a dozen linkages to the eyes of greater knowledge.  To a creationist, the idea that life was shaped by "intelligent design" instead of "<a href="0149.html">natural selection</a> [http://lesswrong.com/lw/kr/an_alien_god/]" might sound like a sports team to cheer for.  To a biologist, plausibly arguing that an organism was intelligently designed would require lying about almost every facet of the organism.  To plausibly argue that "humans" were intelligently designed, you'd have to lie about the design of the human retina, the architecture of the human brain, the proteins bound together by weak van der Waals forces instead of strong covalent bonds...</p> <p>Or you could just lie about evolutionary theory, which is the path taken by most creationists.  Instead of lying about the connected nodes in the network, they lie about the <em>general</em> laws governing the links.</p> <p>And then to cover <em>that</em> up, they lie about the rules of science&#8212;like what it means to call something a "theory", or what it means for a scientist to say that they are not absolutely certain.</p> <p><a id="more"></a></p> <p>So they pass from lying about specific facts, to lying about general laws, to lying about the rules of reasoning.  To lie about whether humans evolved, you must lie about evolution; and then you have to lie about the rules of science that constrain our understanding of evolution.</p> <p>But how else?  Just as a human would be out of place in a community of <em>actually</em> intelligently designed life forms, and you have to lie about the rules of evolution to make it appear otherwise; so too, beliefs about creationism are themselves out of place in science&#8212;you wouldn't find them in a well-ordered mind any more than you'd find palm trees growing on a glacier.  And so you have to disrupt the barriers that would forbid them.</p> <p>Which brings us to the case of self-deception.</p> <p>A single lie you tell <em>yourself</em> may seem plausible enough, when you don't know any of the rules governing thoughts, or even that there <em>are</em> rules; and the <a href="0385.html">choice</a> [http://lesswrong.com/lw/rb/possibility_and_couldness/] seems as arbitrary as choosing a flavor of ice cream, as isolated as a pebble on the shore...</p> <p>...but then someone calls you on your belief, using the rules of reasoning that <em>they've</em> learned.  They say, "Where's your evidence?"</p> <p>And you say, "What?  Why do I need evidence?"</p> <p>So they say, "In general, beliefs require evidence."</p> <p>This argument, clearly, is <a href="0010.html">a soldier fighting on the other side</a> [http://lesswrong.com/lw/gw/politics_is_the_mindkiller/], which you must defeat.  So you say:  "I disagree!  Not all beliefs require evidence.  In particular, beliefs about dragons don't require evidence.  When it comes to dragons, you're allowed to believe anything you like.  So I don't need evidence to believe there's <a href="0054.html">a dragon in my garage</a> [http://lesswrong.com/lw/i4/belief_in_belief/]."</p> <p>And the one says, "Eh?  You can't just exclude dragons like that.  There's a reason for the rule that beliefs require evidence.  To draw a correct <a href="http://yudkowsky.net/bayes/truth.html">map</a> [http://yudkowsky.net/bayes/truth.html] of the city, <a href="0271.html">you have to walk through the streets</a> [http://lesswrong.com/lw/o5/the_second_law_of_thermodynamics_and_engines_of/] and make lines on paper that correspond to what you see.  That's not an arbitrary legal requirement&#8212;if you sit in your living room and draw lines on the paper at random, the map's going to be wrong.  With <a href="0272.html">extremely high probability</a> [http://lesswrong.com/lw/o6/perpetual_motion_beliefs/].  That's as true of a map of a dragon as it is of anything."</p> <p>So now <em>this,</em> the explanation of <em>why</em> beliefs require evidence, is <em>also</em> an opposing soldier.  So you say:  "Wrong with extremely high probability?  <a href="0215.html">Then there's still a chance, right?</a> [http://lesswrong.com/lw/ml/but_theres_still_a_chance_right/]  I don't have to believe if it's not <a href="0217.html">absolutely certain</a> [http://lesswrong.com/lw/mn/absolute_authority/]."</p> <p>Or maybe you even begin to suspect, yourself, that "beliefs require evidence".  But this threatens a lie you hold precious; so you reject the dawn inside you, push the sun back under the horizon.</p> <p>Or you've previously heard the proverb "beliefs require evidence", and it sounded wise enough, and you endorsed it in public.  But it never quite occurred to you, until someone else brought it to your attention, that this provreb could <em>apply to</em> your belief that there's a dragon in your garage.  So you think fast and say, "The dragon is in a <a href="0058.html">separate magisterium</a> [http://lesswrong.com/lw/i8/religions_claim_to_be_nondisprovable/]."</p> <p>Having false beliefs isn't a good thing, but it doesn't have to be permanently crippling&#8212;if, when you discover your mistake, you get over it.  The dangerous thing is to have a false belief that you <em>believe should be protected as a belief</em>&#8212;a <a href="0054.html">belief-in-belief</a> [http://lesswrong.com/lw/i4/belief_in_belief/], whether or not accompanied by actual belief.</p> <p>A single Lie That Must Be Protected can block someone's progress into advanced rationality.  No, it's not harmless fun.</p> <p>Just as the world itself is <a href="0514.html">more tangled by far</a> [http://lesswrong.com/lw/uw/entangled_truths_contagious_lies/] than it appears on the surface; so too, there are stricter rules of reasoning, constraining belief more strongly, than the untrained would suspect.  The world is woven tightly, governed by general laws, and so are <em>rational</em> beliefs.</p> <p>Think of what it would take to deny evolution or heliocentrism&#8212;all the connected truths and governing laws you wouldn't be allowed to know.  Then you can imagine how a single act of self-deception can block off the whole meta-level of truthseeking, once your mind begins to be threatened by seeing the connections.  Forbidding all the intermediate and higher levels of the rationalist's Art.  Creating, in its stead, a vast complex of anti-law, rules of anti-thought, general justifications for believing the untrue.</p> <p>Steven Kaas <a href="http://www.acceleratingfuture.com/steven/?p=124">said</a> [http://www.acceleratingfuture.com/steven/?p=124], "Promoting less than maximally accurate beliefs is an act of sabotage. Don't do it to anyone unless you'd also slash their tires."  Giving someone a false belief <em>to protect</em>&#8212;convincing them that the <em>belief itself</em> must be defended from any thought that seems to threaten it&#8212;well, you shouldn't do that to someone unless you'd also give them a frontal lobotomy.</p> <p>Once you tell a lie, the truth is your enemy; and every truth connected to that truth, and every ally of truth in general; all of these you must oppose, to protect the lie.  Whether you're lying to others, or to yourself.</p> <p>You have to deny that beliefs require evidence, and then you have to deny that maps should reflect territories, and then you have to deny that truth is a good thing...</p> <p>Thus comes into being the Dark Side.</p> <p>I worry that people aren't aware of it, or aren't sufficiently wary&#8212;that as we wander through our human world, we can expect to encounter <em>systematically</em> bad epistemology.</p> <p>The "how to think" memes floating around, the <a href="0127.html">cached thoughts</a> [http://lesswrong.com/lw/k5/cached_thoughts/] of <a href="0130.html">Deep Wisdom</a> [http://lesswrong.com/lw/k8/how_to_seem_and_be_deep/]&#8212;some of it will be good advice devised by rationalists.  But other notions were invented to protect a lie or self-deception: spawned from the Dark Side.</p> <p>"Everyone has a right to their own opinion."  When you think about it, where was that proverb generated?  Is it something that someone would say in the course of protecting a truth, or in the course of protecting <em>from</em> the truth?  But people don't perk up and say, "Aha!  I sense the presence of the Dark Side!"  As far as I can tell, it's not widely realized that the Dark Side is out there.</p> <p>But how else?  Whether you're deceiving others, or just yourself, the Lie That Must Be Protected will propagate recursively through the network of empirical causality, and the network of general empirical rules, and the rules of reasoning themselves, and the understanding behind those rules.  If there is <em>good</em> epistemology in the world, and also lies or self-deceptions that people are trying to protect, then there will come into existence bad epistemology to counter the good.  We could hardly expect, in this world, to find the Light Side without the Dark Side; there is the Sun, and that which shrinks away and generates a cloaking Shadow.</p> <p>Mind you, these are not necessarily <a href="0050.html"><em>evil</em> people</a> [http://lesswrong.com/lw/i0/are_your_enemies_innately_evil/].  The vast majority who go about repeating the Deep Wisdom are more duped than duplicitous, more self-deceived than deceiving.  I think.</p> <p>And it's surely not my intent to offer you a <a href="0028.html">Fully General Counterargument</a> [http://lesswrong.com/lw/he/knowing_about_biases_can_hurt_people/], so that whenever someone offers you some epistemology you don't like, you say:  "Oh, someone on the Dark Side made that up."  It's one of the rules of the Light Side that you have to refute the proposition for itself, not by accusing its inventor of <a href="0413.html">bad intentions</a> [http://lesswrong.com/lw/s3/the_genetic_fallacy/].</p> <p>But the Dark Side is out there.  Fear is the path that leads to it, and one betrayal can turn you.  Not all who wear robes are either Jedi or fakes; there are also the Sith Lords, masters and unwitting apprentices.  Be warned, be wary.</p> <p>As for listing common memes that were spawned by the Dark Side&#8212;not random false beliefs, mind you, but bad epistemology, the Generic Defenses of Fail&#8212;well, would you care to take a stab at it, dear readers?</p> <p> </p> <p style="text-align:right">Part of the <a href="http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind#Against_Rationalization"><em>Against Rationalization</em></a> [http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind#Against_Rationalization] subsequence of <a href="http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind"><em>How To Actually Change Your Mind</em></a> [http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind]</p> <p style="text-align:right">Next post: "<a href="0688.html">The Sacred Mundane</a> [http://lesswrong.com/lw/57/the_sacred_mundane/]"</p> <p style="text-align:right">Previous post: "<a href="0703.html">Of Lies and Black Swan Blowups</a> [http://lesswrong.com/lw/9a/of_lies_and_black_swan_blowups/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq07.html">Sequence 07: Against Rationalization</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0703.html">Of Lies and Black Swan Blowups</a></p></td><td><p><i>Next: </i><a href="0688.html">The Sacred Mundane</a></p></td></tr></table><p><i>Referenced by: </i><a href="0519.html">Ethical Injunctions</a> &#8226; <a href="0574.html">Artificial Mysterious Intelligence</a> &#8226; <a href="0667.html">Belief in Self-Deception</a> &#8226; <a href="0672.html">Striving to Accept</a> &#8226; <a href="0674.html">Raising the Sanity Waterline</a> &#8226; <a href="0688.html">The Sacred Mundane</a> &#8226; <a href="0703.html">Of Lies and Black Swan Blowups</a> &#8226; <a href="0707.html">Beware of Other-Optimizing</a> &#8226; <a href="0716.html">My Way</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/uy/dark_side_epistemology/">Dark Side Epistemology</a></p></body></html>