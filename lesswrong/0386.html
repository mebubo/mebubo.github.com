<html><head><title>The Ultimate Source</title></head><body><h1>The Ultimate Source</h1><p><i>Eliezer Yudkowsky, 15 June 2008 09:01AM</i></p><div><p><em>This post is part of the </em><em><a href="http://wiki.lesswrong.com/wiki/Free_will_%28solution%29">Solution to "Free Will"</a> [http://wiki.lesswrong.com/wiki/Free_will_%28solution%29].</em><br><strong>Followup to</strong>:  <a href="0375.html">Timeless Control</a> [http://lesswrong.com/lw/r1/timeless_control/], <a href="0385.html">Possibility and Could-ness</a> [http://lesswrong.com/lw/rb/possibility_and_couldness/]</p> <p>Faced with a burning orphanage, you ponder your next action for long agonizing moments, uncertain of what you will do.  Finally, the thought of a burning child overcomes your fear of fire, and you run into the building and haul out a toddler.</p> <p>There's a strain of philosophy which says that this scenario is not sufficient for what they call "free will".  It's not enough for your thoughts, your agonizing, your fear and your empathy, to finally give rise to a judgment.  It's not enough to be the source of your decisions.</p> <p>No, you have to be the <em>ultimate source</em> of your decisions.  If anything else in your past, such as the initial condition of <a href="0374.html">your brain</a> [http://lesswrong.com/lw/r0/thou_art_physics/], fully determined your decision, then clearly <em>you</em> did not.</p> <p>But we <a href="0375.html">already</a> [http://lesswrong.com/lw/r1/timeless_control/] drew this diagram:</p> <p><a href="http://lesswrong.com/static/imported/2008/06/14/fwmarkov_3.png"><img src="0c5443a2.png" title="Fwmarkov_3" height="124" width="219" alt="Fwmarkov_3" border="0"></a> [http://lesswrong.com/static/imported/2008/06/14/fwmarkov_3.png]</p> <p><a id="more"></a></p> <p>As <a href="0375.html">previously discussed</a> [http://lesswrong.com/lw/r1/timeless_control/], the left-hand structure is preferred, even given deterministic physics, because it is more local; and because it is not possible to compute the Future without computing the Present as an intermediate.</p> <p>So it is proper to say, "If-counterfactual the past changed and the present remained the same, the future would remain the same," but not to say, "If the past remained the same and the present changed, the future would remain the same."</p> <p>Are you the true source of your decision to run into the burning orphanage?  What if your parents once told you that it was right for people to help one another?  What if it were the case that, if your parents <em>hadn't</em> told you so, you <em>wouldn't</em> have run into the burning orphanage?  Doesn't that mean that your parents made the decision for you to run into the burning orphanage, rather than <em>you</em>?</p> <p>On several grounds, no:</p> <p>If it were counterfactually the case that your parents hadn't raised you to be good, then it would counterfactually be the case that <a href="0384.html">a different person would stand in front of the burning orphanage</a> [http://lesswrong.com/lw/ra/causality_and_moral_responsibility/].  It would be a different person who arrived at a different decision.  And how can <em>you</em> be anyone other than <em>yourself?</em>  Your parents may have helped pluck <em>you</em> out of Platonic person-space to stand in front of the orphanage, but is that the same as <a href="0384.html">controlling the decision of <em>your</em> point in Platonic person-space</a> [http://lesswrong.com/lw/ra/causality_and_moral_responsibility/]?</p> <p>Or:  If we imagine that your parents had raised you differently, and yet somehow, exactly the same brain had ended up standing in front of the orphanage, then the same action would have resulted.  Your present self and brain, <a href="0191.html">screens</a> [http://lesswrong.com/lw/lx/argument_screens_off_authority/] <a href="0365.html">off</a> [http://lesswrong.com/lw/qr/timeless_causality/] the influence of your parents - this is true even if the past fully determines the future.</p> <p>But above all:  There is no single true cause of an event.  Causality proceeds in directed acyclic networks.  I see no good way, within the modern understanding of causality, to translate the idea that an event must have a <em>single</em> cause.  Every asteroid large enough to reach Earth's surface could have prevented the assassination of John F. Kennedy, if it had been in the right place to strike Lee Harvey Oswald.  There can be any number of prior events, which if they had counterfactually occurred differently, would have changed the present.  After spending even a small amount of time working with the directed acyclic graphs of causality, the idea that a decision can only have a single true source, sounds just plain odd.</p> <p>So there is no contradiction between "My decision caused me to run into the burning orphanage", "My upbringing caused me to run into the burning orphanage", "Natural selection built me in such fashion that I ran into the burning orphanage", and so on.  Events have long causal histories, not single true causes.</p> <p>Knowing the intuitions behind "free will", we can construct other intuition pumps.  The feeling of freedom comes from the combination of not knowing which decision you'll make, and of having the options labeled as <a href="0385.html">primitively reachable</a> [http://lesswrong.com/lw/rb/possibility_and_couldness/] in your planning algorithm.  So if we wanted to pump someone's intuition against the argument "Reading <a href="0178.html">superhero</a> [http://lesswrong.com/lw/lk/superhero_bias/] comics as a child, is the true source of your decision to rescue those toddlers", we reply:</p> <p>"But even if you visualize Batman running into the burning building, you might not immediately know which choice you'll make (standard source of feeling free); and you could still take either action <em>if you wanted to</em> (note correctly phrased counterfactual and appeal to primitive reachability).  The comic-book authors didn't visualize this exact scenario or its exact consequences; they didn't agonize about it (they didn't run the decision algorithm you're running).  So the comic-book authors did not make this decision for you.  Though they may have contributed to it being <em>you</em> who stands before the burning orphanage and chooses, rather than someone else."</p> <p>How could anyone possibly believe that they are the ultimate and only source of their actions?  Do they think they have no past?</p> <p>If we, for a moment, forget that we know all this that we know, we can see what a believer in "ultimate free will" might say to the comic-book argument:  "Yes, I read comic books as a kid, but the comic books didn't reach into my brain and <em>force</em> me to run into the orphanage.  Other people read comic books and don't become more heroic.  <em>I</em> chose it."</p> <p>Let's say that you're confronting some complicated moral dilemma that, unlike a burning orphanage, gives you some time to agonize - say, thirty minutes; that <a href="0347.html">ought to be enough time</a> [http://lesswrong.com/lw/q9/the_failures_of_eld_science/].</p> <p>You might find, looking over each factor one by one, that none of them seem <em>perfectly decisive</em> - to force a decision entirely on their own.</p> <p>You might incorrectly conclude that if no one factor is decisive, all of them together can't be decisive, and that there's some extra perfectly decisive thing that is your free will.</p> <p>Looking back on your decision to run into a burning orphanage, you might reason, "But I <em>could</em> have stayed out of that orphanage, <em>if</em> I'd needed to run into the building next door in order to prevent a nuclear war.  Clearly, burning orphanages don't <em>compel</em> me to enter them.  Therefore, I must have made an <em>extra choice</em> to <em>allow</em> my empathy with children to govern my actions.  My nature does not command me, unless <em>I choose</em> to let it do so."</p> <p>Well, yes, your empathy with children could have been overridden by your desire to prevent nuclear war, if (counterfactual) that had been at stake.</p> <p>This is actually a <a href="0304.html">hand-vs.-fingers</a> [http://lesswrong.com/lw/p2/hand_vs_fingers/] confusion; all of the factors in your decision, plus the dynamics governing their combination, <em>are</em> your will.  But if you don't realize this, then it will seem like no individual part of yourself has "control" of you, from which you will incorrectly conclude that there is something beyond their sum that is the ultimate source of control.</p> <p>But this is like reasoning that if no single neuron in your brain could control your choice in spite of every other neuron, then all your neurons together must not control your choice either.</p> <p>Whenever you reflect, and focus your whole attention down upon a single part of yourself, it will seem that the part does not make your decision, that it is not <em>you,</em> because the you-that-sees could choose to override it (it is a primitively reachable option).  But when all of the parts of yourself that you see, and all the parts that you do not see, are added up together, they <em>are you;</em> they are even that which reflects upon itself.</p> <p>So now we have the intuitions that:</p> <ul> <li>The sensation of the <a href="0385.html">primitive reachability</a> [http://lesswrong.com/lw/rb/possibility_and_couldness/] of actions, is incompatible with their physical determinism</li> <li>A decision can only have a single "true" source; what is <a href="0375.html">determined</a> [http://lesswrong.com/lw/r1/timeless_control/] by the past cannot be determined by the present</li> <li>If no single psychological factor you can see is perfectly responsible, then there must be an additional something that <em>is</em> perfectly responsible</li> <li>When you reflect upon any single factor of your decision, you see that <em>you</em> could override it, and this "you" is the <em>extra additional</em> something that is perfectly responsible</li> </ul> <p>The combination of these intuitions has led philosophy into strange veins indeed.</p> <p>I once saw one such vein described neatly in terms of "Author" control and "Author*" control, though I can't seem to find or look up the paper.</p> <p>Consider the control that an Author has over the characters in their books.  Say, the sort of control that I have over <a href="0303.html">Brennan</a> [http://lesswrong.com/lw/p1/initiation_ceremony/].</p> <p>By an act of will, I can make Brennan decide to step off a cliff.  I can also, by an act of will, control Brennan's inner nature; I can make him more or less heroic, empathic, kindly, wise, angry, or sorrowful.  I can even make Brennan stupider, or smarter up to the limits of my own intelligence.  I am entirely responsible for Brennan's past, both the good parts and the bad parts; I decided everything that would happen to him, over the course of his whole life.</p> <p>So you might think that having Author-like control over ourselves - which we obviously <em>don't</em> - would at least be <em>sufficient</em> for free will.</p> <p>But wait!  <em>Why</em> did I decide that Brennan would decide to join the Bayesian Conspiracy?  Well, it <em>is</em> in character for Brennan to do so, at that stage of his life.  But if this had not been true of Brennan, I would have chosen a different character that <em>would</em> join the Bayesian Conspiracy, because I wanted to write about the <em>beisutsukai.</em>  Could I have chosen not to want to write about the Bayesian Conspiracy?</p> <p>To have Author* self-control is not only have <em>control</em> over your entire existence and past, but to have <em>initially written</em> your entire existence and past, without having been <em>previously</em> influenced by it - the way that I invented Brennan's life without having previously lived it.  To choose <em>yourself</em> into existence this way, would be Author* control.  (If I remember the paper correctly.)</p> <p>Paradoxical?  Yes, of course.  The point of the paper was that Author* control is what <em>would</em> be required to be the "ultimate source of your own actions", the way some philosophers seemed to define it.</p> <p>I don't see how you could manage Author* self-control even <em>with</em> a time machine.</p> <p>I could write a story in which Jane went back in time and created herself from raw atoms using her knowledge of Artificial Intelligence, and then Jane oversaw and orchestrated her own entire childhood up to the point she went back in time.  <em>Within</em> the story, Jane would have control over her existence and past - but not without having been "previously" influenced by them.  And I, as an outside author, would have chosen <em>which</em> Jane went back in time and recreated herself.  If I needed Jane to be a bartender, she would be one.</p> <p>Even in the unlikely event that, in real life, it is possible to create closed timelike curves, and we find that a self-recreating Jane emerges from the time machine without benefit of human intervention, that Jane <em>still</em> would not have Author* control.  She would not have written her own life without having been "previously" influenced by it.  She might <em>preserve</em> her personality; but would she have <em>originally</em> created it?  And you could stand outside time and look at the cycle, and ask, "Why is this cycle here?"  The answer to that would presumably lie within the laws of physics, rather than Jane having written the laws of physics to create herself.</p> <p>And you run into exactly the same trouble, if you try to have yourself be the sole ultimate Author* source of even a single particular decision made by you - which is to say it was decided by your beliefs, inculcated morals, evolved emotions, etc. - which is to say your brain calculated it - which is to say physics determined it.  You can't have Author* control over one single decision, even with a time machine.</p> <p>So a philosopher would say:  Either we don't have free will, or free will doesn't require being the sole ultimate Author* source of your own decisions, QED.</p> <p>I have a somewhat different perspective, and say:  Your sensation of freely choosing, clearly does not provide you with trustworthy information to the effect that you are the 'ultimate and only source' of your own actions.  This being the case, why attempt to <em>interpret</em> the sensation as having such a <a href="0256.html">meaning</a> [http://lesswrong.com/lw/nq/feel_the_meaning/], and then say that the sensation is <em>false</em>?</p> <p>Surely, if we want to know which meaning to attach to a confusing sensation, we should <a href="0283.html">ask why the sensation is there</a> [http://lesswrong.com/lw/oh/righting_a_wrong_question/], and under what conditions it is present or absent.</p> <p>Then I could say something like:  "This sensation of freedom occurs when I believe that I can carry out, without interference, each of multiple actions, such that I do not yet know which of them I will take, but I am in the process of judging their consequences according to my emotions and morals."</p> <p>This is a condition that can fail in the presence of jail cells, or a decision so overwhelmingly forced that I never perceived any uncertainty about it.</p> <p>There - <em>now</em> my sensation of freedom indicates something coherent; and most of the time, I will have no reason to doubt the sensation's veracity.  I have no problems about saying that I have "free will" <a href="0279.html">appropriately defined</a> [http://lesswrong.com/lw/od/37_ways_that_words_can_be_wrong/]; so long as I am out of jail, uncertain of my own future decision, and living in a lawful universe that gave me emotions and morals whose interaction determines my choices.</p> <p>Certainly I do not "lack free will" if that means I am in jail, or never uncertain of my future decisions, or in a brain-state where my emotions and morals fail to determine my actions in the usual way.</p> <p>Usually I don't talk about "free will" at all, of course!  That would be asking for trouble - no, <em>begging</em> for trouble - since the other person doesn't know about my redefinition.  The <em>phrase</em> means far too many things to far too many people, and you could make a good case for tossing it out the window.</p> <p>But I generally prefer to reinterpret my <em>sensations</em> sensibly, as opposed to refuting a confused interpretation and then calling the sensation "false".</p></div> <hr><p><i>Referenced by: </i><a href="0385.html">Possibility and Could-ness</a> &#8226; <a href="0387.html">Passing the Recursive Buck</a> &#8226; <a href="0388.html">Grasping Slippery Things</a> &#8226; <a href="0389.html">Ghosts in the Machine</a> &#8226; <a href="0391.html">Heading Toward Morality</a> &#8226; <a href="0397.html">No Universally Compelling Arguments</a> &#8226; <a href="0409.html">Will As Thou Wilt</a> &#8226; <a href="0410.html">Where Recursive Justification Hits Bottom</a> &#8226; <a href="0415.html">Rebelling Within Nature</a> &#8226; <a href="0431.html">Setting Up Metaethics</a> &#8226; <a href="0432.html">The Meaning of Right</a> &#8226; <a href="0443.html">Inseparably Right; or, Joy in the Merely Good</a> &#8226; <a href="0540.html">Lawful Creativity</a> &#8226; <a href="0589.html">Living By Your Own Strength</a> &#8226; <a href="0595.html">Nonsentient Optimizers</a> &#8226; <a href="0601.html">Free to Optimize</a> &#8226; <a href="0629.html">Value is Fragile</a> &#8226; <a href="0656.html">Formative Youth</a> &#8226; <a href="0704.html">Whining-Based Communities</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/rc/the_ultimate_source/">The Ultimate Source</a></p></body></html>