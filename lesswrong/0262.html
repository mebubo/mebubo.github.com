<html><head><title>Fallacies of Compression</title></head><body style="width: 600px; margin: 0 auto; font-family: Georgia, serif;"><h1>Fallacies of Compression</h1><p><i>Eliezer Yudkowsky, 17 February 2008 06:51PM</i></p><div><p><strong>Followup to</strong>:  <a href="0261.html">Replace the Symbol with the Substance</a> [http://lesswrong.com/lw/nv/replace_the_symbol_with_the_substance/]</p> <p>"The map is not the territory," as the saying goes.  The only life-size, atomically detailed, 100% accurate map of California is California.  But California has important regularities, such as the shape of its highways, that can be described using vastly less information&#8212;not to mention vastly less <em>physical material</em>&#8212;than it would take to describe every atom within the state borders.  Hence the <em>other</em> saying:  "The map is not the territory, but you can't fold up the territory and put it in your glove compartment."</p> <p>A paper map of California, at a scale of 10 kilometers to 1 centimeter (a million to one), doesn't have room to show the distinct position of two fallen leaves lying a centimeter apart on the sidewalk.  Even if the map tried to show the leaves, the leaves would appear as the same point on the map; or rather the map would need a feature size of 10 nanometers, which is a finer resolution than most book printers handle, not to mention human eyes.</p> <p>Reality is very large&#8212;just the part we can see is billions of lightyears across.  But your map of reality is written on a few pounds of neurons, folded up to fit inside your skull.  I don't mean to be insulting, but your skull is tiny, comparatively speaking.</p> <p>Inevitably, then, certain things that are distinct in reality, will be compressed into the same point on your map.</p> <p>But what this <a href="0254.html">feels like from inside</a> [http://lesswrong.com/lw/no/how_an_algorithm_feels_from_inside/] is not that you say, "Oh, look, I'm compressing two things into one point on my map."  What it <em>feels </em>like from inside is that there is just <em>one</em> thing, and you are seeing it.</p> <p><a id="more"></a></p> <p>A sufficiently young child, or a sufficiently ancient Greek philosopher, would not know that there were such things as "acoustic vibrations" or "auditory experiences".  There would just be a single thing that happened when a tree fell; a single event called "sound".</p> <p>To realize that there are <em>two</em> distinct events, underlying <em>one</em> point on your map, is an essentially <em>scientific</em> challenge&#8212;a big, difficult scientific challenge.</p> <p>Sometimes fallacies of compression result from confusing two known things under the same label&#8212;you know about acoustic vibrations, and you know about auditory processing in brains, but you call them both "sound" and so confuse yourself.  But the more dangerous fallacy of compression arises from having <em>no idea whatsoever</em> that two distinct entities even <em>exist</em>.  There is just one mental folder in the filing system, labeled "sound", and everything thought about "sound" drops into that one folder.  It's not that there are two folders with the same label; there's just a single folder.  By default, the map is compressed; why would the brain create two mental buckets where one would serve?</p> <p>Or think of a mystery novel in which the detective's critical insight is that one of the suspects has an identical twin.  In the course of the detective's ordinary work, his job is just to observe that Carol is wearing red, that she has black hair, that her sandals are leather&#8212;but all these are <em>facts about</em> Carol.  It's easy enough to question an individual fact, like WearsRed(Carol) or BlackHair(Carol).  Maybe BlackHair(Carol) is false.  Maybe Carol dyes her hair.  Maybe BrownHair(Carol).  But it takes a subtler detective to wonder if the Carol in WearsRed(Carol) and BlackHair(Carol)&#8212;the Carol file into which his observations drop&#8212;should be split into <em>two</em> files.  Maybe there are two Carols, so that the Carol who wore red is not the same woman as the Carol who had black hair.</p> <p>Here it is the very act of <em>creating</em> two different buckets that is the stroke of genius insight.  'Tis easier to question one's facts than one's ontology.</p> <p>The map of reality contained in a human brain, unlike a paper map of California, can expand dynamically when we write down more detailed descriptions.  But what this feels like from inside is not so much zooming in on a map, as fissioning an indivisible atom&#8212;taking <em>one thing</em> (it felt like one thing) and splitting it into two or more things.</p> <p>Often this manifests in the creation of new words, like "acoustic vibrations" and "auditory experiences" instead of just "sound".  Something about creating the new name seems to allocate the new bucket.  The detective is liable to start calling one of his suspects "Carol-2" or "the Other Carol" almost as soon as he realizes that there are two of them.</p> <p>But expanding the map isn't always as simple as generating new city names.  It is a stroke of scientific insight to realize that such things as acoustic vibrations, or auditory experiences, even <em>exist.</em></p> <p>The obvious modern-day illustration would be words like "intelligence" or "consciousness".  Every now and then one sees a press release claiming that a research has "explained consciousness" because a team of neurologists investigated a 40Hz electrical rhythm that might have something to do with cross-modality binding of sensory information, or because they investigated the reticular activating system that keeps humans awake.  That's an extreme example, and the usual failures are more subtle, but they are of the same kind.  The part of "consciousness" that people find most interesting is reflectivity, self-awareness, realizing that the person I see in the mirror is "me"; that and the hard problem of subjective experience as distinguished by Chalmers.  We also label "conscious" the state of being awake, rather than asleep, in our daily cycle.  But they are all different concepts going under the same name, and the underlying phenomena are different scientific puzzles.  You can explain being awake without explaining reflectivity or subjectivity.</p> <p>Fallacies of compression also underlie the bait-and-switch technique in philosophy&#8212;you argue about "consciousness" under one definition (like the ability to think about thinking) and then apply the conclusions to "consciousness" under a different definition (like subjectivity).  Of course it may be that the two are the same thing, but if so, genuinely <em>understanding</em> this fact would require <em>first</em> a conceptual split and <em>then</em> a genius stroke of reunification.</p> <p>Expanding your map is (I say again) a <em>scientific</em> challenge: part of the art of science, the skill of inquiring into the world.  (And of course you cannot solve a scientific challenge by appealing to dictionaries, nor master a complex skill of inquiry by saying "I can define a word any way I like".)  Where you see a single confusing thing, with protean and self-contradictory attributes, it is a good guess that your map is cramming too much into one point&#8212;you need to pry it apart and allocate some new buckets.  This is not like <em>defining</em> the single thing you see, but it <em>does</em> often follow from figuring out how to talk about the thing without using a single mental handle.</p> <p>So the skill of prying apart the map is linked to the <a href="0261.html">rationalist version</a> [http://lesswrong.com/lw/nv/replace_the_symbol_with_the_substance/] of <a href="0260.html">Taboo</a> [http://lesswrong.com/lw/nu/taboo_your_words/], and to the wise use of words; because words often represent the points on our map, the labels under which we file our propositions and the buckets into which we drop our information.  Avoiding a single word, or allocating new ones, is often part of the skill of expanding the map.</p> <p> </p> <p style="text-align:right">Part of the sequence <a href="http://wiki.lesswrong.com/wiki/A_Human%27s_Guide_to_Words"><em>A Human's Guide to Words</em></a> [http://wiki.lesswrong.com/wiki/A_Human%27s_Guide_to_Words]</p> <p style="text-align:right">Next post: "<a href="0263.html">Categorizing Has Consequences</a> [http://lesswrong.com/lw/nx/categorizing_has_consequences]"</p> <p style="text-align:right">Previous post: "<a href="0261.html">Replace the Symbol with the Substance</a> [http://lesswrong.com/lw/nv/replace_the_symbol_with_the_substance/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq11.html">Sequence 11: A Human's Guide to Words</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0261.html">Replace the Symbol with the Substance</a></p></td><td><p><i>Next: </i><a href="0263.html">Categorizing Has Consequences</a></p></td></tr></table><p><i>Referenced by: </i><a href="0261.html">Replace the Symbol with the Substance</a> &#8226; <a href="0263.html">Categorizing Has Consequences</a> &#8226; <a href="0266.html">Where to Draw the Boundary?</a> &#8226; <a href="0278.html">Variable Question Fallacies</a> &#8226; <a href="0279.html">37 Ways That Words Can Be Wrong</a> &#8226; <a href="0286.html">The Quotation is not the Referent</a> &#8226; <a href="0311.html">The Generalized Anti-Zombie Principle</a> &#8226; <a href="0372.html">Why Quantum?</a> &#8226; <a href="0416.html">Probability is Subjectively Objective</a> &#8226; <a href="0442.html">Morality as Fixed Computation</a> &#8226; <a href="0460.html">Three Fallacies of Teleology</a> &#8226; <a href="0670.html">Moore's Paradox</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/nw/fallacies_of_compression/">Fallacies of Compression</a></p></body></html>