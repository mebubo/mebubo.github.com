<html><head><title>Angry Atoms</title></head><body style="width: 600px; margin: 0 auto; font-family: Georgia, serif;"><h1>Angry Atoms</h1><p><i>Eliezer Yudkowsky, 31 March 2008 12:28AM</i></p><div><p><strong>Followup to</strong>:  <a href="0304.html">Hand vs. Fingers</a> [http://lesswrong.com/lw/p2/hand_vs_fingers/]</p> <p>Fundamental physics&#8212;quarks 'n stuff&#8212;is far removed from the levels we can <a href="0304.html"><em>see,</em></a> [http://lesswrong.com/lw/p2/hand_vs_fingers/] like hands and fingers.  At best, you can know how to replicate the experiments which show that your hand (like everything else) is composed of quarks, and you may know how to derive a few equations for things like atoms and electron clouds and molecules.</p> <p>At worst, the existence of quarks beneath your hand may just be something you were <a href="0076.html">told</a> [http://lesswrong.com/lw/iq/guessing_the_teachers_password/].  In which case it's questionable in one what sense you can be said to "know" it at all, even if you repeat back the same word "quark" that a physicist would use to convey knowledge to another physicist.</p> <p>Either way, you can't actually <em>see</em> the identity between levels&#8212;no one has a brain large enough to <em>visualize</em> avogadros of quarks and recognize a hand-pattern in them.</p> <p>But we at least understand what hands <em>do.</em>  Hands push on things, exert forces on them.  When we're told about atoms, we visualize little billiard balls bumping into each other.  This makes it seem obvious that "atoms" can push on things too, by bumping into them.</p> <p>Now this notion of atoms is not quite correct.  But so far as <em>human imagination</em> goes, it's relatively easy to imagine our hand being made up of a little galaxy of swirling billiard balls, pushing on things when our "fingers" touch them.  Democritus imagined this 2400 years ago, and there was a time, roughly <a href="http://en.wikipedia.org/wiki/Atom">1803-1922</a> [http://en.wikipedia.org/wiki/Atom], when Science thought he was right.</p> <p>But what about, say, anger?</p> <p>How could little billiard balls be angry?  Tiny frowny faces on the billiard balls?</p> <p><a id="more"></a></p> <p>Put yourself in the shoes of, say, a hunter-gatherer&#8212;someone who may not even have a notion of writing, let alone the notion of using base matter to perform computations&#8212;someone who has no idea that such a thing as neurons exist.  Then you can imagine the <em>functional</em> gap that your ancestors might have perceived between billiard balls and "Grrr!  Aaarg!"</p> <p>Forget about subjective experience for the moment, and consider the sheer <em>behavioral</em> gap between anger and billiard balls.  The difference between what little billiard balls <em>do,</em> and what anger makes people <em>do.</em> Anger can make people raise their fists and hit someone&#8212;or say snide things behind their backs&#8212;or plant scorpions in their tents at night.  Billiard balls just push on things.</p> <p>Try to put yourself in the shoes of the hunter-gatherer who's never had the "Aha!" of information-processing.  Try to avoid <a href="0085.html">hindsight bias</a> [http://lesswrong.com/lw/iz/failing_to_learn_from_history/] about things like neurons and computers.  Only then will you be able to see the uncrossable explanatory gap:</p> <p>How can you explain angry behavior in terms of billiard balls?</p> <p>Well, the <em>obvious</em> materialist conjecture is that the little billiard balls push on your arm and make you hit someone, or push on your tongue so that insults come out.</p> <p>But how do the little billiard balls know how to do this&#8212;or how to guide your tongue and fingers through long-term plots&#8212;if they aren't angry themselves?</p> <p>And besides, if you're not seduced by&#8212;gasp!&#8212;scientism, you can see from a first-person perspective that this explanation is obviously false.  Atoms can push on your arm, but they can't make you <em>want</em> anything.</p> <p>Someone may point out that drinking wine can make you angry.  But who says that wine is made exclusively of little billiard balls?  Maybe wine just contains a potency of angerness.</p> <p>Clearly, reductionism is just a flawed notion.</p> <p>(The novice goes astray and says "The art failed me"; the master goes astray and says "I failed my art.")</p> <p>What does it take to cross this gap?  It's not just the idea of "neurons" that "process information"&#8212;if you say only this and nothing more, it just inserts a magical, unexplained level-crossing rule into your model, where you go from billiards to thoughts.</p> <p>But an Artificial Intelligence programmer who knows how to create a chess-playing program out of base matter, has taken a <em>genuine</em> step toward crossing the gap.  If you understand concepts like <a href="0162.html">consequentialism</a> [http://lesswrong.com/lw/l4/terminal_values_and_instrumental_values/], backward chaining, utility functions, and <a href="http://en.wikipedia.org/wiki/Minimax">search trees</a> [http://en.wikipedia.org/wiki/Minimax], you can make merely causal/mechanical systems compute plans.</p> <p>The trick goes something like this:  For each possible chess move, compute the moves your opponent could make, then your responses to those moves, and so on; evaluate the furthest position you can see using some local algorithm (you might simply count up the material); then trace back using <a href="http://en.wikipedia.org/wiki/Minimax">minimax</a> [http://en.wikipedia.org/wiki/Minimax] to find the best move on the current board; then make that move.</p> <p>More generally:  If you have chains of causality inside the mind that have a kind of mapping&#8212;a mirror, an echo&#8212;to what goes on in the environment, then you can run a utility function over the end products of imagination, and find an action that achieves something which the utility function rates highly, and output that action.  It is not necessary for the chains of causality inside the mind, that are similar to the environment, to be made out of billiard balls that have little auras of intentionality.  Deep Blue's transistors do not need little chess pieces carved on them, in order to work.  See also <a href="http://yudkowsky.net/bayes/truth.html">The Simple Truth</a> [http://yudkowsky.net/bayes/truth.html].</p> <p>All this is still tremendously oversimplified, but it should, at least, reduce the apparent length of the gap.  If you can understand all that, you can see how a planner built out of base matter can be influenced by alcohol to output more angry behaviors.  The billiard balls in the alcohol push on the billiard balls making up the utility function.</p> <p>But even if you know how to write small AIs, you can't <em>visualize</em> the level-crossing between transistors and chess.  There are too many transistors, and too many moves to check.</p> <p>Likewise, even if you knew all the facts of neurology, you would not be able to <em>visualize</em> the level-crossing between neurons and anger&#8212;let alone the level-crossing between atoms and anger.  Not the way you can visualize a hand consisting of fingers, thumb, and palm.</p> <p>And suppose a cognitive scientist just <a href="0291.html">flatly tells</a> [http://lesswrong.com/lw/op/fake_reductionism/] you "Anger is hormones"?  Even if you repeat back the words, it doesn't mean you've crossed the gap.  You may <a href="0054.html">believe you believe it</a> [http://lesswrong.com/lw/i4/belief_in_belief/], but that's not the same as understanding what little billiard balls have to do with wanting to hit someone.</p> <p>So you come up with interpretations like, "Anger is <em>mere</em> hormones, it's caused by little molecules, so it must not be justified in any moral sense&#8212;<em>that's</em> why you should learn to control your anger."</p> <p>Or, "There isn't really any such thing as anger&#8212;it's an illusion, a quotation with no referent, like a mirage of water in the desert, or looking in the garage for a dragon and not finding one."</p> <p>These are both tough pills to swallow (not that you <em>should</em> swallow them) and so it is a good easier to <a href="0077.html">profess</a> [http://lesswrong.com/lw/ir/science_as_attire/] them than to believe them.</p> <p>I think this is what non-reductionists/non-materialists think they are criticizing when they criticize reductive materialism.</p> <p>But materialism isn't that easy.  It's not as cheap as saying, "Anger is made out of atoms&#8212;there, now I'm done."  That wouldn't explain how to get from billiard balls to hitting.  You need the specific insights of computation, consequentialism, and search trees before you can start to close the explanatory gap.</p> <p>All this was a relatively easy example <em>by modern standards,</em> because I restricted myself to talking about angry <em>behaviors.</em>  Talking about outputs doesn't require you to appreciate <a href="0254.html">how an algorithm feels from inside</a> [http://lesswrong.com/lw/no/how_an_algorithm_feels_from_inside/] (cross a first-person/third-person gap) or <a href="0282.html">dissolve a wrong question</a> [http://lesswrong.com/lw/og/wrong_questions/] (untangle places where the interior of your own mind runs skew to reality).</p> <p>Going from material substances that bend and break, burn and fall, push and shove, to angry <em>behavior,</em> is just a practice problem by the standards of modern philosophy.  But it is an <em>important</em> practice problem.  It can only be fully appreciated, if you realize how <em>hard</em> it would have been to solve before writing was invented.  There was once an explanatory gap here&#8212;though it may not seem that way in <a href="0085.html">hindsight</a> [http://lesswrong.com/lw/iz/failing_to_learn_from_history/], now that it's been bridged for generations.</p> <p>Explanatory gaps can be crossed, if you accept help from science, and don't trust the view from the interior of your own mind.</p> <p> </p> <p style="text-align:right">Part of the sequence <a href="http://wiki.lesswrong.com/wiki/Reductionism_%28sequence%29"><em>Reductionism</em></a> [http://wiki.lesswrong.com/wiki/Reductionism_%28sequence%29]</p> <p style="text-align:right">Next post: "<a href="0306.html">Heat vs. Motion</a> [http://lesswrong.com/lw/p4/heat_vs_motion/]"</p> <p style="text-align:right">Previous post: "<a href="0304.html">Hand vs. Fingers</a> [http://lesswrong.com/lw/p2/hand_vs_fingers/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq12.html">Sequence 12: Reductionism</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0304.html">Hand vs. Fingers</a></p></td><td><p><i>Next: </i><a href="0306.html">Heat vs. Motion</a></p></td></tr></table><p><i>Referenced by: </i><a href="0304.html">Hand vs. Fingers</a> &#8226; <a href="0306.html">Heat vs. Motion</a> &#8226; <a href="0339.html">Bell's Theorem: No EPR "Reality"</a> &#8226; <a href="0368.html">A Premature Word on AI</a> &#8226; <a href="0374.html">Thou Art Physics</a> &#8226; <a href="0431.html">Setting Up Metaethics</a> &#8226; <a href="0451.html">When Anthropomorphism Became Stupid</a> &#8226; <a href="0674.html">Raising the Sanity Waterline</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/p3/angry_atoms/">Angry Atoms</a></p></body></html>