<html><head><title>Is Morality Given?</title></head><body style="width: 600px; margin: 0 auto; font-family: Georgia, serif;"><h1>Is Morality Given?</h1><p><i>Eliezer Yudkowsky, 06 July 2008 08:12AM</i></p><div><p><strong>Continuation of</strong>:  <a href="0407.html">Is Morality Preference?</a> [http://lesswrong.com/lw/rx/is_morality_preference/]</p> <p>(Disclaimer:  Neither Subhan nor Obert represent my own position on morality; rather they represent different sides of the <em>questions</em> I hope to answer.)</p> <p>Subhan:  "What is this 'morality' stuff, if it is <em>not</em> a preference within you?"</p> <p>Obert:  "I know that my mere wants, don't change what is <em>right;</em> but I don't claim to have absolute knowledge of what is right&#8212;"</p> <p>Subhan:  "You're not escaping that easily!  How does a universe in which murder is wrong, differ from a universe in which murder is right?  How can you detect the difference experimentally?  If the answer to that is 'No', then how does any human being come to <em>know</em> that murder is wrong?"</p> <p>Obert:  "Am I allowed to say 'I don't know'?"</p> <p>Subhan:  "No.  You believe <em>now</em> that murder is wrong.  You must believe you <em>already</em> have evidence and you should be able to present it <em>now.</em>"</p> <p>Obert:  "That's too strict!  It's like saying to a hunter-gatherer, 'Why is the sky blue?' and expecting an immediate answer."</p> <p>Subhan:  "No, it's like saying to a hunter-gatherer:  Why do you <em>believe</em> the sky is blue?"</p> <p>Obert:  "Because it seems blue, just as murder seems wrong.  Just don't ask me what the sky is, or how I can see it."</p> <p>Subhan:  "But&#8212;aren't we discussing the nature of morality?"</p> <p>Obert:  "That, I confess, is not one of my strong points.  I specialize in plain old morality.  And as a matter of morality, I know that I can't make murder <em>right</em> just by wanting to kill someone."</p> <p><a id="more"></a></p> <p>Subhan:  "But if you <em>wanted</em> to kill someone, you would say, 'I know murdering this guy is right, and I couldn't make it wrong just by not wanting to do it.'"</p> <p>Obert:  "Then, if I said that, I would be wrong.  That's common moral sense, right?"</p> <p>Subhan:  "Argh!  It's difficult to even argue with you, since you won't tell me exactly what you think morality is made of, or where you're getting all these amazing moral truths&#8212;"</p> <p>Obert:  "Well, I do regret having to frustrate you.  But it's more important that I <em>act morally,</em> than that I come up with amazing new theories of the <em>nature</em> of morality.  I don't claim that my strong point is in explaining the fundamental nature of morality.  Rather, my strong point is coming up with theories of morality that give normal moral answers to questions like, 'If you feel like killing someone, does that make it right to do so?'  The common-sense answer is 'No' and I really see no reason to adopt a theory that makes the answer 'Yes'.  Adding up to moral normality&#8212;<em>that</em> is my theory's strong point."</p> <p>Subhan:  "Okay... look.  You say that, if you believed it was right to murder someone, you would be <em>wrong.</em>"</p> <p>Obert:  "Yes, of course!  And just to cut off any quibbles, we'll specify that we're not talking about going back in time and shooting Stalin, but rather, stalking some innocent bystander through a dark alley and slitting their throat for no other reason but my own enjoyment.  That's <em>wrong</em>."</p> <p>Subhan:  "And <em>anyone</em> who says murder is right, is mistaken."</p> <p>Obert:  "Yes."</p> <p>Subhan:  "Suppose there's an alien species somewhere in the vastness of the multiverse, who evolved from carnivores.  In fact, through most of their evolutionary history, they were cannibals.  They've evolved different emotions from us, and they have no concept that murder is wrong&#8212;"</p> <p>Obert:  "Why doesn't their society fall apart in an orgy of mutual killing?"</p> <p>Subhan:  "That doesn't matter for our purposes of theoretical metaethical investigation.  But since you ask, we'll suppose that the Space Cannibals have a strong sense of <em>honor</em>&#8212;they won't kill someone they promise not to kill; they have a very strong idea that violating an oath is wrong.  Their society holds together on that basis, and on the basis of vengeance contracts with private assassination companies.  But so far as the actual killing is concerned, the aliens just think it's fun.  When someone gets executed for, say, driving through a traffic light, there's a bidding war for the rights to personally tear out the offender's throat."</p> <p>Obert:  "Okay... where is this going?"</p> <p>Subhan:  "I'm proposing that the Space Cannibals not only have no sense that murder is wrong&#8212;indeed, they have a positive sense that killing is an important part of life&#8212;but moreover, there's no path of arguments you could use to <em>persuade</em> a Space Cannibal of your view that murder is wrong.  There's no fact the aliens can learn, and no chain of reasoning they can discover, which will <em>ever</em> cause them to conclude that murder is a moral wrong.  Nor is there any way to persuade them that they <em>should</em> modify themselves to perceive things differently."</p> <p>Obert:  "I'm not sure I believe <em>that's</em> possible&#8212;"</p> <p>Subhan:  "Then you believe in <a href="0397.html">universally compelling arguments</a> [http://lesswrong.com/lw/rn/no_universally_compelling_arguments/] processed by a <a href="0389.html">ghost in the machine</a> [http://lesswrong.com/lw/rf/ghosts_in_the_machine/].  For every <a href="0396.html">possible mind</a> [http://lesswrong.com/lw/rm/the_design_space_of_mindsingeneral/] whose utility function assigns <a href="0162.html">terminal value</a> [http://lesswrong.com/lw/l4/terminal_values_and_instrumental_values/] +1, <a href="0396.html">mind design space</a> [http://lesswrong.com/lw/rm/the_design_space_of_mindsingeneral/] contains an equal and opposite mind whose utility function assigns terminal value&#8212;1.  A mind is a physical device and you can't have a little blue woman pop out of nowhere and make it say 1 when the physics calls for it to say 0."</p> <p>Obert:  "Suppose I were to concede this.  Then?"</p> <p>Subhan:  "Then it's possible to have an alien species that believes murder is not wrong, and moreover, will continue to believe this given knowledge of every possible fact and every possible argument.  Can you say these aliens are <em>mistaken?</em>"</p> <p>Obert:  "Maybe it's the right thing to do in <em>their</em> very different, alien world&#8212;"</p> <p>Subhan:  "And then they land on Earth and start slitting human throats, laughing all the while, because they don't believe it's wrong.  Are they <em>mistaken?</em>"</p> <p>Obert:  "Yes."</p> <p>Subhan:  "Where exactly is the mistake?  In which step of reasoning?"</p> <p>Obert:  "I don't know exactly.  My guess is that they've got a bad axiom."</p> <p>Subhan:  "Dammit!  Okay, look.  Is it possible that&#8212;by analogy with the Space Cannibals&#8212;there are true moral facts of which the human species is not only <em>presently</em> unaware, but incapable of perceiving <em>in principle?</em>  Could we have been born defective&#8212;incapable even of being <em>compelled</em> by the arguments that would lead us to the light?  Moreover, born without any desire to modify ourselves to be capable of understanding such arguments?  Could we be <em>irrevocably mistaken</em> about morality&#8212;just like you say the Space Cannibals are?"</p> <p>Obert:  "I... guess so..."</p> <p>Subhan:  "You guess so?  Surely this is an inevitable consequence of believing that morality is a given, independent of anyone's preferences!  Now, is it possible that <em>we,</em> not the Space Cannibals, are the ones who are irrevocably mistaken in believing that murder is wrong?"</p> <p>Obert:  "<em>That</em> doesn't seem likely."</p> <p>Subhan:  "I'm not asking you if it's likely, I'm asking you if it's <em>logically possible!</em>  If it's <em>not</em> possible, then you have just confessed that human morality is ultimately determined by our human constitutions.  And if it <em>is</em> possible, then what distinguishes this scenario of 'humanity is irrevocably mistaken about morality', from finding a stone tablet on which is written the phrase 'Thou Shalt Murder' without any known justification attached?  How is a given morality any different from an unjustified stone tablet?"</p> <p>Obert:  "Slow down.  Why does this argument show that morality is determined by our own constitutions?"</p> <p>Subhan:  "Once upon a time, theologians tried to say that God was the foundation of morality.  And even since the time of the ancient Greeks, philosophers were sophisticated enough to go on and ask the next question&#8212;'<a href="http://plato.stanford.edu/entries/metaethics/#EutPro"><em>Why</em> follow God's commands?</a> [http://plato.stanford.edu/entries/metaethics/#EutPro]'  Does God have <em>knowledge</em> of morality, so that we should follow Its orders as good advice?  But then what is this morality, outside God, of which God has knowledge?  Do God's commands <em>determine</em> morality?  But then why, <em>morally,</em> should one follow God's orders?"</p> <p>Obert:  "Yes, this demolishes attempts to answer questions about the nature of morality just by saying 'God!', unless you answer the obvious further questions.  But so what?"</p> <p>Subhan:  "And furthermore, let us castigate those who made the argument originally, for the sin of trying to <em>cast off responsibility</em>&#8212;trying to wave a scripture and say, 'I'm just following God's orders!'  Even if God <em>had</em> told them to do a thing, it would still have been <em>their own decision</em> to follow God's orders."</p> <p>Obert:  "I agree&#8212;as a matter of morality, there is no evading of moral responsibility.  Even if your parents, or your government, or some kind of hypothetical superintelligence, tells you to do something, you are <a href="0013.html">responsible for your decision</a> [http://lesswrong.com/lw/gz/policy_debates_should_not_appear_onesided/] in doing it."</p> <p>Subhan:  "But you see, this also demolishes the idea of any morality that is outside, beyond, or above human preference.  Just substitute 'morality' for 'God' in the argument!"</p> <p>Obert:  "<em>What?</em>"</p> <p>Subhan:  "<a href="http://en.wikiquote.org/wiki/John_McCarthy">John McCarthy</a> [http://en.wikiquote.org/wiki/John_McCarthy] said:  'You say you couldn't live if you thought the world had no purpose. You're saying that you can't form purposes of your own-that you need someone to tell you what to do. The average child has more gumption than that.'  For every kind of stone tablet that you might imagine anywhere, in the trends of the universe or in the structure of logic, you are still left with the question:  'And <em>why</em> obey this morality?'  It would be <em>your decision</em> to follow this trend of the universe, or obey this structure of logic.  Your decision&#8212;and <em>your preference.</em>"</p> <p>Obert:  "That doesn't follow!  Just because it is <em>my decision</em> to be moral&#8212;and even because there are drives in me that lead me to make that decision&#8212;it doesn't follow that the morality I follow consists <em>merely</em> of my preferences.  If someone gives me a pill that makes me prefer to <em>not</em> be moral, to commit murder, then this just alters my preference&#8212;but <em>not</em> the morality; murder is still wrong.  That's common moral sense&#8212;"</p> <p>Subhan:  "I beat my head against my keyboard!  What about <em>scientific</em> common sense?  If morality is this mysterious <em>given</em> thing, from beyond space and time&#8212;and I don't even see why we <em>should</em> follow it, in that case&#8212;but in any case, if morality exists independently of human nature, then isn't it a <em>remarkable coincidence</em> that, say, <em>love</em> is good?"</p> <p>Obert:  "Coincidence?  How so?"</p> <p>Subhan:  "Just where on Earth do you think the emotion of <em>love</em> comes from?  If the ancient Greeks had ever thought of the theory of natural selection, they could have looked at the human institution of sexual romance, or parental love for that matter, and deduced in one flash that human beings had evolved&#8212;or at least derived tremendous Bayesian evidence for human evolution.  Parental bonds and sexual romance clearly display the signature of <a href="0159.html">evolutionary psychology</a> [http://lesswrong.com/lw/l1/evolutionary_psychology/]&#8212;they're archetypal cases, in fact, so obvious we usually don't even see it."</p> <p>Obert:  "But love isn't just about reproduction&#8212;"</p> <p>Subhan:  "Of course not; individual organisms are <a href="0158.html">adaptation-executers, not fitness-maximizers</a> [http://lesswrong.com/lw/l0/adaptationexecuters_not_fitnessmaximizers/].  But for something independent of humans, morality looks remarkably like <a href="0161.html">godshatter of natural selection</a> [http://lesswrong.com/lw/l3/thou_art_godshatter/].  Indeed, it is far too much coincidence for me to credit.  Is happiness morally preferable to pain?  What a coincidence!  And if you claim that there is any emotion, any instinctive preference, any complex brain circuitry in humanity which was created by some external morality thingy and not natural selection, then you are infringing upon science and you will surely be torn to shreds&#8212;science has never needed to postulate anything but evolution to explain any feature of human psychology&#8212;"</p> <p>Obert:  "I'm <em>not</em> saying that humans got here by anything except evolution."</p> <p>Subhan:  "Then why does morality look so amazingly like a product of an evolved psychology?"</p> <p>Obert:  "I don't claim perfect access to moral truth; maybe, being human, I've made certain mistakes about morality&#8212;"</p> <p>Subhan:  "Say <em>that</em>&#8212;forsake love and life and happiness, and follow some useless damn trend of the universe or whatever&#8212;and you will lose every scrap of the moral normality that you once touted as your strong point.  And I will be right here, asking, 'Why even bother?'  It would be a pitiful mind indeed that demanded authoritative answers so strongly, that it would forsake all good things to have some authority beyond itself to follow."</p> <p>Obert:  "All right... then maybe the reason morality seems to bear certain similarities to our human constitutions, is that we could only perceive morality at all, if we happened, by luck, to evolve in consonance with it."</p> <p>Subhan:  "Horsemanure."</p> <p>Obert:  "Fine... you're right, that wasn't very plausible.  Look, I admit you've driven me into quite a corner here.  But even if there <em>were</em> nothing more to morality than preference, I would still prefer to act as morality were real.  I mean, if it's all just preference, that way is as good as anything else&#8212;"</p> <p>Subhan:  "Now you're just trying to avoid <a href="0063.html">facing reality</a> [http://lesswrong.com/lw/id/you_can_face_reality/]!  Like someone who says, 'If there is no Heaven or Hell, then I may as well still act as if God's going to punish me for sinning.'"</p> <p>Obert:  "That may be a good metaphor, in fact.  Consider two theists, in the process of becoming atheists.  One says, 'There is no Heaven or Hell, so I may as well cheat and steal, if I can get away without being caught, since there's no God to watch me.'  And the other says, 'Even though there's no God, I intend to <em>pretend</em> that God is watching me, so that I can go on being a moral person.'  Now they are both mistaken, but the first is straying much further from the path."</p> <p>Subhan:  "And what is the second one's flaw?  <em>Failure to accept personal responsibility!</em>"</p> <p>Obert:  "Well, and I admit I find that a more compelling argument than anything else you have said.  Probably because it is a moral argument, and it has always been morality, not metaethics, with which I claimed to be concerned.  But even so, after our whole conversation, I still maintain that wanting to murder someone does not make murder <em>right.</em>  Everything that you have said about preference is interesting, but it is ultimately <em>about</em> preference&#8212;about minds and what they are designed to desire&#8212;and not about this other thing that humans sometimes talk about, 'morality'.  I can just ask <a href="http://plato.stanford.edu/entries/metaethics/#IsOOpeQueArg">Moore's Open Question</a> [http://plato.stanford.edu/entries/metaethics/#IsOOpeQueArg]:  Why should I <em>care</em> about human preferences?  What makes following human preferences <em>right</em>?  By changing a mind, you can change what it prefers; you can even change what it <em>believes</em> to be right; but you cannot change what <em>is</em> right.  Anything you talk about, that can be changed in this way, is not 'right-ness'."</p> <p>Subhan:  "So you take refuge in <a href="0265.html">arguing from definitions</a> [http://lesswrong.com/lw/nz/arguing_by_definition/]?"</p> <p>Obert:  "You know, when I reflect on this whole argument, it seems to me that your position has the definite advantage when it comes to arguments about ontology and reality and all that stuff&#8212;"</p> <p>Subhan:  "'<em>All that stuff'</em>?  What else <em>is</em> there, besides reality?"</p> <p>Obert:  "Okay, the morality-as-preference viewpoint is a lot easier to shoehorn into a universe of quarks.  But I still think the morality-as-given viewpoint has the advantage when it comes to, you know, the actual <em>morality</em> part of it&#8212;giving answers that are good in the sense of being <em>morally</em> good, not in the sense of being a good reductionist.  Because, you know, there <em>are</em> such things as moral errors, there <em>is</em> moral progress, and you really <em>shouldn't</em> go around thinking that murder would be right if you wanted it to be right."</p> <p>Subhan:  "That sounds to me like the logical fallacy of appealing to consequences."</p> <p>Obert:  "Oh?  Well, it sounds to <em>me</em> like an incomplete reduction&#8212;one that doesn't quite add up to normality."</p> <p> </p> <p style="text-align:right">Part of <a href="http://wiki.lesswrong.com/wiki/Metaethics_sequence"><em>The Metaethics Sequence</em></a> [http://wiki.lesswrong.com/wiki/Metaethics_sequence]</p> <p style="text-align:right">Next post: "<a href="0410.html">Where Recursive Justification Hits Bottom</a> [http://lesswrong.com/lw/s0/where_recursive_justification_hits_bottom/]"</p> <p style="text-align:right">Previous post: "<a href="0407.html">Is Morality Preference?</a> [http://lesswrong.com/lw/rx/is_morality_preference/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq14.html">Sequence 14: Metaethics</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0407.html">Is Morality Preference?</a></p></td><td><p><i>Next: </i><a href="0410.html">Where Recursive Justification Hits Bottom</a></p></td></tr></table><p><i>Referenced by: </i><a href="0407.html">Is Morality Preference?</a> &#8226; <a href="0410.html">Where Recursive Justification Hits Bottom</a> &#8226; <a href="0415.html">Rebelling Within Nature</a> &#8226; <a href="0420.html">The Gift We Give To Tomorrow</a> &#8226; <a href="0429.html">Does Your Morality Care What You Think?</a> &#8226; <a href="0430.html">Changing Your Metaethics</a> &#8226; <a href="0431.html">Setting Up Metaethics</a> &#8226; <a href="0606.html">Emotional Involvement</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/ry/is_morality_given/">Is Morality Given?</a></p></body></html>