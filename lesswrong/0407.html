<html><head><title>Is Morality Preference?</title></head><body><h1>Is Morality Preference?</h1><p><i>Eliezer Yudkowsky, 05 July 2008 12:55AM</i></p><div><p><strong>Followup to</strong>:  <a href="0406.html">Moral Complexities</a> [http://lesswrong.com/lw/rw/moral_complexities/]</p> <p>In the dialogue "<a href="0404.html">The Bedrock of Fairness</a> [http://lesswrong.com/lw/ru/the_bedrock_of_fairness/]", I intended Yancy to represent morality-as-raw-fact, Zaire to represent morality-as-raw-whim, and Xannon to be a particular kind of attempt at compromising between them.  Neither Xannon, Yancy, or Zaire represent my own views&#8212;rather they are, in their disagreement, showing the <em>problem</em> that I am trying to solve.  It is futile to present answers to which questions are lacking.</p> <p>But characters have independent life in the minds of all readers; when I create a <em>dialogue</em>, I don't view my authorial intent as primary.  Any good interpretation can be discussed.  I meant Zaire to be asking for half the pie out of pure selfishness; many readers interpreted this as a genuine need... which is as interesting a discussion to have as any, though it's a different discussion.</p> <p>With this in mind, I turn to Subhan and Obert, who shall try to answer <a href="0406.html">yesterday's questions</a> [http://lesswrong.com/lw/rw/moral_complexities/] on behalf of their respective viewpoints.</p> <p>Subhan makes the opening statement:</p> <p>Subhan:  "I defend this proposition: that there is no reason to talk about a 'morality' distinct from what people want."</p> <p>Obert:  "I challenge.  Suppose someone comes to me and says, 'I want a slice of that pie you're holding.'  It seems to me that they have just made a very different statement from 'It is <em>right</em> that I should get a slice of that pie'.  I have no reason at all to doubt the former statement&#8212;to suppose that they are lying to me about their desires.  But when it comes to the latter proposition, I have reason indeed to be skeptical.  Do you say that these two statements <em>mean</em> the same thing?"</p> <p><a id="more"></a></p> <p>Subhan:  "I suggest that when the pie-requester says to you, 'It is right for me to get some pie', this asserts that <em>you</em> want the pie-requester to get a slice."</p> <p>Obert:  "Why should <em>I</em> need to be told what <em>I</em> want?"</p> <p>Subhan:  "You take a needlessly restrictive view of wanting, Obert; I am not setting out to reduce humans to creatures of animal instinct.  Your wants include those desires you label 'moral values', such as wanting the hungry to be fed&#8212;"</p> <p>Obert:  "And you see no distinction between my desire to feed the hungry, and my desire to eat all the delicious pie myself?"</p> <p>Subhan:  "No!  They are both desires&#8212;backed by <em>different</em> emotions, perhaps, but both desires.  To continue, the pie-requester hopes that you have a desire to feed the hungry, and so says, 'It is right that I should get a slice of this pie', to remind you of your own desire.  We do not automatically know all the consequences of our own wants; we are not logically omniscient."</p> <p>Obert:  "This seems psychologically unrealistic&#8212;I don't think that's what goes through the mind of the person who says, 'I have a right to some pie'.  In this latter case, if I deny them pie, they will feel <em>indignant.</em>  If they are only trying to remind me of my own desires, why should they feel indignant?"</p> <p>Subhan:  "Because they didn't get any pie, so they're frustrated."</p> <p>Obert:  "Unrealistic!  Indignation at moral transgressions has a psychological dimension that goes beyond struggling with a struck door."</p> <p>Subhan:  "Then consider the <a href="0159.html">evolutionary psychology</a> [http://lesswrong.com/lw/l1/evolutionary_psychology/].  The pie-requester's emotion of indignation would evolve as a display, first to remind you of the potential consequences of offending fellow tribe-members, and second, to remind any observing tribe-members of goals <em>they</em> may have to feed the hungry.  By refusing to share, you would offend against a social norm&#8212;which is to say, a widely shared want."</p> <p>Obert:  "So you take refuge in social wants as the essence of morality?  But people seem to see a difference between desire and morality, <em>even</em> in the quiet of their own minds.  They say things like:  'I want X, but the right thing to do is Y... what shall I do?'"</p> <p>Subhan:  "So they experience a conflict between their want to eat pie, and their want to feed the hungry&#8212;which they know is also a want of society.  It's not predetermined that the prosocial impulse will be victorious, but they are both impulses."</p> <p>Obert:  "And when, during WWII, a German hides Jews in their basement&#8212;<em>against</em> the wants of surrounding society&#8212;how then?"</p> <p>Subhan:  "People do not always define their in-group by looking at their next-door neighbors; they may conceive of <em>their group</em> as 'good Christians' or 'humanitarians'."</p> <p>Obert:  "I should sooner say that people choose their in-groups by looking for others who share their beliefs about morality&#8212;not that they construct their morality from their in-group."</p> <p>Subhan:  "Oh, <em>really?</em>  I should not be surprised if that were experimentally testable&#8212;if so, how much do you want to bet?"</p> <p>Obert:  "That the Germans who hid Jews in their basements, chose who to call <em>their people</em> by looking at their beliefs about morality?  Sure.  I'd bet on that."</p> <p>Subhan:  "But in any case, even if a German resister has a desire to preserve life which is so strong as to go against their own perceived 'society', it is still <em>their desire</em>."</p> <p>Obert:  "Yet they would attribute to that desire, the same distinction they make between 'right' and 'want'&#8212;even when going <em>against</em> society.  They might think to themselves, 'How dearly I wish I could stay out of this, and keep my family safe.  But it is my duty to hide these Jews from the Nazis, and I must fulfill that duty.'  There is an interesting moral question, as to whether it <a href="0178.html">reveals greater heroism</a> [http://lesswrong.com/lw/lk/superhero_bias/], to fulfill a duty eagerly, or to fulfill your duties when you are not eager.  For myself I should just total up the lives saved, and call that their score.  But I digress...  The distinction between 'right' and 'want' is not explained by your distinction of socially shared and individual wants.  The distinction between desire and duty seems to me a basic thing, which someone could experience floating alone in a spacesuit a thousand light-years from company."</p> <p>Subhan:  "Even if I were to grant this <em>psychological</em> distinction, perhaps that is simply a matter of emotional flavoring. Why should I not describe perceived duties as a differently flavored want?"</p> <p>Obert:  "Duties, and should-ness, seem to have a dimension that goes beyond our whims.  If we want different pizza toppings today, we can order a different pizza without guilt; but we cannot choose to make murder a good thing."</p> <p>Subhan:  "Schopenhauer:  'A man can do as he wills, but not will as he wills.'  You cannot decide to make salad taste better to you than cheeseburgers, and you cannot decide <em>not</em> to dislike murder.  Furthermore, people do change, albeit rarely, those wants that you name 'values'; indeed they are easier to change than our food tastes."</p> <p>Obert:  "Ah!  That is something I meant to ask <em>you</em> about.  People sometimes change their morals; <em>I</em> would call this updating their beliefs about morality, but <em>you</em> would call it changing their wants.  Why would anyone want to change their wants?"</p> <p>Subhan:  "Perhaps they simply find that their wants have changed; brains do change over time.  Perhaps they have formed a <em>verbal belief</em> about what they want, which they have discovered to be mistaken. Perhaps society has changed, or their perception of society has changed.  But really, in most cases you don't have to go that far, to explain apparent changes of morality."</p> <p>Obert:  "Oh?"</p> <p>Subhan:  "Let's say that someone begins by thinking that Communism is a good social system, has some arguments, and ends by believing that Communism is a bad social system.  This does not mean that their <em>ends</em> have changed&#8212;they may simply have gotten a good look at the history of Russia, and decided that Communism is a poor <em>means</em> to the end of raising standards of living.  I challenge you to find me a case of changing morality in which people change their <a href="0162.html">terminal values</a> [http://lesswrong.com/lw/l4/terminal_values_and_instrumental_values/], and not just their beliefs about which acts have which consequences."</p> <p>Obert:  "Someone begins by believing that God ordains against premarital sex; they find out there is no God; subsequently they approve of premarital sex.  This, let us specify, is <em>not</em> because of fear of Hell; but because previously they believed that God had the power to ordain, or knowledge to tell them, what is <em>right;</em> in ceasing to believe in God, they updated their belief about what is right."</p> <p>Subhan:  "I am not responsible for straightening others' confusions; this one is merely in a general state of disarray around the 'God' concept."</p> <p>Obert:  "All right; suppose I get into a moral argument with a man from a society that practices female circumcision.  I do not think our argument is about the <em>consequences</em> to the woman; the argument is about the morality of these consequences."</p> <p>Subhan:  "Perhaps the one falsely believes that women have no feelings&#8212;"</p> <p>Obert:  "Unrealistic, unrealistic!  It is far more likely that the one hasn't really considered whether the woman has feelings, because he doesn't see any obligation to care.  The happiness of women is not a terminal value to him.  Thousands of years ago, most societies devalued consequences to women.  They also had false beliefs about women, true&#8212;and false beliefs about men as well, for that matter&#8212;but nothing like the Victorian era's complex rationalizations for how paternalistic rules really benefited women. The Old Testament doesn't explain <em>why</em> it levies the death penalty for a woman wearing men's clothing.  It certainly doesn't explain how this rule really benefits women after all.  It's not the sort of argument it would have occurred to the authors to rationalize!  They didn't <em>care</em> about the consequences to women."</p> <p>Subhan:  "So they wanted different things than you; what of it?"</p> <p>Obert:  "See, now that is exactly why I cannot accept your viewpoint.  <em>Somehow,</em> societies went from Old Testament attitudes, to democracies with female suffrage.  And this transition&#8212;however it occurred&#8212;was caused by people saying, 'What this society does to women is a great wrong!', not, 'I would personally prefer to treat women better.'  That's not just a change in semantics&#8212;it's the difference between being obligated to stand and deliver a justification, versus being able to just say, 'Well, I prefer differently, end of discussion.'  And who says that humankind has finished with its moral progress?  You're yanking the ladder out from underneath a very important climb."</p> <p>Subhan:  "Let us suppose that the change of human societies over the last ten thousand years, has been accompanied by a change in terminal values&#8212;"</p> <p>Obert:  "You call this a <em>supposition?</em>  Modern political debates turn around vastly different valuations of consequences than in ancient Greece!"</p> <p>Subhan:  "I am not so sure; human cognitive psychology has not had time to change evolutionarily over that period.  Modern democracies tend to appeal to our empathy for those suffering; that empathy existed in ancient Greece as well, but it was invoked less often.  In each single moment of argument, I doubt you would find modern politicians appealing to <em>emotions that didn't exist</em> in ancient Greece."</p> <p>Obert:  "I'm not saying that emotions have changed; I'm saying that beliefs about morality have changed.  Empathy merely provides emotional depth to an argument that can be made on a purely logical level:  'If it's wrong to enslave you, if it's wrong to enslave your family and your friends, then how can it be right to enslave people who happen to be a different color?  What difference does the color make?'  If morality is just preference, then there's a very simple answer:  'There is no right or wrong, I just like my own family better.'  You see the problem here?"</p> <p>Subhan:  "<a href="http://www.nizkor.org/features/fallacies/appeal-to-consequences.html">Logical fallacy:  Appeal to consequences.</a> [http://www.nizkor.org/features/fallacies/appeal-to-consequences.html]"</p> <p>Obert:  "I'm not appealing to consequences.  I'm showing that when I reason about 'right' or 'wrong', I am reasoning about something that does <em>not</em> behave like 'want' and 'don't want'."</p> <p>Subhan:  "Oh?  But I think that in reality, your rejection of morality-as-preference has a great deal to do with your fear of where the truth leads."</p> <p>Obert:  "<a href="http://www.nizkor.org/features/fallacies/ad-hominem.html">Logical fallacy:  Ad hominem.</a> [http://www.nizkor.org/features/fallacies/ad-hominem.html]"</p> <p>Subhan:  "Fair enough.  Where were we?"</p> <p>Obert:  "If morality is preference, why would you want to change your wants to be more inclusive?  Why would you want to change your wants at all?"</p> <p>Subhan:  "The answer to your first question probably has to do with a fairness instinct, I would suppose&#8212;a notion that the tribe should have the same rules for everyone."</p> <p>Obert:  "I don't think that's an instinct.  I think that's a triumph of three thousand years of moral philosophy."</p> <p>Subhan:  "That could be tested."</p> <p>Obert:  "And my second question?"</p> <p>Subhan:  "Even if terminal values change, it doesn't mean that terminal values are stored on a great stone tablet outside humanity.  Indeed, it would seem to argue against it!  It just means that some of the events that go on in our brains, can change what we want."</p> <p>Obert:  "<em>That's</em> your concept of moral progress?  <em>That's</em> your view of the last three thousand years?  <em>That's</em> why we have free speech, democracy, mass street protests against wars, nonlethal weapons, no more slavery&#8212;"</p> <p>Subhan:  "If you wander on a random path, and you compare all past states to your present state, you will see continuous 'advancement' toward your present condition&#8212;"</p> <p>Obert:  "<em>Wander on a random path?</em>"</p> <p>Subhan:  "I'm just pointing out that saying, 'Look how much better things are now', when your criterion for 'better' is comparing past moral values to yours, does not establish any directional trend in human progress."</p> <p>Obert:  "Your strange beliefs about the nature of morality have destroyed your soul.  I don't even believe in souls, and I'm saying that."</p> <p>Subhan:  "Look, depending on which arguments do, in fact, move us, you might be able to regard the process of changing terminal values as a directional progress.  You might be able to show that the change had a consistent trend as we thought of more and more arguments.  But that doesn't show that morality is something <em>outside</em> us.  We could even&#8212;though this is psychologically unrealistic&#8212;choose to <em>regard you</em> as computing a converging approximation to your 'ideal wants', so that you would have meta-values that defined both your present value and the rules for updating them.  But these would be <em>your</em> meta-values and <em>your</em> ideals and <em>your</em> computation, just as much as pepperoni is <em>your own</em> taste in pizza toppings.  You may not know your <em>real</em> favorite ever pizza topping, until you've tasted many possible flavors."</p> <p>Obert:  "Leaving out <em>what</em> it is that you just compared to pizza toppings, I begin to be suspicious of the all-embracingness of your viewpoint.  No matter <em>what</em> my mind does, you can simply call it a still-more-modified 'want'.  I think that <em>you</em> are the one suffering from meta-level confusion, not I.  Appealing to right is not the same as appealing to desire.  Just because the appeal is judged <em>inside my brain</em>, doesn't mean that the appeal is not <em>to</em> something more than my desires.  Why can't my brain compute duties as well as desires?"</p> <p>Subhan:  "What is the difference between duty and desire?"</p> <p>Obert:  "A duty is something you must do whether you want to or not."</p> <p>Subhan:  "Now you're just being incoherent.  Your brain computes something it wants to do whether it wants to or not?"</p> <p>Obert:  "No, <em>you</em> are the one whose theory makes this incoherent.  Which is why your theory ultimately fails to add up to morality."</p> <p>Subhan:  "I say again that you underestimate the power of mere wanting.  And more:  <em>You</em> accuse <em>me</em> of incoherence?  You say that <em>I</em> suffer from meta-level confusion?"</p> <p>Obert:  "Er... yes?"</p> <p><em>To be continued...</em></p> <p> </p> <p style="text-align:right">Part of <a href="http://wiki.lesswrong.com/wiki/Metaethics_sequence"><em>The Metaethics Sequence</em></a> [http://wiki.lesswrong.com/wiki/Metaethics_sequence]</p> <p style="text-align:right">Next post: "<a href="0408.html">Is Morality Given?</a> [http://lesswrong.com/lw/ry/is_morality_given/]"</p> <p style="text-align:right">Previous post: "<a href="0406.html">Moral Complexities</a> [http://lesswrong.com/lw/rw/moral_complexities/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq14.html">Sequence 14: Metaethics</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0406.html">Moral Complexities</a></p></td><td><p><i>Next: </i><a href="0408.html">Is Morality Given?</a></p></td></tr></table><p><i>Referenced by: </i><a href="0406.html">Moral Complexities</a> &#8226; <a href="0408.html">Is Morality Given?</a> &#8226; <a href="0419.html">Whither Moral Progress?</a> &#8226; <a href="0431.html">Setting Up Metaethics</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/rx/is_morality_preference/">Is Morality Preference?</a></p></body></html>