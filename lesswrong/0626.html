<html><head><title>31 Laws of Fun</title></head><body><h1>31 Laws of Fun</h1><p><i>Eliezer Yudkowsky, 26 January 2009 10:13AM</i></p><div><p style="margin-left: 40px;">So this is Utopia, is it?  Well<br>I beg your pardon, I thought it was Hell.<br>&#160;&#160;&#160; &#160;&#160;&#160; -- Sir Max Beerholm, verse entitled<br>&#160;&#160;&#160; &#160;&#160;&#160; <em>In a Copy of More's (or Shaw's or Wells's or Plato's or Anybody's) Utopia</em></p><p>This is a shorter summary of the <a href="0624.html">Fun Theory Sequence</a> [http://lesswrong.com/lw/xy/the_fun_theory_sequence/] with all the background theory left out - just the compressed advice to the would-be author or futurist who wishes to imagine a world where people <em>might actually want to live:</em></p><ol> <li>Think of a <em>typical day</em> in the life of someone who's been adapting to Utopia <em>for a while.</em>  Don't anchor on the first moment of "hearing the good news".  Heaven's "You'll never have to work again, and the streets are paved with gold!" sounds like good news to a tired and poverty-stricken peasant, but two months later it might not be so much fun.  (<a href="0585.html">Prolegomena to a Theory of Fun</a> [http://lesswrong.com/lw/wv/prolegomena_to_a_theory_of_fun/].)</li> <li>Beware of packing your Utopia with things you think people <em>should</em> do that aren't actually <em>fun</em>.  Again, consider Christian Heaven: singing hymns doesn't sound like loads of endless fun, but you're <em>supposed </em>to enjoy praying, so no one can point this out.  (<a href="0585.html">Prolegomena to a Theory of Fun</a> [http://lesswrong.com/lw/wv/prolegomena_to_a_theory_of_fun/].)</li> <li>Making a video game easier doesn't always improve it.  The same holds true of a life.  Think in terms of clearing out low-quality drudgery to make way for high-quality challenge, rather than eliminating work.  (<a href="0586.html">High Challenge</a> [http://lesswrong.com/lw/ww/high_challenge/].)</li> <li>Life should contain novelty - experiences you haven't encountered before, preferably teaching you something you didn't already know.  If there isn't a sufficient supply of novelty (relative to the speed at which you generalize), you'll get bored.  (<a href="0587.html">Complex Novelty</a> [http://lesswrong.com/lw/wx/complex_novelty/].)</li> </ol> <a id="more"></a> <ol start="5"> <li>People should get smarter at a rate sufficient to integrate their old experiences, but not so much smarter so fast that they can't integrate their new intelligence.  Being smarter means you get bored faster, but you can also tackle new challenges you couldn't understand before.  (<a href="0587.html">Complex Novelty</a> [http://lesswrong.com/lw/wx/complex_novelty/].)</li> <li>People should live in a world that fully engages their senses, their bodies, and their brains.  This means either that the world resembles the ancestral savanna more than say a windowless office; or alternatively, that brains and bodies have changed to be fully engaged by different kinds of complicated challenges and environments.  (Fictions intended to entertain a human audience should concentrate primarily on the former option.)  (<a href="0588.html">Sensual Experience</a> [http://lesswrong.com/lw/wy/sensual_experience/].)</li> <li>Timothy Ferris:  "What is the opposite of happiness?  Sadness?  No.  Just as love and hate are two sides of the same coin, so are happiness and sadness...  The opposite of love is indifference, and the opposite of happiness is - here's the clincher - boredom...  The question you should be asking isn't 'What do I want?' or 'What are my goals?' but 'What would excite me?'...  <em>Living</em> like a millionaire requires <em>doing</em> interesting things and not just owning enviable things."  (<a href="0422.html">Existential Angst Factory</a> [http://lesswrong.com/lw/sc/existential_angst_factory/].)</li> <li>Any particular individual's life should get better and better over time.  (<a href="0610.html">Continuous Improvement</a> [http://lesswrong.com/lw/xk/continuous_improvement/].)</li> <li>You should not know exactly what improvements the future holds, although you should look forward to finding out.  The actual event should come as a pleasant surprise.  (<a href="0614.html">Justified Expectation of Pleasant Surprises</a> [http://lesswrong.com/lw/xo/justified_expectation_of_pleasant_surprises/].)</li> <li>Our hunter-gatherer ancestors strung their own bows, wove their own baskets and whittled their own flutes; then they did their own hunting, their own gathering and played their own music.  Futuristic Utopias are often depicted as offering more and more neat buttons that do less and less comprehensible things <em>for </em>you.  Ask not what interesting things Utopia can do <span style="font-style: italic;"></span><em>for </em>people; ask rather what interesting things the inhabitants could do for <em>themselves </em>- with their own brains, their own bodies, or tools they understand how to build.  (<a href="0589.html">Living By Your Own Strength</a> [http://lesswrong.com/lw/wz/living_by_your_own_strength/].)</li> <li>Living in Eutopia should make people stronger, not weaker, over time.  The inhabitants should appear <em>more formidable</em> than the people of our own world, not less.  (<a href="0589.html">Living By Your Own Strength</a> [http://lesswrong.com/lw/wz/living_by_your_own_strength/]; see also, <a href="0022.html">Tsuyoku Naritai</a> [http://lesswrong.com/lw/h8/tsuyoku_naritai_i_want_to_become_stronger/].)</li> <li>Life should not be broken up into a series of disconnected episodes with no long-term consequences.  No matter how sensual or complex, playing one <em>really great video game</em> after another, does not make a life story.  (<a href="0606.html">Emotional Involvement</a> [http://lesswrong.com/lw/xg/emotional_involvement/].)</li> <li>People should make their own destinies; their lives should not be choreographed to the point that they no longer need to imagine, plan and navigate their own futures.  Citizens should not be the pawns of more powerful gods, still less their sculpted material.  One simple solution would be to have the world work by stable rules that are the same for everyone, where the burden of Eutopia is carried by a good initial choice of rules, rather than by any optimization pressure applied to individual lives.  (<a href="0601.html">Free to Optimize</a> [http://lesswrong.com/lw/xb/free_to_optimize/].)</li> <li>Human minds should not have to <em>play on a level field</em> with vastly superior entities.  Most people don't like being overshadowed.  Gods destroy a human protagonist's "main character" status; this is undesirable in fiction and probably in real life.  (E.g.:  C. S. Lewis's Narnia, Iain Banks's Culture.)  Either change people's emotional makeup so that they don't <em>mind </em>being unnecessary, or keep the gods <em>way </em>off their playing field.  Fictional stories intended for human audiences cannot do the former.  (And in real life, you probably <em>can</em> have powerful AIs that are neither sentient nor meddlesome.  See the main post and its prerequisites.)  (<a href="0598.html">Amputation of Destiny</a> [http://lesswrong.com/lw/x8/amputation_of_destiny/].)</li> <li>Trying to compete on a single flat playing field with <em>six billion other humans </em>also creates problems.  Our ancestors lived in bands of around 50 people.  Today the media is constantly bombarding us with news of <em>exceptionally </em>rich and pretty people as if they lived next door to us; and very few people get a chance to be the <em>best </em>at any specialty.  (<a href="0599.html">Dunbar's Function</a> [http://lesswrong.com/lw/x9/dunbars_function/].)</li> <li>Our ancestors also had some degree of genuine control over their band's politics.  Contrast to modern nation-states where almost no one knows the President on a personal level or could argue Congress out of a bad decision.  (Though that doesn't stop people from arguing as loudly as if they still lived in a 50-person band.)  (<a href="0599.html">Dunbar's Function</a> [http://lesswrong.com/lw/x9/dunbars_function/].)</li> <li>Offering people more options is <em>not </em>always helping them (especially if the option is something they couldn't do for themselves).  Losses are more painful than the corresponding gains, so if choices are different along many dimensions and only one choice can be taken, people tend to focus on the loss of the road <em>not </em>taken.  Offering a road that bypasses a challenge makes the challenge feel less real, even if the cheat is diligently refused.  It is also a sad fact that humans predictably make certain kinds of mistakes.  Don't assume that building <em>more choice</em> into your Utopia is necessarily an improvement because "people can always just say no".  This <em>sounds reassuring</em> to an outside reader - "Don't worry, <em>you'll</em> decide!  You trust <em>yourself</em>, right?" - but might not be much fun to actually <em>live </em>with.  (<a href="0592.html">Harmful Options</a> [http://lesswrong.com/lw/x2/harmful_options/].)</li> <li>Extreme example of the above: being constantly offered huge temptations that are incredibly dangerous - a completely realistic virtual world, or very addictive and pleasurable drugs.  You can never allow yourself a single moment of willpower failure over your whole life.  (E.g.:  John C. Wright's Golden Oecumene.)  (<a href="0593.html">Devil's Offers</a> [http://lesswrong.com/lw/x3/devils_offers/].)</li> <li>Conversely, when people are grown strong enough to shoot off their feet <em>without external help,</em> stopping them may be too much interference.  Hopefully they'll then be smart enough <em>not</em> to:  By the time they can build the gun, they'll know what happens if they pull the gun, and won't need a smothering safety blanket.  If that's the theory, then dangerous options need correspondingly difficult locks.  (<a href="0593.html">Devil's Offers</a> [http://lesswrong.com/lw/x3/devils_offers/].)</li> <li><em>Telling</em> people truths they haven't yet figured out for themselves, is not always helping them.  (<a href="0294.html">Joy in Discovery</a> [http://lesswrong.com/lw/os/joy_in_discovery/].)</li> <li>Brains are some of the most complicated things in the world.  Thus, other humans (other minds) are some of the most complicated things we deal with.  For us, this interaction has a unique character because of the <em>sympathy </em>we feel for others - the way that our brain tends to align with their brain - rather than our brain just treating other brains as big complicated machines with levers to pull.  Reducing the need for people to interact with other people reduces the complexity of human existence; this is a step in the wrong direction.  For example, resist the temptation to <em>simplify people's lives</em> by offering them artificially perfect sexual/romantic partners. (<a href="0619.html">Interpersonal Entanglement</a> [http://lesswrong.com/lw/xt/interpersonal_entanglement/].)</li> <li>But admittedly, humanity does have a <em>statistical </em>sex problem: the male distribution of attributes doesn't harmonize with the female distribution of desires, or vice versa.  Not everything in Eutopia should be easy - but it shouldn't be pointlessly, unresolvably frustrating either.  (This is a general principle.)  So imagine <em>nudging</em> the distributions to make the problem <em>solvable</em> - rather than waving a magic wand and solving everything instantly.  (<a href="0619.html">Interpersonal Entanglement</a> [http://lesswrong.com/lw/xt/interpersonal_entanglement/].)</li> <li>In general, tampering with brains, minds, emotions, and personalities is way more fraught on every possible level of ethics and difficulty, than tampering with bodies and environments.  Always ask what you can do by messing with the environment before you imagine messing with minds.  Then prefer small cognitive changes to big ones.  You're not just outrunning your human audience, you're outrunning your own imagination.  (<a href="0604.html">Changing Emotions</a> [http://lesswrong.com/lw/xe/changing_emotions/].)</li> <li>In this present world, there is an imbalance between pleasure and pain.  An unskilled torturer with simple tools can create worse pain in thirty seconds, than an extremely skilled sexual artist can create pleasure in thirty minutes.  One response would be to <em>remedy the imbalance</em> - to have the world contain <em>more </em>joy than sorrow.  Pain might exist, but not pointless endless unendurable pain.  Mistakes would have more <em>proportionate </em>penalties:  You might touch a hot stove and end up with a painful blister; but not glance away for two seconds and spend the rest of your life in a wheelchair.  The people would be stronger, less exhausted.  This path would eliminate <em>mind-destroying</em> pain, and make pleasure more abundant.  Another path would eliminate pain <em>entirely</em>.  Whatever the relative merits of the real-world proposals, <em>fictional stories cannot take the second path.</em>  (<a href="0608.html">Serious Stories</a> [http://lesswrong.com/lw/xi/serious_stories/].)</li> <li>George Orwell once observed that Utopias are chiefly concerned with avoiding fuss.  Don't be afraid to write a loud Eutopia that might wake up the neighbors.  (<a href="0611.html">Eutopia is Scary</a> [http://lesswrong.com/lw/xl/eutopia_is_scary/]; George Orwell's <a href="http://www.orwell.ru/library/articles/socialists/english/e_fun">Why Socialists Don't Believe in Fun</a> [http://www.orwell.ru/library/articles/socialists/english/e_fun].)</li> <li>George Orwell observed that "The inhabitants of perfect universes seem to have no spontaneous gaiety and are usually somewhat repulsive into the bargain."  If you write a story and your characters turn out like this, it probably reflects some much deeper flaw that can't be fixed by having the State hire a few clowns.  (George Orwell's <a href="http://www.orwell.ru/library/articles/socialists/english/e_fun">Why Socialists Don't Believe in Fun</a> [http://www.orwell.ru/library/articles/socialists/english/e_fun].)</li> <li>Ben Franklin, yanked into our own era, would be surprised and delighted by some aspects of his Future.  Other aspects would horrify, disgust, and <em>frighten</em> him; and this is not because our world has gone <em>wrong</em>, but because it has <em>improved </em>relative to his time.  Relatively few things would have gone <em>just </em>as Ben Franklin expected.  If you imagine a world which your imagination finds familiar and comforting, it will inspire few others, and the whole exercise will lack integrity.  Try to conceive of a genuinely better world in which you, yourself, would be <em>shocked </em>(at least at first) and <em>out of place</em> (at least at first).  (<a href="0611.html">Eutopia is Scary</a> [http://lesswrong.com/lw/xl/eutopia_is_scary/].)</li> <li>Utopia and Dystopia are two sides of the same coin; both just confirm the moral sensibilities you started with.  Whether the world is a libertarian utopia of government non-interference, or a hellish dystopia of government intrusion and regulation, you get to say "I was right all along."  Don't just imagine something that conforms to your <em>existing </em>ideals of government, relationships, politics, work, or daily life.  Find the better world that zogs instead of zigging or zagging.  (To safeguard your sensibilities, you can tell yourself it's just an <em>arguably</em> better world but isn't <em>really</em> better than your favorite standard Utopia... but you'll know you're <em>really </em>doing it right if you find your ideals <em>changing</em>.)  (<a href="0612.html">Building Weirdtopia</a> [http://lesswrong.com/lw/xm/building_weirdtopia/].)</li> <li>If your Utopia still seems like an endless gloomy drudgery of existential angst no matter how much you try to brighten it, there's at least one major problem that you're <em>entirely failing to focus on</em>.  (<a href="0422.html">Existential Angst Factory</a> [http://lesswrong.com/lw/sc/existential_angst_factory/].)</li> <li>'Tis a sad mind that cares about nothing except itself.  In the modern-day world, if an altruist looks around, their eye is caught by large groups of people in desperate jeopardy.  People in a better world will <em>not </em>see this:  A true Eutopia will run low on victims to be rescued.  This doesn't imply that the inhabitants look around outside themselves and see <em>nothing</em>.  They may care about friends and family, truth and freedom, common projects; outside minds, shared goals, and high ideals.  (<a href="0622.html">Higher Purpose</a> [http://lesswrong.com/lw/xw/higher_purpose/].)</li> <li>Still, a story that confronts the challenge of Eutopia should <em>not </em>just have the convenient plot of "The Dark Lord Sauron is about to invade and kill everybody".  The would-be author will have to find something <em>slightly less awful </em>for his characters to <em>legitimately care about</em>.  This is part of the challenge of showing that human progress is not the end of human stories, and that people <em>not</em> in imminent danger of death can still lead interesting lives.  Those of you interested in confronting lethal planetary-sized dangers should focus on <em>present-day real life</em>.  (<a href="0622.html">Higher Purpose</a> [http://lesswrong.com/lw/xw/higher_purpose/].)</li> </ol> <p>The simultaneous solution of all these design requirements is left as an exercise to the reader.  At least for now.</p><p>The enumeration in this post of certain Laws shall not be construed to deny or disparage others not mentioned.  I didn't happen to write about humor, but it would be a sad world that held no laughter, etcetera.</p><p>To anyone seriously interested in trying to write a Eutopian story using these Laws:  You must first know <em>how to write</em>.  There are many, many books on how to write; you should read at least three; and they will all tell you that a great deal of practice is required.  Your practice stories should <em>not </em>be composed anywhere so difficult as Eutopia.  That said, my <em>second </em>most important advice for authors is this:  Life will never become boringly easy for your characters so long as they can make things difficult for each other.</p><p>Finally, this dire warning:  <a href="0615.html">Concretely imagining worlds much better than your present-day real life, may suck out your soul like an emotional vacuum cleaner</a> [http://lesswrong.com/lw/xp/seduced_by_imagination/].  (See <a href="0615.html">Seduced by Imagination</a> [http://lesswrong.com/lw/xp/seduced_by_imagination/].)  Fun Theory is dangerous, use it with caution, you have been warned.</p></div> <hr><p><i>Referenced by: </i><a href="0622.html">Higher Purpose</a> &#8226; <a href="0624.html">The Fun Theory Sequence</a> &#8226; <a href="0639.html">The Thing That I Protect</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/y0/31_laws_of_fun/">31 Laws of Fun</a></p></body></html>