<html><head><title>Seduced by Imagination</title></head><body style="width: 600px; margin: 0 auto; font-family: Georgia, serif;"><h1>Seduced by Imagination</h1><p><i>Eliezer Yudkowsky, 16 January 2009 03:10AM</i></p><div><p><strong>Previously in series</strong>:  <a href="0614.html">Justified Expectation of Pleasant Surprises</a> [http://lesswrong.com/lw/xo/justified_expectation_of_pleasant_surprises/]</p> <p>"Vagueness" usually has a <a href="0062.html">bad name</a> [http://lesswrong.com/lw/ic/the_virtue_of_narrowness/] in rationality&#8212;connoting skipped steps in reasoning and attempts to <a href="0054.html">avoid falsification</a> [http://lesswrong.com/lw/i4/belief_in_belief/].  But a rational view of the Future <em>should </em>be vague, because the information we have about the Future is <a href="0553.html">weak</a> [http://lesswrong.com/lw/vz/the_weak_inside_view/].  Yesterday I argued that <a href="0614.html">justified vague hopes</a> [http://lesswrong.com/lw/xo/justified_expectation_of_pleasant_surprises/] might also be better <em>hedonically</em> than specific foreknowledge&#8212;the power of pleasant surprises.</p> <p>But there's also a more severe warning that I must deliver:  It's not a good idea to dwell much <em>on</em> imagined pleasant futures, since you can't actually dwell <em>in </em>them.  It can suck the emotional energy out of your actual, current, ongoing life.</p> <p>Epistemically, we know the Past much more <em>specifically </em>than the Future.  But also on <em>emotional</em> grounds, it's probably wiser to compare yourself to Earth's past, so you can see how far we've come, and how much better we're doing.  Rather than comparing your life to an imagined future, and thinking about how awful you've got it Now.</p> <p>Having set out to explain George Orwell's observation that <a href="http://www.orwell.ru/library/articles/socialists/english/e_fun">no one can seem to write about a Utopia where anyone would want to live</a> [http://www.orwell.ru/library/articles/socialists/english/e_fun]&#8212;having laid out the various Laws of Fun that I believe are being <em>violated </em>in these dreary Heavens&#8212;I am now explaining why you <em>shouldn't</em> apply this knowledge to invent an extremely seductive Utopia and write stories set there.  That may suck out your soul like an emotional vacuum cleaner.</p> <p><a id="more"></a></p> <p>I briefly remarked on this phenomenon <a href="0611.html">earlier</a> [http://lesswrong.com/lw/xl/eutopia_is_scary/], and someone said, "Define 'suck out your soul'."  Well, it's mainly a tactile thing: you can practically <em>feel </em>the pulling sensation, if your dreams wander too far into the Future.  It's like something out of H. P. Lovecraft:  <em>The Call of Eutopia.</em>  A professional hazard of having to stare out into vistas that <em>humans were meant to gaze upon</em>, and knowing <em>a little too much</em> about the lighter side of existence.</p> <p>But for the record, I will now lay out the components of "soul-sucking", that you may recognize the bright abyss and steer your thoughts away:</p> <ul> <li>Your emotional energy drains away into your imagination of Paradise: <ul> <li>You find yourself thinking of it more and more often.</li> <li>The actual challenges of your current existence start to seem less interesting, less compelling; you think of them less and less.</li> <li>Comparing everything to your imagined perfect world heightens your annoyances and diminishes your pleasures.</li> </ul> </li> <li>You go into an <a href="0180.html">affective death spiral</a> [http://lesswrong.com/lw/lm/affective_death_spirals/] around your imagined scenario; you're reluctant to admit anything bad could happen on your assumptions, and you find more and more nice things to say.</li> <li>Your mind begins to forget the difference between fiction and real life: <ul> <li>You originally made many arbitrary or iffy choices in constructing your scenario.  You forget that the Future is actually more unpredictable than this, and that you made your choices using limited foresight and merely human optimizing ability.</li> <li>You forget that, in real life, at least <em>some </em>of your amazing good ideas are <em>guaranteed </em>not to work as well as they do in your imagination.</li> <li>You start wanting the <em>exact specific</em> Paradise you imagined, and worrying about the disappointment if you don't get that <em>exact</em> thing.</li> </ul> </li> </ul> <p>Hope can be a dangerous thing.  And when you've just been hit hard&#8212;at the moment when you most <em>need</em> hope to keep you going&#8212;that's also when the real world seems most painful, and the world of imagination becomes most seductive.</p> <p>It's a balancing act, I think.  One needs enough Fun Theory to truly and legitimately justify hope in the future.  But not a detailed vision so seductive that it steals emotional energy from the real life and real challenge of creating that future.  You need "a light at the end of the secular rationalist tunnel" as <a href="0610.html">Roko put it</a> [http://lesswrong.com/lw/xk/continuous_improvement/], but you don't want people to drift away from their bodies into that light.</p> <p>So <em>how much</em> light is that, exactly?  Ah, now that's the issue.</p> <p>I'll start with a simple and genuine question:  Is what I've already said, enough?</p> <p>Is knowing the abstract fun theory and being able to pinpoint the exact flaws in previous flawed Utopias, enough to make you look forward to tomorrow?  Is it enough to inspire a stronger will to live?  To dispel worries about a long dark tea-time of the soul?  Does it now seem&#8212;on a gut level&#8212;that if we could really build an AI and really shape it, the resulting future would be very much worth staying alive to see?</p> <p> </p> <p style="text-align:right">Part of <a href="0624.html"><em>The Fun Theory Sequence</em></a> [http://lesswrong.com/lw/xy/the_fun_theory_sequence/]</p> <p style="text-align:right">Next post: "<a href="0602.html">The Uses of Fun (Theory)</a> [http://lesswrong.com/lw/xc/the_uses_of_fun_theory/]"</p> <p style="text-align:right">Previous post: "<a href="0614.html">Justified Expectation of Pleasant Surprises</a> [http://lesswrong.com/lw/xo/justified_expectation_of_pleasant_surprises/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq15.html">Sequence 15: Fun Theory</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0614.html">Justified Expectation of Pleasant Surprises</a></p></td><td><p><i>Next: </i><a href="0602.html">The Uses of Fun (Theory)</a></p></td></tr></table><p><i>Referenced by: </i><a href="0602.html">The Uses of Fun (Theory)</a> &#8226; <a href="0614.html">Justified Expectation of Pleasant Surprises</a> &#8226; <a href="0617.html">In Praise of Boredom</a> &#8226; <a href="0619.html">Interpersonal Entanglement</a> &#8226; <a href="0622.html">Higher Purpose</a> &#8226; <a href="0624.html">The Fun Theory Sequence</a> &#8226; <a href="0626.html">31 Laws of Fun</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/xp/seduced_by_imagination/">Seduced by Imagination</a></p></body></html>