<html><head><title>Conversation Halters</title></head><body><h1>Conversation Halters</h1><p><i>Eliezer Yudkowsky, 20 February 2010 03:00PM</i></p><div><p><strong>Related to</strong>:  <a href="0787.html">Logical Rudeness</a> [http://lesswrong.com/lw/1p1/logical_rudeness/], <a href="0079.html">Semantic Stopsigns</a> [http://lesswrong.com/lw/it/semantic_stopsigns/]</p> <p>While working on my book, I found in passing that I'd developed a list of what I started out calling "stonewalls", but have since decided to refer to as "conversation halters".  These tactics of argument are distinguished by their being attempts to <em>cut off the flow of debate</em> - which is rarely the wisest way to think, and should certainly rate an alarm bell.</p> <p>Here's my assembled list, on which I shall expand shortly:</p> <ul> <li>Appeal to permanent unknowability;</li> <li>Appeal to humility;</li> <li>Appeal to egalitarianism;</li> <li>Appeal to common guilt;</li> <li>Appeal to inner privacy;</li> <li>Appeal to personal freedom;</li> <li>Appeal to arbitrariness;</li> <li>Appeal to inescapable assumptions.</li> <li>Appeal to unquestionable authority;</li> <li>Appeal to absolute certainty.</li> </ul> <p>Now all of these might seem like dodgy moves, some dodgier than others.  But they become dodgier still when you take a step back, feel the flow of debate, observe the cognitive traffic signals, and view these as attempts to <em>cut off the flow of further debate.<a id="more"></a></em></p> <p>Hopefully, most of these are obvious, but to define terms:</p> <p><em>Appeal to permanent unknowability</em> - something along the lines of "Why did God allow smallpox?  Well, no one can know the mind of God."  Or, "There's no way to distinguish among interpretations of quantum mechanics, so we'll never know."  Arguments like these can be refuted easily enough by anyone who knows the rules for reasoning under uncertainty and how they imply a correct probability estimate given a state of knowledge... but of course you'll probably have to explain the rules to the other, and the reason they appealed to unknowability is probably to <em>cut off further discussion</em>.</p> <p><em>Appeal to humility</em> - much the same as above, but said with a different emphasis:  "How can <em>we</em> know?", where of course the speaker doesn't much want to know, and so the real meaning is "How can <em>you</em> know?"  Of course one may gather entangled evidence in most such cases, and <a href="http://wiki.lesswrong.com/wiki/Occam%27s_razor">Occam's Razor</a> [http://wiki.lesswrong.com/wiki/Occam%27s_razor] or extrapolation from already-known facts takes care of the other cases.  But you're not likely to get a chance to explain it, because by continuing to speak, you are committing the sin of pride.</p> <p><em>Appeal to egalitarianism</em> - something along the lines of "No one's opinion is better than anyone else's."  Now if you keep talking you're committing <a href="0023.html">an offense against tribal equality</a> [http://lesswrong.com/lw/h9/tsuyoku_vs_the_egalitarian_instinct/].</p> <p><em>Appeal to common guilt</em> - "<a href="0022.html">everyone is irrational</a> [http://lesswrong.com/lw/h8/tsuyoku_naritai_i_want_to_become_stronger/] now and then", so if you keep talking, you're claiming to be better than them.  An implicit subspecies of appeal to egalitarianism.</p> <p><em>Appeal to inner privacy</em> - "you can't possibly know how I feel!"&#160;&#160;It's true that modern technology still encounters some slight difficulties in reading thoughts out of the brain, though work is underway as we speak.  But it is rare that <em>the exact details of how you feel </em>are the <em>key subject matter </em>being disputed.  Here the bony borders of the skull are being redeployed as a hard barrier to keep out further arguments.</p> <p><em>Appeal to personal freedom</em> - "<a href="0279.html">I can define a word any way I want!</a> [http://lesswrong.com/lw/od/37_ways_that_words_can_be_wrong/]"  Now if you keep talking you're infringing on their civil rights.</p> <p><em>Appeal to arbitrariness</em> - again, the notion that <a href="0279.html">word definitions are arbitrary</a> [http://lesswrong.com/lw/od/37_ways_that_words_can_be_wrong/] serves as a good example (in fact I was harvesting some of these appeals from that sequence).  It's not just that this is wrong, but that it serves to cut off further discourse.  Generally, anything that people are motivated to argue about is not <em>arbitrary.</em>  It is being controlled by invisible criteria of evaluation, it has connotations with consequences, and if <em>that</em> isn't true either, the topic of discourse is probably not "arbitrary" but just "meaningless".  No map that corresponds to an external territory can be arbitrary.</p> <p><em>Appeal to inescapable assumptions</em> - closely related, the idea that you need some assumptions and therefore everyone is free to choose whatever assumptions they want.  This again is almost never true.  In the realm of physical reality, reality is one way or another and you don't get to make it that way by choosing an opinion, and so some "assumptions" are right and others wrong.  In the realm of math, once you choose enough axioms to specify the subject matter, the remaining theorems are matters of logical implication.  What I want you to notice is not just that "appeal to inescapable assumptions" is a bad idea, but that it is supposed to halt further conversation.</p> <p><em>Appeal to unquestionable authority </em>- for example, defending a definition by <a href="0257.html">appealing to the dictionary</a> [http://lesswrong.com/lw/nr/the_argument_from_common_usage/], which is supposed to be a final settlement of the argument.  Of course it is very rare that whatever is <em>really</em> at stake is something that ought to turn out differently if a Merriam-Webster editor writes a different definition.  Only in matters of the solidest, most replicable science, do we have information so authoritative that there is no longer much point in considering other sources of evidence.  And even then we shouldn't expect to see strong winds of evidence blowing in an opposing direction - under the Bayesian definition of evidence, strong evidence is just that sort of evidence which you only ever expect to find on at most one side of a factual question.  More usually, this argument runs something along the lines of "How dare you argue with the dictionary?" or "How dare you argue with Professor Picklepumper of Harvard University?"</p> <p><em>Appeal to absolute certainty</em> - if you <em>did</em> have some source of absolute certainty, it would do no harm to cut off debate at that point.  Needless to say, <a href="0245.html">this usually doesn't happen</a> [http://lesswrong.com/lw/nf/the_parable_of_hemlock/].</p> <p>And again:  These appeals are all flawed in their separate ways, but what I want you to notice is the thing they have in common, the stonewall-effect, the conversation-halting cognitive traffic signal.</p> <p>The only time it would <em>actually</em> be appropriate to use such a traffic signal is when you have information so strong, or coverage so complete, that there really is no point in further debate.  This condition is rarely if ever met.  A truly definite series of replicated experiments might settle an issue pending really surprising new experimental results, a la Newton's laws of gravity versus Einstein's GR.  Or a gross prior improbability, combined with failure of the advocates to provide confirming evidence in the face of repeated opportunities to do so.  Or you might simply run out of time.</p> <p>But then you should state the stoppage condition outright and plainly, not package it up in one of these appeals.  By and large, these traffic signals are simply bad traffic signals.</p></div> <hr><p><i>Referenced by: </i><a href="0791.html">"Outside View!" as Conversation-Halter</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/1p2/conversation_halters/">Conversation Halters</a></p></body></html>