<html><head><title>Real-Life Anthropic Weirdness</title></head><body><h1>Real-Life Anthropic Weirdness</h1><p><i>Eliezer Yudkowsky, 05 April 2009 10:26PM</i></p><div><p>In passing, I <a href="0699.html">said</a> [http://lesswrong.com/lw/7k/incremental_progress_and_the_valley]:</p> <blockquote> <p>From a statistical standpoint, lottery winners don't exist - you would never encounter one in your lifetime, if it weren't for the selective reporting.</p> </blockquote> <p>And lo, CronoDAS <a href="0699.html">said</a> [http://lesswrong.com/lw/7k/incremental_progress_and_the_valley/#5dr]:</p> <blockquote> <p>Well... one of my grandmothers' neighbors, whose son I played with as a child, did indeed win the lottery. (AFAIK, it was a relatively modest jackpot, but he did win!)</p> </blockquote> <p>To which I replied:</p> <blockquote> <p>Well, yes, some of the <em>modest</em> jackpots are statistically <em>almost</em> possible, in the sense that on a large enough web forum, someone <em>else's</em> grandmother's neighbor will have won it. Just not your <em>own</em> grandmother's neighbor.</p> <p>Sorry about your statistical anomalatude, CronoDAS - it had to happen to someone, just not me.</p> </blockquote> <p>There's a certain resemblance here - though not an actual analogy - to the strange position your <em>friend</em> ends up in, after <em>you</em> test the Quantum Theory of Immortality.<a id="more"></a></p> <p>For those unfamiliar with QTI, it's a simple simultaneous test of many-worlds plus a particular interpretation of anthropic observer-selection effects:  You put a gun to your head and wire up the trigger to a quantum coinflipper.  After flipping a million coins, if the gun still hasn't gone off, you can be pretty sure of the simultaneous truth of MWI+QTI.</p> <p>But what is your watching <em>friend</em> supposed to think?  Though his predicament is perfectly predictable to <em>you</em> - that is, you expected before starting the experiment to see his confusion - from <em>his</em> perspective it is just a pure 100% unexplained miracle.  What you have reason to believe and what he has reason to believe would now seem separated by an uncrossable gap, which no amount of explanation can bridge.  This is the main plausible exception I know to Aumann's Agreement Theorem.</p> <p>Pity those poor folk who <em>actually win the lottery!</em>  If the hypothesis "this world is a holodeck" is normatively assigned a calibrated confidence well above 10<sup>-8</sup>, the lottery winner now has <em>incommunicable</em> good reason to believe they are in a holodeck.  (I.e. to believe that the universe is such that <em>most</em> conscious observers observe ridiculously improbable positive events.)</p> <p>It's a sad situation to be in - but don't worry: it will always happen to someone <em>else</em>, not <em>you.</em></p></div> <hr><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/7w/reallife_anthropic_weirdness/">Real-Life Anthropic Weirdness</a></p></body></html>