<html><head><title>The Bedrock of Morality: Arbitrary?</title></head><body style="width: 600px; margin: 0 auto; font-family: Georgia, serif;"><h1>The Bedrock of Morality: Arbitrary?</h1><p><i>Eliezer Yudkowsky, 14 August 2008 10:00PM</i></p><div><p><strong>Followup to</strong>:  <a href="0448.html">Is Fairness Arbitrary?</a> [http://lesswrong.com/lw/t2/is_fairness_arbitrary/], <a href="0443.html">Joy in the Merely Good</a> [http://lesswrong.com/lw/sx/inseparably_right_or_joy_in_the_merely_good/],  <a href="0444.html">Sorting Pebbles Into Correct Heaps</a> [http://lesswrong.com/lw/sy/sorting_pebbles_into_correct_heaps/]</p> <p>Yesterday, I presented the idea that when only five people are present, having just stumbled across a pie in the woods (a naturally growing pie, that just popped out of the ground) then it is fair to give Dennis only 1/5th of this pie, even if Dennis persistently claims that it is fair for him to get the whole thing.  Furthermore, it is meta-fair to follow such a symmetrical division procedure, even if Dennis insists that <em>he</em> ought to dictate the division procedure.</p> <p>Fair, meta-fair, or meta-meta-fair, there is no level of fairness where you're obliged to concede everything to Dennis, without reciprocation or compensation, just because he demands it.</p> <p>Which goes to say that fairness has a meaning beyond which "that which everyone can be convinced is 'fair'".  This is an empty proposition, isomorphic to "Xyblz is that which everyone can be convinced is 'xyblz'".  There must be some <em>specific</em> thing of which people are being convinced; and once you identify that thing, it has a meaning beyond agreements and convincing.</p> <p>You're not introducing something <em>arbitrary</em>, something un-fair, in refusing to concede everything to Dennis.  You are being fair, and meta-fair and meta-meta-fair.  As far up as you go, there's no level that calls for unconditional surrender.  The stars do not judge between you and Dennis&#8212;but it <em>is</em> baked into the very question that is asked, when you ask, "What is fair?" as opposed to "What is xyblz?"</p> <p>Ah, but why <em>should </em>you be fair, rather than xyblz?  Let us concede that Dennis cannot validly persuade us, on any level, that it is <em>fair</em> for him to dictate terms and give himself the whole pie; but perhaps he could argue whether we <em>should</em> be fair?</p> <p>The hidden agenda of the whole discussion of fairness, of course, is that good-ness and right-ness and should-ness, ground out similarly to fairness.</p> <p><a id="more"></a></p> <p><a href="0149.html">Natural selection</a> [http://lesswrong.com/lw/kr/an_alien_god/] optimizes for inclusive genetic fitness.  This is not a <a href="0446.html">disagreement</a> [http://lesswrong.com/lw/t0/abstracted_idealized_dynamics/] with humans about what is good.  It is simply that natural selection does not <em>do</em> what is good: it optimizes for inclusive genetic fitness.</p> <p>Well, since some optimization processes optimize for inclusive genetic fitness, instead of what is good, which <em>should</em> we do, ourselves?</p> <p>I know my answer to this question.  It has something to do with natural selection being a terribly wasteful and <a href="0151.html">stupid</a> [http://lesswrong.com/lw/kt/evolutions_are_stupid_but_work_anyway/] and inefficient process.  It has something to do with elephants starving to death in their old age when they wear out their last set of teeth.  It has something to do with natural selection never choosing a single act of mercy, of grace, even when it would cost its purpose nothing: not auto-anesthetizing a wounded and dying gazelle, when its pain no longer serves even the adaptive purpose that first created pain.  Evolution had to happen sometime in the history of the universe, because that's the only way that intelligence could <em>first</em> come into being, without brains to make brains; but now that era is over, and good riddance.</p> <p>But most of all&#8212;why on Earth <em>would</em> any human being think that one <em>ought</em> to optimize inclusive genetic fitness, rather than what is good?  What is even the appeal of this, morally or otherwise?  <em>At all?</em>  I know people who <a href="0054.html">claim</a> [http://lesswrong.com/lw/i4/belief_in_belief/] to think like this, and I wonder what wrong turn they made in their cognitive history, and I wonder how to get them to snap out of it.</p> <p>When we take a step back from fairness, and ask if we <em>should</em> be fair, the answer may not always be yes.  Maybe sometimes we should be merciful.  But if you ask if it is <em>meta-fair</em> to be fair, the answer will generally be yes.  Even if someone else wants you to be unfair in their favor, or claims to disagree about what is "fair", it will still generally be meta-fair to be fair, even if you can't make the Other agree.  By the same token, if you ask if we meta-should do what we should, rather than something else, the answer is yes.  Even if some other agent or optimization process does not do what is right, that doesn't change what is meta-right.</p> <p>And this is not "arbitrary" in the sense of rolling dice, not "arbitrary" in the sense that justification is expected and then not found.  The accusations that I level against evolution are not <em>merely</em> pulled from a hat; they are expressions of morality as I understand it.  They are merely moral, and there is nothing mere about that.</p> <p>In <a href="0447.html">"Arbitrary"</a> [http://lesswrong.com/lw/t1/arbitrary/] I finished by saying:</p> <blockquote> <p>The upshot is that differently structured minds may well label different propositions with their <em>analogues</em> of the internal label "arbitrary"&#8212;though only one of these labels is what <em>you mean</em> when you say "arbitrary", so you and these other agents do not really have a disagreement.</p> </blockquote> <p>This was to help shake people loose of the idea that if any two possible minds can say or do different things, then it must all be arbitrary.  Different minds may have different ideas of what's "arbitrary", so clearly this whole business of "arbitrariness" is arbitrary, and we should ignore it.  After all, Sinned (the anti-Dennis) just always says "Morality isn't arbitrary!" no matter how you try to persuade her otherwise, so clearly you're just being arbitrary in saying that morality is arbitrary.</p> <p>From the perspective of a human, saying that <a href="0444.html">one should sort pebbles into prime-numbered heaps</a> [http://lesswrong.com/lw/sy/sorting_pebbles_into_correct_heaps/] is arbitrary&#8212;it's the sort of act you'd expect to come with a justification attached, but there isn't any justification.</p> <p>From the perspective of a Pebblesorter, saying that one p-should scatter a heap of 38 pebbles into two heaps of 19 pebbles is not p-arbitrary at all&#8212;it's the most p-important thing in the world, and fully p-justified by the intuitively obvious fact that a heap of 19 pebbles is p-correct and a heap of 38 pebbles is not.</p> <p>So which perspective should we adopt?  I answer that I see no reason at all why I should start sorting pebble-heaps.  It strikes me as a completely pointless activity.  Better to engage in art, or music, or science, or heck, better to connive political plots of terrifying dark elegance, than to sort pebbles into prime-numbered heaps.  A galaxy transformed into pebbles and sorted into prime-numbered heaps would be just plain boring.</p> <p>The Pebblesorters, of course, would only reason that music is p-pointless because it doesn't help you sort pebbles into heaps; the human activity of humor is not only p-pointless but just plain p-bizarre and p-incomprehensible; and most of all, the human vision of a galaxy in which agents are running around experiencing positive reinforcement <em>but not sorting any pebbles,</em> is a vision of an utterly p-arbitrary galaxy devoid of p-purpose.  The Pebblesorters would gladly sacrifice their lives to create a P-Friendly AI that sorted the galaxy on their behalf; it would be the most p-profound statement they could make about the p-meaning of their lives.</p> <p>So which of these two perspectives do I choose?  The human one, of course; not because it is the human one, but because it is <em>right.</em>  I do not know perfectly what is right, but <a href="0421.html">neither can I plead entire ignorance</a> [http://lesswrong.com/lw/sb/could_anything_be_right/].</p> <p>And the Pebblesorters, <em>who simply are not built to do what is right,</em> choose the Pebblesorting perspective: not merely because it is theirs, or because they think they can get away with being p-arbitrary, but because that is what is p-right.</p> <p>And in fact, both we and the Pebblesorters can <em>agree</em> on all these points.  We can agree that sorting pebbles into prime-numbered heaps is arbitrary and unjustified, but not p-arbitrary or p-unjustified; that it is the sort of thing an agent p-should do, but not the sort of thing an agent should do.</p> <p>I fully expect that even if there is other life in the universe only a few trillions of lightyears away (I don't think it's local, or we would have seen it by now), that we humans are the only creatures for a long long way indeed who are built to do what is <em>right</em>.  That may be a <a href="0420.html">moral miracle</a> [http://lesswrong.com/lw/sa/the_gift_we_give_to_tomorrow/], but it is not a causal miracle.</p> <p>There may be some other evolved races, a sizable fraction perhaps, maybe even a majority, who do some right things.  Our <a href="0158.html">executing adaptation</a> [http://lesswrong.com/lw/l0/adaptationexecuters_not_fitnessmaximizers/] of compassion is not so far removed from the game theory that gave it birth; it might be a common adaptation.  But laughter, I suspect, may be rarer by far than mercy.  What would a galactic civilization be like, if it had sympathy, but never a moment of humor?  A little more boring, perhaps, by our standards.</p> <p>This humanity that we find ourselves in, is a great gift.  It may not be a great p-gift, but who cares about p-gifts?</p> <p>So I really must deny the charges of moral relativism:  I don't think that human morality is arbitrary at all, and I would expect any logically omniscient reasoner to agree with me on that.  We are better than the Pebblesorters, because we care about sentient lives, and the Pebblesorters don't.  Just as the Pebblesorters are p-better than us, because they care about pebble heaps, and we don't.  Human morality is p-arbitrary, but who cares?  P-arbitrariness is arbitrary.</p> <p>You've just got to avoid thinking that the words "better" and "p-better", or "moral" and "p-moral", are  <em>talking about the same thing</em>&#8212;because then you might think that the Pebblesorters were coming to different conclusions than us about <em>the same thing</em>&#8212;and then you might be tempted to think that our own morals were arbitrary.  Which, of course, they're not.</p> <p>Yes, I really truly do believe that humanity is better than the Pebblesorters!  I am not being sarcastic, I really do believe that.  I am not playing games by redefining "good" or "arbitrary", I think I mean the same thing by those terms as everyone else.  When you understand that I am genuinely sincere about that, you will understand my metaethics.  I really <em>don't</em> consider myself a moral relativist&#8212;not even in the slightest!</p> <p> </p> <p style="text-align:right">Part of <a href="http://wiki.lesswrong.com/wiki/Metaethics_sequence"><em>The Metaethics Sequence</em></a> [http://wiki.lesswrong.com/wiki/Metaethics_sequence]</p> <p style="text-align:right">Next post: "<a href="0454.html">You Provably Can't Trust Yourself</a> [http://lesswrong.com/lw/t8/you_provably_cant_trust_yourself/]"</p> <p style="text-align:right">Previous post: "<a href="0448.html">Is Fairness Arbitrary?</a> [http://lesswrong.com/lw/t2/is_fairness_arbitrary/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq14.html">Sequence 14: Metaethics</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0448.html">Is Fairness Arbitrary?</a></p></td><td><p><i>Next: </i><a href="0454.html">You Provably Can't Trust Yourself</a></p></td></tr></table><p><i>Referenced by: </i><a href="0448.html">Is Fairness Arbitrary?</a> &#8226; <a href="0450.html">Hot Air Doesn't Disagree</a> &#8226; <a href="0454.html">You Provably Can't Trust Yourself</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/t3/the_bedrock_of_morality_arbitrary/">The Bedrock of Morality: Arbitrary?</a></p></body></html>