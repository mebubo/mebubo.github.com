<html><head><title>Help Fund Lukeprog at SIAI</title></head><body style="width: 600px; margin: 0 auto; font-family: Georgia, serif;"><h1>Help Fund Lukeprog at SIAI</h1><p><i>Eliezer Yudkowsky, 24 August 2011 07:16AM</i></p><div><p>Singularity Institute desperately needs someone who is not me who can write cognitive-science-based material. Someone smart, energetic, able to speak to popular audiences, and with an excellent command of the science. If you&#8217;ve been reading Less Wrong for the last few months, you probably just thought the same thing I did: &#8220;SIAI should hire Lukeprog!&#8221; To support Luke Muelhauser becoming a full-time Singularity Institute employee, please <a href="http://intelligence.org/donate/">donate</a> [http://intelligence.org/donate/] and mention Luke (e.g. &#8220;Yay for Luke!&#8221;) in the check memo or the comment field of your donation - or if you donate by a method that doesn&#8217;t allow you to leave a comment, tell Louie Helm (louie@intelligence.org) your donation was to help fund Luke.</p> <p>Note that the <a href="http://intelligence.org/2011summerchallenge">Summer Challenge</a> [http://intelligence.org/2011summerchallenge] that doubles all donations will run until August 31st. (We're currently at $31,000 of $125,000.)<a id="more"></a></p> <p>During his stint as a Singularity Institute Visiting Fellow, Luke has already:</p> <ul> <li>Co-organized and taught sessions for a well-received one-week <a href="http://lesswrong.com/lw/5ec/minicamp_on_rationality_awesomeness_and/">Rationality Minicamp</a> [http://lesswrong.com/lw/5ec/minicamp_on_rationality_awesomeness_and/], and taught sessions for the nine-week Rationality Boot Camp.</li> <li>Written many <a href="http://commonsenseatheism.com/?p=13954">helpful and well-researched</a> [http://commonsenseatheism.com/?p=13954] articles for Less Wrong on metaethics, rationality theory, and rationality practice, including the 20-page tutorial <em><a href="http://lesswrong.com/lw/71x/a_crash_course_in_the_neuroscience_of_human/">A Crash Course in the Neuroscience of Human Motivation</a> [http://lesswrong.com/lw/71x/a_crash_course_in_the_neuroscience_of_human/]</em>.</li> <li>Written a new <a href="http://intelligence.org/singularityfaq">Singularity FAQ</a> [http://intelligence.org/singularityfaq].</li> <li>Published an intelligence explosion <a href="http://intelligenceexplosion.com/">website</a> [http://intelligenceexplosion.com/] for academics.</li> <li>...and completed many smaller projects.</li> </ul> <p>As a full-time Singularity Institute employee, Luke could:</p> <ul> <li>Author and co-author research papers and outreach papers, including <ul> <li>A chapter already accepted to Springer&#8217;s <em><a href="http://singularityhypothesis.blogspot.com/">The Singularity Hypothesis</a> [http://singularityhypothesis.blogspot.com/]</em> volume (co-authored with Louie Helm).</li> <li>A paper on existential risk and optimal philanthropy, co-authored with a Columbia University researcher.</li> </ul> </li> <li>Continue to write articles for Less Wrong on the theory and practice of rationality.</li> <li>Write a report that summarizes unsolved problems related to Friendly AI.</li> <li>Continue to develop his <a href="http://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics">metaethics sequence</a> [http://wiki.lesswrong.com/wiki/No-Nonsense_Metaethics], the conclusion of which will be a sort of <a href="http://en.wikipedia.org/wiki/Timothy_Gowers#Polymath_Project">Polymath Project</a> [http://en.wikipedia.org/wiki/Timothy_Gowers#Polymath_Project] for collaboratively solving open problems in metaethics relevant to FAI development.</li> <li>Teach courses on rationality and social effectiveness, as he has been doing for the Singularity Institute&#8217;s <a href="http://lesswrong.com/lw/5ec/minicamp_on_rationality_awesomeness_and/">Rationality Minicamp</a> [http://lesswrong.com/lw/5ec/minicamp_on_rationality_awesomeness_and/] and <a href="http://lesswrong.com/lw/4wm/rationality_boot_camp/">Rationality Boot Camp</a> [http://lesswrong.com/lw/4wm/rationality_boot_camp/].</li> <li>Produce introductory materials to help bridge <a href="http://wiki.lesswrong.com/wiki/Inferential_distance">inferential gaps</a> [http://wiki.lesswrong.com/wiki/Inferential_distance], as he did with the <a href="http://intelligence.org/singularityfaq">Singularity FAQ</a> [http://intelligence.org/singularityfaq].</li> <li>Raise awareness of AI risk and the uses of rationality by giving talks at universities and technology companies, as he recently did at <a href="http://halcyonmolecular.com/">Halcyon Molecular</a> [http://halcyonmolecular.com/].</li> </ul> <p>If you&#8217;d like to help us fund Luke Muehlhauser to do all that and probably more, please <a href="http://intelligence.org/donate/">donate now</a> [http://intelligence.org/donate/] and include the word &#8220;Luke&#8221; in the comment field.  And if you donate before August 31st, your donation will be doubled as part of the <a href="http://intelligence.org/2011summerchallenge">2011 Summer Singularity Challenge</a> [http://intelligence.org/2011summerchallenge].</p></div> <hr><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/78s/help_fund_lukeprog_at_siai/">Help Fund Lukeprog at SIAI</a></p></body></html>