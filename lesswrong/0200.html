<html><head><title>Effortless Technique</title></head><body><h1>Effortless Technique</h1><p><i>Eliezer Yudkowsky, 23 December 2007 04:22AM</i></p><div><blockquote><p>"All my life I have been intensely repelled by the idea of 'making an effort'.  I hate this idea today as much as I did as a child.  I don't know why I hate it so much; I just do."<br>  &#160;&#160; &#160;&#160; &#160;&#160; -- Raymond Smullyan, <em>The Tao Is Silent</em></p></blockquote><p>In the Hollywood version of rationality - or even the Traditional rationality that was passed down from supervisor to grad student in ancient days before Bayesianism - rationality is a great strain, a great effort, a continuous battle to coerce your mind into a desired shape.  Spock, the archetype of Hollywood's concept of rationality, represses <em>all</em> his <a href="0039.html">emotions</a> [http://lesswrong.com/lw/hp/feeling_rational/]. </p> <p>And this great effort, they conceive, is virtue unto a rationalist.  The more effort you expend on forcing yourself into the mold, the better the rationalist you must be.  It's like working extra hard at your job, as demanded by the Protestant work-ethic.  If the one works long hours - sweating, getting ulcers - surely the one must be worthy of praise?</p><a id="more"></a><p>This, I think, is an instance of a <a href="0172.html">Lost Purpose</a> [http://lesswrong.com/lw/le/lost_purposes/].  People see that successful folk must sometimes make an effort, and so they conclude that effort of itself is virtuous whether or not it succeeds.</p> <p>I am reminded of an AI koan from AGI '06, where the discussion turned (as it often does) to defining "intelligence".  A medium-prominent AI researcher suggested that an agent's "intelligence" could be measured in the agent's processing cycles per second, bits of memory, and bits of sensory bandwidth.  To which I replied with a quote from <a href="http://www.cs.utexas.edu/users/EWD/transcriptions/EWD10xx/EWD1036.html">Dijkstra</a> [http://www.cs.utexas.edu/users/EWD/transcriptions/EWD10xx/EWD1036.html]:</p><blockquote><p>"If we wish to count lines of code, we should not regard them as 'lines produced' but as 'lines spent': the current conventional wisdom is so foolish as to book that count on the wrong side of the ledger."</p></blockquote><p>Surely (I said), an agent is <em>less</em> intelligent if it uses <em>more</em> memory, processing power, and sensory bandwidth to accomplish the same task?</p> <p>This reply was due, in no small part, to my having read Raymond Smullyan's <em>The Tao Is Silent</em> at the age of sixteen.  <a href="http://en.wikipedia.org/wiki/Raymond_Smullyan">Raymond Smullyan</a> [http://en.wikipedia.org/wiki/Raymond_Smullyan] is a mathematical logician, a great composer of logic puzzles, and sometime Westernized Taoist.  Though I disagree with much of <em>The Tao Is Silent,</em> I would count "just the parts of the book I liked" as one of my most important formative influences as a rationalist.</p> <p>In particular, it was in <em>The Tao Is Silent</em> that I first encountered the Taoistic principles of spontaneity, working with rather than against the nature of things, human goodness as a distinct phenomenon from the heavy weight of dutiful moral obligation, and above all, <em>wei wu wei</em>, "acting through not acting".</p> <p>Smullyan's Taoism was more inspiration than instruction, but it was <em>important</em> inspiration.  I matured as a rationalist while keeping firmly in mind that my "rationality" was not measured by <em>how much</em> effort I expended on proper thinking, but rather <em>how little.</em></p> <p>You can see this same view manifested in these lines from <a href="http://yudkowsky.net/bayes/truth.html">The Simple Truth</a> [http://yudkowsky.net/bayes/truth.html]:</p><blockquote><p>  &#160;&#160; &#160;&#160; "You have to throw in a pebble <em>every</em> time a sheep leaves through the gate?" says Mark.  "Take out a pebble <em>every</em> time a sheep returns?"<br>  &#160;&#160; &#160;&#160; Autrey nods.  "Yeah."<br>  &#160;&#160; &#160;&#160; "That must be really hard," Mark says sympathetically.<br>  &#160;&#160; &#160;&#160; Autrey brightens, soaking up Mark's sympathy like rain.  "Exactly!" says Autrey.  "It's <em>extremely</em> hard on your emotions.  When the bucket has held its level for a while, you... tend to get attached to that level."<br>  &#160;&#160; &#160;&#160; A sheep passes then, leaving through the gate. Autrey sees; he stoops, picks up a pebble, holds it aloft in the air. "Behold!" Autrey proclaims. "A sheep has passed! I must now toss a pebble into this bucket, my dear bucket, and destroy that fond level which has held for so long -" Another sheep passes. Autrey, caught up in his drama, misses it; so I plunk a pebble into the bucket. Autrey is still speaking: "- for that is the supreme test of the shepherd, to throw in the pebble, be it ever so agonizing, be the old level ever so precious. Indeed, only the best of shepherds can meet a requirement so stern -"<br>  &#160;&#160; &#160;&#160; "Autrey," I say, "if you want to be a great shepherd someday, learn to shut up and throw in the pebble. No fuss. No drama. Just do it." </p></blockquote><p>Long ago - I think I must have been pretty young - I decided to move my limbs with maximum "efficiency", to save effort.  I might even have been thinking of Vulcans.</p> <p>So I tried what my youthful mind wordlessly conceived of as "efficiency":  I tried to move my limbs in perfectly straight lines as quickly as possible, with corresponding sudden stops and sudden starts.</p> <p>"Efficiency" didn't feel very efficient.  The sudden starts and sudden stops took effort.  Moving my hand in a straight line forced my elbow and shoulder to move in strange curves.</p> <p>You can buy books that teach this same life lesson, but they use a lot more pages.</p> <p>Now this is scarcely Taoism, at least so far as philosophical premises are concerned.  According to authentic Taoism, you can exert no effort at all while accomplishing all worthwhile things.  This seems to me around as plausible as an agent that achieves its utility function using zero computing power and is therefore maximally intelligent.  The only way you could do it is if the agent assigns constant utility to all outcomes, or if the utility function's maximum is set by sleight of hand to wherever the universe goes anyway.  This may be why I am not a Taoist:  "A maximally intelligent agent with zero computing power and no utility function" sounds like a good metaphor for the Tao.  I object to a metric of intelligence that makes me dumber than a rock.</p> <p>According to Taoism, everyone ought to act in accordance with their natures.  One can scarcely see how it could be otherwise.  I think this religion only appears nontrivial because of selective failure to consider all its consequences.</p> <p>In any case, my own nature is to make certain efforts even if they seem unpleasant.  Therefore I have no objection to making an effort now and then.</p> <p>But one should not think that force, effort, and control are virtuous unto a rationalist - that would book them on the wrong side of the ledger.</p> <p><strong>Addendum</strong>:  Before anyone else points it out:  Yes, I know that my critique of Taoism is appallingly simplistic and that the Taoists are well aware of it.  That doesn't make it wrong.<br> </p></div> <hr><p><i>Referenced by: </i><a href="0201.html">Zen and the Art of Rationality</a> &#8226; <a href="0523.html">Inner Goodness</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/m6/effortless_technique/">Effortless Technique</a></p></body></html>