<html><head><title>Intelligence in Economics</title></head><body><h1>Intelligence in Economics</h1><p><i>Eliezer Yudkowsky, 30 October 2008 09:17PM</i></p><div><p><strong>Followup to</strong>:  <a href="0530.html">Economic Definition of Intelligence?</a> [http://lesswrong.com/lw/vc/economic_definition_of_intelligence/]</p> <p>After I challenged Robin to show how economic concepts can be useful in defining or measuring intelligence, Robin <a href="http://www.overcomingbias.com/2008/10/does-intelligen.html">responded</a> [http://www.overcomingbias.com/2008/10/does-intelligen.html] by - as I interpret it - challenging me to show why a generalized concept of "intelligence" is any use in economics.</p> <p>Well, I'm not an economist (as you may have noticed) but I'll try to respond as best I can.</p> <p>My primary view of the world tends to be through the lens of AI.  If I talk about economics, I'm going to try to subsume it into notions like expected utility maximization (I manufacture lots of copies of something that I can use to achieve my goals) or information theory (if you manufacture lots of copies of something, my probability of seeing a copy goes up).  This subsumption isn't meant to be some kind of challenge for academic supremacy - it's just what happens if you ask an AI guy an econ question.</p> <p>So first, let me describe what I see when I look at economics:</p> <p>I see a special case of game theory in which some interactions are <em>highly regular and repeatable:</em>  You can take 3 units of steel and 1 unit of labor and make 1 truck that will transport 5 units of grain between Chicago and Manchester once per week, and agents can potentially do this <em>over and over</em> again.  If the numbers aren't <em>constant,</em> they're at least <em>regular</em> - there's diminishing marginal utility, or supply/demand curves, rather than rolling random dice every time.  Imagine economics if no two elements of reality were fungible - you'd just have a huge incompressible problem in non-zero-sum game theory.</p> <p>This may be, for example, why we don't think of scientists writing papers that build on the work of other scientists in terms of an <em>economy of science papers</em> - if you turn an economist loose on science, they may measure scientist salaries paid in fungible dollars, or try to see whether scientists trade countable citations with each other.  But it's much less likely to occur to them to analyze the way that units of scientific knowledge are produced from previous units plus scientific labor.  Where information is concerned, two identical copies of a file are the same information as one file.  So every unit of <em>knowledge</em> is unique, non-fungible, and so is each act of production.  There isn't even a common currency that measures how much a given paper contributes to human knowledge.  (<a href="0141.html">I don't know what economists don't know</a> [http://lesswrong.com/lw/kj/no_one_knows_what_science_doesnt_know/], so do correct me if this is actually extensively studied.)</p> <p>Since "intelligence" deals with an informational domain, building a bridge from it to economics isn't trivial - but where do factories come from, anyway?  Why do humans get a higher return on capital than chimpanzees?</p><a id="more"></a><p>I see two basic bridges between intelligence and economics.</p> <p>The first bridge is the role of intelligence in economics: the way that steel is put together into a truck involves choosing one out of an exponentially vast number of possible configurations.  With a more clever configuration, you may be able to make a truck using less steel, or less labor.  Intelligence also plays a role at a larger scale, in deciding whether or not to buy a truck, or where to invest money.  We may even be able to talk about something akin to optimization at a macro scale, the degree to which the whole economy has put itself together in a special configuration that earns a high rate of return on investment.  (Though this introduces problems for <a href="0528.html">my own formulation</a> [http://lesswrong.com/lw/va/measuring_optimization_power/], as I assume a central preference ordering / utility function that an economy doesn't possess - still, deflated monetary valuations seem like a good proxy.)</p> <p>The second bridge is the role of economics in intelligence: if you jump up a meta-level, there are <em>repeatable cognitive algorithms</em> underlying the production of unique information.  These cognitive algorithms use some resources that are fungible, or at least <em>material</em> enough that you can only use the resource on one task, creating a problem of opportunity costs.  (A unit of time will be an example of this for almost any algorithm.)  Thus we have <a href="0530.html">Omohundro's resource balance principle</a> [http://lesswrong.com/lw/vc/economic_definition_of_intelligence/], which says that the inside of an efficiently organized mind should have a common currency in expected utilons.</p> <p>Says Robin:</p><blockquote><p>'Eliezer has <a href="0530.html">just raised the issue</a> [http://lesswrong.com/lw/vc/economic_definition_of_intelligence/] of how to define "intelligence", a concept he clearly wants to apply to a very wide range of possible systems.  He wants a quantitative concept that is "not parochial to humans," applies to systems with very "different utility functions," and that summarizes the system's performance over a broad "not ... narrow problem domain."  My main response is to note that this may just not be possible.  I have no objection to looking, but it is not obvious that there is any such useful broadly-applicable "intelligence" concept.'</p></blockquote><p>Well, one might run into some trouble assigning a total ordering to all intelligences, as opposed to a partial ordering.  But that intelligence as a <em>concept</em> is useful - especially the way that I've <a href="0529.html">defined it</a> [http://lesswrong.com/lw/vb/efficient_crossdomain_optimization/] - that I must strongly defend.  Our current science has advanced further on some problems than others.  Right now, there is better understanding of the steps carried out to construct a car, than the cognitive algorithms that invented the unique car design.  But they are both, to some degree, regular and repeatable; <a href="0395.html">we don't all have different brain architectures</a> [http://lesswrong.com/lw/rl/the_psychological_unity_of_humankind/].</p> <p>I generally <a href="0359.html">inveigh against focusing on relatively minor between-human variations when discussing "intelligence"</a> [http://lesswrong.com/lw/ql/my_childhood_role_model/].  It is controversial what role is played in the modern economy by such variations in whatever-IQ-tests-try-to-measure.  Anyone who denies that <em>some</em> such a role exists would be a poor deluded fool indeed.  But, on the whole, we needn't expect "the role played by IQ variations" to be at all the same sort of question as "the role played by intelligence".</p> <p>You will surely find no cars, if you take away the mysterious "intelligence" that produces, from out of a vast exponential space, the <em>information</em> that describes one particular configuration of steel etc. constituting a <em>car design</em>.  Without optimization to conjure certain informational patterns out of vast search spaces, the modern economy evaporates like a puff of smoke.</p> <p>So you need some account of where the car design comes from.</p> <p>Why should you try to give the same account of "intelligence" across different domains?  When someone designs a car, or an airplane, or a hedge-fund trading strategy, aren't these different designs?</p> <p>Yes, they are different informational goods.</p> <p>And wasn't it a different set of skills that produced them?  You can't just take a car designer and plop them down in a hedge fund.</p> <p>True, but where did the different skills come from?</p> <p>From going to different schools.</p> <p>Where did the different schools come from?</p> <p>They were built by different academic lineages, compounding knowledge upon knowledge within a line of specialization.</p> <p>But where did so many different academic lineages come from?  And how is this trick of "compounding knowledge" repeated over and over?</p> <p>Keep moving meta, and you'll find a regularity, something repeatable: you'll find humans, with common human genes that construct common human brain architectures.</p> <p>No, not every discipline puts the same relative strain on the same brain areas.  But they are all using human parts, manufactured by mostly-common DNA.  Not all the adult brains are the same, but they learn into unique adulthood starting from a <em>much more regular</em> underlying set of <em>learning algorithms</em>.  We should expect less variance in infants than in adults.</p> <p>And all the adaptations of the human brain were produced by the (relatively much structurally simpler) processes of natural selection.  Without that <a href="0151.html">earlier and less efficient</a> [http://lesswrong.com/lw/kt/evolutions_are_stupid_but_work_anyway/] optimization process, there wouldn't be a human brain design, and hence no human brains.</p> <p>Subtract the human brains executing repeatable cognitive algorithms, and you'll have no unique adulthoods produced by learning; and no grown humans to invent the cultural concept of science; and no chains of discoveries that produce scientific lineages; and no engineers who attend schools; and no unique innovative car designs; and thus, no cars.</p> <p>The moral being that you can generalize across domains, if you keep tracing back the causal chain and keep going meta.</p> <p>It may be harder to talk about "intelligence" as a common factor in the full causal account of the economy, as to talk about the repeated operation that puts together many instantiations of the same car design - but there <em>is</em> a common factor, and the economy could hardly exist without it.</p> <p>As for generalizing away from humans - well, what part of the notion of "efficient cross-domain optimization" <em>ought</em> to apply only to humans?</p></div> <hr><p><i>Referenced by: </i><a href="0553.html">The Weak Inside View</a> &#8226; <a href="0559.html">Cascades, Cycles, Insight...</a> &#8226; <a href="0570.html">Permitted Possibilities, &amp; Locality</a> &#8226; <a href="0606.html">Emotional Involvement</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/vd/intelligence_in_economics/">Intelligence in Economics</a></p></body></html>