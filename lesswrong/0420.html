<html><head><title>The Gift We Give To Tomorrow</title></head><body style="width: 600px; margin: 0 auto; font-family: Georgia, serif;"><h1>The Gift We Give To Tomorrow</h1><p><i>Eliezer Yudkowsky, 17 July 2008 06:07AM</i></p><div><p><strong>Followup to</strong>:  <a href="0161.html">Thou Art Godshatter</a> [http://lesswrong.com/lw/l3/thou_art_godshatter/], <a href="0293.html">Joy in the Merely Real</a> [http://lesswrong.com/lw/or/joy_in_the_merely_real/], <a href="0408.html">Is Morality Given?</a> [http://lesswrong.com/lw/ry/is_morality_given/], <a href="0415.html">Rebelling Within Nature</a> [http://lesswrong.com/lw/s5/rebelling_within_nature/]<a href="0159.html"> </a> [http://lesswrong.com/lw/l1/evolutionary_psychology/]</p> <p>How, oh how, did an unloving and mindless universe, cough up minds who were capable of love?</p> <p>"No mystery in that," you say, "it's just a matter of <a href="0149.html">natural selection</a> [http://lesswrong.com/lw/kr/an_alien_god/]."</p> <p>But natural selection is <a href="0149.html">cruel, bloody, and bloody stupid</a> [http://lesswrong.com/lw/kr/an_alien_god/].  Even when, on the surface of things, biological organisms aren't <em>directly</em> fighting each other&#8212;aren't <em>directly</em> tearing at each other with claws&#8212;there's still a deeper competition going on between the genes.  Genetic information is created when genes increase their <em>relative</em> frequency in the next generation&#8212;what matters for "genetic fitness" is not how many children you have, but that you have <em>more</em> children than others.  It is quite possible for a species to <a href="0163.html">evolve to extinction</a> [http://lesswrong.com/lw/l5/evolving_to_extinction/], if the winning genes are playing negative-sum games.</p> <p>How, oh how, could such a process create beings capable of love?</p> <p>"No mystery," you say, "there is never any mystery-in-the-world; <a href="0080.html">mystery is a property of questions, not answers</a> [http://lesswrong.com/lw/iu/mysterious_answers_to_mysterious_questions/].  A mother's children share her genes, so the mother loves her children."</p> <p><a id="more"></a></p> <p>But sometimes mothers adopt children, and still love them.  And mothers love their children for themselves, not for their genes.</p> <p>"No mystery," you say, "Individual organisms are <a href="0158.html">adaptation-executers, not fitness-maximizers</a> [http://lesswrong.com/lw/l0/adaptationexecuters_not_fitnessmaximizers/].  <span style="text-decoration: underline;"> </span><a href="0159.html">Evolutionary psychology</a> [http://lesswrong.com/lw/l1/evolutionary_psychology/] is not about deliberately maximizing fitness&#8212;through most of human history, we didn't know genes existed.  We don't calculate our acts' effect on genetic fitness consciously, or even subconsciously."</p> <p>But human beings form friendships even with non-relatives: how, oh how, can it be?</p> <p>"No mystery, for hunter-gatherers often play Iterated Prisoner's Dilemmas, the solution to which is reciprocal altruism.  Sometimes the most dangerous human in the tribe is not the strongest, the prettiest, or even the smartest, but the one who has the most allies."</p> <p>Yet not all friends are fair-weather friends; we have a concept of true friendship&#8212;and some people have sacrificed their life for their friends.  Would not such a devotion tend to remove itself from the gene pool?</p> <p>"You said it yourself: we have a concept of true friendship and fair-weather friendship.  We can tell, or try to tell, the difference between someone who considers us a valuable ally, and someone executing the friendship adaptation.  We wouldn't be true friends with someone who we didn't think was a true friend to us&#8212;and someone with many <em>true </em>friends is far more formidable than someone with many fair-weather allies."</p> <p>And Mohandas Gandhi, who really did turn the other cheek?  Those who try to serve all humanity, whether or not all humanity serves them in turn?</p> <p>"That perhaps is a more complicated story.  Human beings are not just social animals.  We are political animals who argue linguistically about policy in adaptive tribal contexts.  Sometimes the formidable human is not the strongest, but the one who can most skillfully argue that their preferred policies match the preferences of others."</p> <p>Um... that doesn't explain Gandhi, or am I missing something?</p> <p>"The point is that we have the ability to <em>argue</em> about 'What should be done?' as a <em>proposition</em>&#8212;we can make those arguments and respond to those arguments, without which politics could not take place."</p> <p>Okay, but Gandhi?</p> <p>"Believed certain complicated propositions about 'What should be done?' and did them."</p> <p>That sounds like it could <a href="0076.html">explain any possible</a> [http://lesswrong.com/lw/iq/guessing_the_teachers_password/] human behavior.</p> <p>"If we traced back the chain of causality through all the arguments, it would involve: a moral architecture that had the ability to argue <em>general abstract </em>moral propositions like 'What should be done to people?'; appeal to hardwired intuitions like fairness, a concept of duty, pain aversion + empathy; something like a preference for simple moral propositions, probably reused from our previous Occam prior; and the end result of all this, plus perhaps memetic selection effects, was 'You should not hurt people' in full generality&#8212;"</p> <p>And that gets you Gandhi.</p> <p>"Unless you think it was magic, it has to fit into the lawful causal development of the universe somehow."</p> <p>Well... I certainly won't postulate magic, <a href="0081.html">under any name</a> [http://lesswrong.com/lw/iv/the_futility_of_emergence/].</p> <p>"Good."</p> <p>But come on... doesn't it seem a little... <em>amazing</em>... that hundreds of millions of years worth of evolution's death tournament could cough up mothers and fathers, sisters and brothers, husbands and wives, steadfast friends and honorable enemies, true altruists and guardians of causes, police officers and loyal defenders, even artists sacrificing themselves for their art, all practicing so many kinds of love?  For <a href="0161.html">so many things other than genes</a> [http://lesswrong.com/lw/l3/thou_art_godshatter/]?  Doing their part to make their world less ugly, something besides a sea of blood and violence and mindless replication?</p> <p>"Are you claiming to be surprised by this?  If so, <a href="0042.html">question your underlying model, for it has led you to be surprised by the true state of affairs</a> [http://lesswrong.com/lw/hs/think_like_reality/].  Since the beginning, not one unusual thing has ever happened."</p> <p>But how is it <em>not</em> surprising?</p> <p>"What are you suggesting, that some sort of shadowy figure stood behind the scenes and directed evolution?"</p> <p>Hell no.  But&#8212;</p> <p>"Because if you <em>were</em> suggesting that, I would have to ask how that shadowy figure <em>originally</em> decided that love was a <em>desirable</em> outcome of evolution.  I would have to ask where that figure got preferences that included things like love, friendship, loyalty, fairness, honor, romance, and so on.  On evolutionary psychology, we can see how <em>that specific outcome</em> came about&#8212;how <em>those particular goals rather than others</em> were <em>generated in the first place.</em>  You can call it 'surprising' all you like.  But when you really do understand evolutionary psychology, you can see how parental love and romance and honor, and even true altruism and moral arguments, <em>bear the specific design signature of natural selection</em> in particular adaptive contexts of the hunter-gatherer savanna.  So if there was a shadowy figure, it must itself have evolved&#8212;and that obviates the whole point of postulating it."</p> <p>I'm not postulating a shadowy figure!  I'm just asking how human beings ended up so <em>nice.</em></p> <p>"<em>Nice!</em>  Have you <em>looked </em>at this planet lately?  We also bear all those other emotions that evolved, too&#8212;which would tell you very well that we evolved, should you begin to doubt it.  Humans aren't always nice."</p> <p>We're one hell of a lot nicer than the process that produced us, which lets elephants starve to death when they run out of teeth, and doesn't anesthetize a gazelle even as it lays dying and is of no further importance to evolution one way or the other.  It doesn't take much to be nicer than evolution.  To have the <em>theoretical capacity</em> to make one single gesture of mercy, to feel a single twinge of empathy, is to be nicer than evolution.  How did evolution, which is itself so uncaring, create minds on that qualitatively higher moral level than itself?  How did evolution, which is so ugly, end up doing anything so<em> beautiful?</em></p> <p>"Beautiful, you say?  Bach's <em>Little Fugue in G Minor</em> may be beautiful, but the sound waves, as they travel through the air, are not stamped with tiny tags to specify their beauty.  If you wish to find <em>explicitly encoded</em> a measure of the fugue's beauty, you will have to look at a human brain&#8212;nowhere else in the universe will you find it.  Not upon the seas or the mountains will you find such judgments written: they are not minds, they cannot think."</p> <p>Perhaps that is so, but still I ask:  How did evolution end up doing anything so beautiful, as giving us the ability to admire the beauty of a flower?</p> <p>"Can you not see the circularity in your question?  If beauty were like some great light in the sky that shined from outside humans, then your question might make sense&#8212;though there would still be the question of how humans came to perceive that light.  You evolved with a psychology unlike evolution:  Evolution has nothing like the intelligence or the precision required to exactly quine its goal system.  In coughing up the first true minds, <a href="0161.html">evolution's simple fitness criterion shattered into a thousand values</a> [http://lesswrong.com/lw/l3/thou_art_godshatter/].  You evolved with a psychology that attaches <a href="0162.html">utility</a> [http://lesswrong.com/lw/l4/terminal_values_and_instrumental_values/] to things which evolution does not care about, like human life and happiness.  And then you look back and say, 'How marvelous, that uncaring evolution produced minds that care about sentient life!'  So your great marvel and wonder, that seems like far too much coincidence, is really no coincidence at all."</p> <p>But then it is still amazing that this particular circular loop, happened to loop around such important things as beauty and altruism.</p> <p>"I don't think you're following me here.  To you, it seems natural to privilege the beauty and altruism as special, as preferred, because you value them highly; and you don't see this as a unusual fact about yourself, because many of your friends do likewise.  So you expect that a <a href="0397.html">ghost of perfect emptiness</a> [http://lesswrong.com/lw/rn/no_universally_compelling_arguments/] would also value life and happiness&#8212;and then, from this standpoint outside reality, a great coincidence would indeed have occurred."</p> <p>But you can make arguments for the importance of beauty and altruism from first principles&#8212;that our aesthetic senses lead us to create new complexity, instead of repeating the same things over and over; and that altruism is important because it takes us outside ourselves, gives our life a higher meaning than sheer brute selfishness.</p> <p>"Oh, and <em>that</em> argument is going to move even a <a href="0397.html">ghost of perfect emptiness</a> [http://lesswrong.com/lw/rn/no_universally_compelling_arguments/]&#8212;now that you've appealed to slightly different values?  Those aren't first principles, they're just <em>different</em> principles.  Even if you've adopted a high-falutin' philosophical tone, still there are no <em>universally</em> compelling arguments.  All you've done is <a href="0387.html">pass the recursive buck</a> [http://lesswrong.com/lw/rd/passing_the_recursive_buck/]."</p> <p>You don't think that, somehow, we evolved to <em>tap into</em> something beyond&#8212;</p> <p>"What good does it do to suppose something beyond?  Why should we pay more attention to that beyond thing, than we pay to our existence as humans?  How does it alter your personal responsibility, to say that you were only following the orders of the beyond thing?  And you would still have evolved to let the beyond thing, rather than something else, direct your actions.  You are only <a href="0387.html">passing the recursive buck</a> [http://lesswrong.com/lw/rd/passing_the_recursive_buck/].  Above all, it would be <em>too much coincidence.</em>"</p> <p>Too much coincidence?</p> <p>"A flower is beautiful, you say.  Do you think there is no story behind that beauty, or that science does not know the story?  Flower pollen is transmitted by bees, so by sexual selection, flowers evolved to attract bees&#8212;by imitating certain mating signs of bees, as it happened; the flowers' patterns would look more intricate, if you could see in the ultraviolet.  Now healthy flowers are a sign of fertile land, likely to bear fruits and other treasures, and probably prey animals as well; so is it any wonder that humans evolved to be attracted to flowers?  But for there to be some great light written upon the very stars&#8212;those huge unsentient balls of burning hydrogen&#8212;which <em>also</em> said that flowers were beautiful, now <em>that</em> would be far too much coincidence."</p> <p>So you <a href="0290.html">explain away</a> [http://lesswrong.com/lw/oo/explaining_vs_explaining_away/] the beauty of a flower?</p> <p>"No, I explain it.  Of course there's a story behind the beauty of flowers and the fact that we find them beautiful.  Behind ordered events, one finds ordered stories; and what has no story is the product of random noise, which is hardly any better.  <a href="0293.html">If you cannot take joy in things that have stories behind them, your life will be empty indeed.</a> [http://lesswrong.com/lw/or/joy_in_the_merely_real/]  I don't think I take any less joy in a flower than you do; more so, perhaps, because I take joy in its story as well."</p> <p>Perhaps as you say, there is no surprise from a causal viewpoint&#8212;no disruption of the physical order of the universe.  But it still seems to me that, in this creation of humans by evolution, something happened that is precious and marvelous and wonderful.  If we cannot call it a physical miracle, then call it a moral miracle.</p> <p>"Because it's only a miracle from the perspective of the morality that was produced, thus explaining away all of the apparent coincidence from a merely causal and physical perspective?"</p> <p>Well... I suppose you could interpret the term that way, yes.  I just meant something that was immensely surprising and wonderful on a moral level, even if it is not surprising on a physical level.</p> <p>"I think that's what I said."</p> <p>But it still seems to me that you, from your own view, drain something of that wonder away.</p> <p>"Then you have problems taking <a href="0293.html">joy in the merely real</a> [http://lesswrong.com/lw/or/joy_in_the_merely_real/].  Love has to begin <em>somehow,</em> it has to enter the universe <em>somewhere.</em>  It is like asking how life itself begins&#8212;and though you were born of your father and mother, and they arose from their living parents in turn, if you go far and far and far away back, you will finally come to a replicator that arose by pure accident&#8212;the border between life and unlife.  So too with love.</p> <p>"A complex pattern must be explained by a cause which is not already that complex pattern.  Not just the event must be explained, but the very shape and form.  For love to first enter Time, it must come of something that is not love; if this were not possible, then love could not be.</p> <p>"Even as life itself required that first replicator to come about by accident, parentless but still caused: far, far back in the causal chain that led to you: 3.85 billion years ago, in some little tidal pool.</p> <p>"Perhaps your children's children will ask how it is that they are capable of love.</p> <p>"And their parents will say:  Because we, who also love, created you to love.</p> <p>"And your children's children will ask:  But how is it that <em>you</em> love?</p> <p>"And their parents will reply:  Because our own parents, who also loved, created us to love in turn.</p> <p>"Then your children's children will ask:  But where did it all begin?  Where does the recursion end?</p> <p>"And their parents will say:  Once upon a time, long ago and far away, ever so long ago, there were intelligent beings who were not themselves intelligently designed.  Once upon a time, there were lovers created by something that did not love.</p> <p>"Once upon a time, when all of civilization was a single galaxy and a single star: and a single planet, a place called Earth.</p> <p>"Long ago, and far away, ever so long ago."</p> <p> </p> <p style="text-align:right">Part of <a href="http://wiki.lesswrong.com/wiki/Metaethics_sequence"><em>The Metaethics Sequence</em></a> [http://wiki.lesswrong.com/wiki/Metaethics_sequence]</p> <p style="text-align:right">Next post: "<a href="0421.html">Could Anything Be Right?</a> [http://lesswrong.com/lw/sb/could_anything_be_right/]"</p> <p style="text-align:right">Previous post: "<a href="0419.html">Whither Moral Progress?</a> [http://lesswrong.com/lw/s9/whither_moral_progress/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq14.html">Sequence 14: Metaethics</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0419.html">Whither Moral Progress?</a></p></td><td><p><i>Next: </i><a href="0421.html">Could Anything Be Right?</a></p></td></tr></table><p><i>Referenced by: </i><a href="0419.html">Whither Moral Progress?</a> &#8226; <a href="0421.html">Could Anything Be Right?</a> &#8226; <a href="0429.html">Does Your Morality Care What You Think?</a> &#8226; <a href="0430.html">Changing Your Metaethics</a> &#8226; <a href="0431.html">Setting Up Metaethics</a> &#8226; <a href="0432.html">The Meaning of Right</a> &#8226; <a href="0434.html">Humans in Funny Suits</a> &#8226; <a href="0443.html">Inseparably Right; or, Joy in the Merely Good</a> &#8226; <a href="0449.html">The Bedrock of Morality: Arbitrary?</a> &#8226; <a href="0455.html">No License To Be Human</a> &#8226; <a href="0457.html">Mirrors and Paintings</a> &#8226; <a href="0518.html">Ethical Inhibitions</a> &#8226; <a href="0618.html">Sympathetic Minds</a> &#8226; <a href="0629.html">Value is Fragile</a> &#8226; <a href="0645.html">An Especially Elegant Evpsych Experiment</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/sa/the_gift_we_give_to_tomorrow/">The Gift We Give To Tomorrow</a></p></body></html>