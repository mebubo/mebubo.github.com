<html><head><title>Affective Death Spirals</title></head><body><h1>Affective Death Spirals</h1><p><i>Eliezer Yudkowsky, 02 December 2007 04:44PM</i></p><div><p><strong>Followup to</strong>:  <a href="0174.html">The Affect Heuristic</a> [http://lesswrong.com/lw/lg/the_affect_heuristic/], <a href="0177.html">The Halo Effect</a> [http://lesswrong.com/lw/lj/the_halo_effect/]</p> <p><a href="0071.html">Many</a> [http://lesswrong.com/lw/il/hindsight_bias/], <a href="0078.html">many</a> [http://lesswrong.com/lw/is/fake_causality/], <a href="0116.html">many</a> [http://lesswrong.com/lw/ju/rationalization/] are the flaws in human reasoning which lead us to overestimate how well our beloved theory explains the facts.  The phlogiston theory of chemistry could explain just about anything, so long as it didn't have to predict it in advance.  And the more phenomena you use your favored theory to explain, the truer your favored theory seems&#8212;has it not been confirmed by these many observations?  As the theory seems truer, you will be more likely to question evidence that conflicts with it.  As the favored theory seems more general, you will seek to use it in more explanations.</p> <p>If you know anyone who believes that Belgium secretly controls the US banking system, or that they can use an invisible blue spirit force to detect available parking spaces, that's probably how they got started.</p> <p>(Just keep an eye out, and you'll observe much that seems to confirm this theory...)</p> <p>This positive feedback cycle of credulity and confirmation is indeed fearsome, and responsible for much error, both in science and in everyday life.</p> <p>But it's nothing compared to the death spiral that begins with a charge of positive affect&#8212;a thought that <em>feels really good.</em></p> <p>A new political system that can save the world.  A great leader, strong and noble and wise.  An amazing tonic that can cure upset stomachs and cancer.</p> <p>Heck, why not go for all three?  A great cause needs a great leader.  A great leader should be able to brew up a magical tonic or two.</p> <p><a id="more"></a></p> <p>The <a href="0177.html">halo effect</a> [http://lesswrong.com/lw/lj/the_halo_effect/] is that any perceived positive characteristic (such as attractiveness or strength) increases perception of any other positive characteristic (such as intelligence or courage).  Even when it makes no sense, or <a href="0178.html">less than no sense</a> [http://lesswrong.com/lw/lk/superhero_bias/].</p> <p>Positive characteristics enhance perception of every other positive characteristic?  That sounds a lot like how a fissioning uranium atom sends out neutrons that fission other uranium atoms.</p> <p>Weak positive affect is subcritical; it doesn't spiral out of control.  An attractive person seems more honest, which, perhaps, makes them seem more attractive; but the effective neutron multiplication factor is less than 1.  Metaphorically speaking.  The resonance confuses things a little, but then dies out.</p> <p>With intense positive affect attached to the Great Thingy, the resonance touches everywhere.  A believing Communist sees the wisdom of Marx in every hamburger bought at McDonalds; in every promotion they're denied that would have gone to them in a true worker's paradise; in every election that doesn't go to their taste, in every newspaper article "slanted in the wrong direction".  Every time they use the Great Idea to interpret another event, the Great Idea is confirmed all the more.  It feels better&#8212;positive reinforcement&#8212;and of course, when something feels good, that, alas, makes us <em>want </em>to believe it all the more.</p> <p>When the Great Thingy feels good enough to make you <em>seek out</em> new opportunities to feel even better about the Great Thingy, applying it to interpret new events every day, the resonance of positive affect is like <a href="http://www.youtube.com/watch?v=ORqc1x3_Evg&amp;feature=related">a chamber full of mousetraps loaded with ping-pong balls</a> [http://www.youtube.com/watch?v=ORqc1x3_Evg&amp;feature=related].</p> <p>You could call it a "happy attractor", "overly positive feedback", a "praise locked loop", or "funpaper".  Personally I prefer the term "affective death spiral".</p> <p>Coming tomorrow:  How to resist an affective death spiral.  (Hint:  It's not by refusing to ever admire anything again, nor by keeping the things you admire in safe little restricted magisteria.)</p> <p> </p> <p style="text-align:right">Part of the <a href="http://wiki.lesswrong.com/wiki/Death_Spirals_and_the_Cult_Attractor"><em>Death Spirals and the Cult Attractor</em></a> [http://wiki.lesswrong.com/wiki/Death_Spirals_and_the_Cult_Attractor] subsequence of <a href="http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind"><em>How To Actually Change Your Mind</em></a> [http://wiki.lesswrong.com/wiki/How_To_Actually_Change_Your_Mind]</p> <p style="text-align:right">Next post: "<a href="0181.html">Resist the Happy Death Spiral</a> [http://lesswrong.com/lw/ln/resist_the_happy_death_spiral/]"</p> <p style="text-align:right">Previous post: "<a href="0179.html">Mere Messiahs</a> [http://lesswrong.com/lw/ll/mere_messiahs/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq04.html">Sequence 04: Death Spirals and the Cult Attractor</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0179.html">Mere Messiahs</a></p></td><td><p><i>Next: </i><a href="0181.html">Resist the Happy Death Spiral</a></p></td></tr></table><p><i>Referenced by: </i><a href="0179.html">Mere Messiahs</a> &#8226; <a href="0181.html">Resist the Happy Death Spiral</a> &#8226; <a href="0182.html">Uncritical Supercriticality</a> &#8226; <a href="0183.html">Fake Fake Utility Functions</a> &#8226; <a href="0184.html">Fake Utility Functions</a> &#8226; <a href="0186.html">When None Dare Urge Restraint</a> &#8226; <a href="0189.html">Every Cause Wants To Be A Cult</a> &#8226; <a href="0195.html">Guardians of Ayn Rand</a> &#8226; <a href="0197.html">Politics and Awful Art</a> &#8226; <a href="0207.html">Cultish Countercultishness</a> &#8226; <a href="0221.html">Expecting Beauty</a> &#8226; <a href="0349.html">Science Doesn't Trust Your Rationality</a> &#8226; <a href="0352.html">Do Scientists Already Know This Stuff?</a> &#8226; <a href="0366.html">Einstein's Superpowers</a> &#8226; <a href="0368.html">A Premature Word on AI</a> &#8226; <a href="0391.html">Heading Toward Morality</a> &#8226; <a href="0401.html">The Moral Void</a> &#8226; <a href="0430.html">Changing Your Metaethics</a> &#8226; <a href="0480.html">My Childhood Death Spiral</a> &#8226; <a href="0483.html">A Prodigy of Refutation</a> &#8226; <a href="0509.html">Crisis of Faith</a> &#8226; <a href="0552.html">Failure By Affective Analogy</a> &#8226; <a href="0602.html">The Uses of Fun (Theory)</a> &#8226; <a href="0615.html">Seduced by Imagination</a> &#8226; <a href="0616.html">Getting Nearer</a> &#8226; <a href="0674.html">Raising the Sanity Waterline</a> &#8226; <a href="0682.html">Why Our Kind Can't Cooperate</a> &#8226; <a href="0690.html">Can Humanism Match Religion's Output?</a> &#8226; <a href="0708.html">That Crisis thing seems pretty useful</a> &#8226; <a href="0714.html">Bayesians vs. Barbarians</a> &#8226; <a href="0722.html">Go Forth and Create the Art!</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/lm/affective_death_spirals/">Affective Death Spirals</a></p></body></html>