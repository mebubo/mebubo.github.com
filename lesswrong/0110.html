<html><head><title>Einstein's Arrogance</title></head><body><h1>Einstein's Arrogance</h1><p><i>Eliezer Yudkowsky, 25 September 2007 01:29AM</i></p><div><p><strong>Prerequisite:</strong>  <a href="0109.html">How Much Evidence Does It Take?</a> [http://lesswrong.com/lw/jn/how_much_evidence_does_it_take/]</p> <p>In 1919, Sir Arthur Eddington led expeditions to Brazil and to the island of Principe, aiming to observe solar eclipses and thereby test an experimental prediction of Einstein's novel theory of General Relativity.  A journalist asked Einstein what he would do if Eddington's observations failed to match his theory.  Einstein famously replied:  "Then I would feel sorry for the good Lord.  The theory is correct." </p> <p>It seems like a rather foolhardy statement, defying the trope of Traditional Rationality that experiment above all is sovereign.  Einstein seems possessed of an arrogance so great that he would refuse to bend his neck and submit to Nature's answer, as scientists must do.  Who can <em>know</em> that the theory is correct, in advance of experimental test? </p> <p>Of course, Einstein did turn out to be right.  I try to avoid criticizing people when they are right.  If they genuinely deserve criticism, I will not need to wait long for an occasion where they are wrong.<br> </p> <p>And Einstein may not have been quite so foolhardy as he sounded...</p> <a id="more"></a><p>To assign more than 50% probability to the correct candidate from a pool of 100,000,000 possible hypotheses, you need at least <a href="0109.html">27 bits of evidence</a> [http://lesswrong.com/lw/jn/how_much_evidence_does_it_take/] (or thereabouts).  You cannot expect to find the correct candidate without tests that are this strong, because lesser tests will yield more than one candidate that passes all the tests.  If you try to apply a test that only has a million-to-one chance of a false positive (~20 bits), you'll end up with a hundred candidates.  Just <em>finding</em> the right answer, within a large space of possibilities, requires a large amount of evidence.</p> <p>Traditional Rationality emphasizes justification:  "If you want to convince me of X, you've got to present me with Y amount of evidence."  I myself often slip into this phrasing, whenever I say something like, "To <em>justify</em> believing in this proposition, at more than 99% probability, requires 34 bits of evidence."  Or, "in order to assign more than 50% probability to your hypothesis, you need 27 bits of evidence."  The Traditional phrasing implies that you start out with a hunch, or some private line of reasoning that leads you to a suggested hypothesis, and then you have to gather "evidence" to <em>confirm </em>it - to convince the scientific community, or justify saying that you <em>believe </em>in your hunch.</p> <p>But from a Bayesian perspective, you need an <a href="0109.html">amount of evidence</a> [http://lesswrong.com/lw/jn/how_much_evidence_does_it_take/] roughly equivalent to the <a href="0111.html">complexity of the hypothesis</a> [http://lesswrong.com/lw/jp/occams_razor/] just to locate the hypothesis in theory-space.  It's not a question of justifying anything to anyone.  If there's a hundred million alternatives, you need at least 27 bits of evidence just to focus your attention uniquely on the correct answer.</p> <p>This is true even if you call your guess a "hunch" or "intuition".  Hunchings and intuitings are real processes in a real brain.  If your brain doesn't have at least 10 bits of genuinely entangled valid Bayesian evidence to chew on, your brain cannot single out a correct 10-bit hypothesis for your attention - consciously, subconsciously, whatever.  Subconscious processes can't find one out of a million targets using only 19 bits of entanglement any more than conscious processes can.  Hunches can be mysterious to the huncher, but they can't violate the laws of physics.</p> <p>You see where this is going:  <em>At the time of first formulating the hypothesis -</em> the very first time the equations popped into his head - Einstein must have had, <em>already in his possession,</em> sufficient observational evidence to single out the complex equations of General Relativity for his unique attention.  Or he couldn't have gotten them <em>right.</em></p> <p>Now, how likely is it that Einstein would have <em>exactly </em>enough observational evidence to raise General Relativity to the level of his attention, but only justify assigning it a 55% probability?  Suppose General Relativity is a 29.3-bit hypothesis.  How likely is it that Einstein would stumble across <em>exactly</em> 29.5 bits of evidence in the course of his physics reading?</p> <p>Not likely!  If Einstein had enough observational evidence to single out the correct equations of General Relativity in the first place, then he probably had enough evidence to be <em>damn sure</em> that General Relativity was true.</p> <p>In fact, since the human brain is not a perfectly efficient processor of information, Einstein probably had <em>overwhelmingly more evidence</em> than would, in principle, be required for a perfect Bayesian to assign massive confidence to General Relativity.<br> </p> <p>"Then I would feel sorry for the good Lord; the theory is correct," doesn't sound nearly as appalling when you look at it from that perspective.  And remember that General Relativity <em>was</em> correct, from all the vast space of possibilities.</p></div> <hr><p><i>Referenced by: </i><a href="0111.html">Occam's Razor</a> &#8226; <a href="0131.html">The Logical Fallacy of Generalization from Fictional Evidence</a> &#8226; <a href="0149.html">An Alien God</a> &#8226; <a href="0154.html">The Tragedy of Group Selectionism</a> &#8226; <a href="0164.html">No Evolutions for Corporations or Nanodevices</a> &#8226; <a href="0167.html">Artificial Addition</a> &#8226; <a href="0269.html">Superexponential Conceptspace, and Simple Words</a> &#8226; <a href="0312.html">GAZP vs. GLUT</a> &#8226; <a href="0346.html">Many Worlds, One Best Guess</a> &#8226; <a href="0356.html">Faster Than Science</a> &#8226; <a href="0357.html">Einstein's Speed</a> &#8226; <a href="0413.html">The Genetic Fallacy</a> &#8226; <a href="0440.html">Contaminated by Optimism</a> &#8226; <a href="0534.html">Building Something Smarter</a> &#8226; <a href="0750.html">Dreams with Damaged Priors</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/jo/einsteins_arrogance/">Einstein's Arrogance</a></p></body></html>