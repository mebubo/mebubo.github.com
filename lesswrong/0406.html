<html><head><title>Moral Complexities</title></head><body><h1>Moral Complexities</h1><p><i>Eliezer Yudkowsky, 04 July 2008 06:43AM</i></p><div><p><strong>Followup to</strong>:  <a href="0404.html">The Bedrock of Fairness</a> [http://lesswrong.com/lw/ru/the_bedrock_of_fairness/]</p> <p>Discussions of morality seem to me to often end up turning around two different intuitions, which I might label morality-as-preference and morality-as-given.  The former crowd tends to equate morality with what people want; the latter to regard morality as something you can't change by changing people.</p> <p>As for me, I have my own notions, which I am working up to presenting.  But above all, I try to avoid avoiding difficult questions.  Here are what I see as (some of) the difficult questions for the two intuitions:</p> <ul> <li>For morality-as-preference:    <ul> <li>Why do people seem to mean different things by "I want the pie" and "It is right that I should get the pie"?  Why are the two propositions argued in different ways?   </li> <li>When and why do people change their <a href="0162.html">terminal values</a> [http://lesswrong.com/lw/l4/terminal_values_and_instrumental_values/]?  Do the concepts of "moral error" and "moral progress" have referents?  Why would anyone want to change what they want?   </li> <li>Why and how does anyone ever "do something they know they shouldn't", or "want something they know is wrong"?  Does the notion of morality-as-preference really add up to moral normality?</li> </ul> </li> <li>For morality-as-given:    <ul> <li>Would it be possible for everyone in the world to be wrong about morality, <em>and</em> wrong about how to update their beliefs about morality, <em>and</em> wrong about how to choose between metamoralities, etcetera?  So that there would be a morality, but it would be entirely outside our frame of reference?  What distinguishes this state of affairs, from finding a random stone tablet showing the words "You should commit suicide"?   </li> <li>How does a world in which a moral proposition is true, differ from a world in which that moral proposition is false?  If the answer is "no", how does anyone <a href="0124.html">perceive</a> [http://lesswrong.com/lw/k2/a_priori/] moral givens?   </li> <li>Is it better for people to be happy than sad?  If so, why does morality look amazingly like <a href="0161.html">godshatter of natural selection</a> [http://lesswrong.com/lw/l3/thou_art_godshatter/]?   </li> <li>Am I not allowed to construct an alien mind that evaluates morality <a href="0397.html">differently</a> [http://lesswrong.com/lw/rn/no_universally_compelling_arguments/]?  What will stop me from doing so?</li> </ul> </li> </ul> <p> </p> <p style="text-align:right">Part of <a href="http://wiki.lesswrong.com/wiki/Metaethics_sequence"><em>The Metaethics Sequence</em></a> [http://wiki.lesswrong.com/wiki/Metaethics_sequence]</p> <p style="text-align:right">Next post: "<a href="0407.html">Is Morality Preference?</a> [http://lesswrong.com/lw/rx/is_morality_preference/]"</p> <p style="text-align:right">Previous post: "<a href="0404.html">The Bedrock of Fairness</a> [http://lesswrong.com/lw/ru/the_bedrock_of_fairness/]"</p></div> <hr><table><tr><th colspan="2"><a href="seq14.html">Sequence 14: Metaethics</a>:</th></tr><tr><td><p><i>Previous: </i><a href="0404.html">The Bedrock of Fairness</a></p></td><td><p><i>Next: </i><a href="0407.html">Is Morality Preference?</a></p></td></tr></table><p><i>Referenced by: </i><a href="0404.html">The Bedrock of Fairness</a> &#8226; <a href="0407.html">Is Morality Preference?</a> &#8226; <a href="0431.html">Setting Up Metaethics</a></p><p><i>Original with comments: </i><a href="http://lesswrong.com/lw/rw/moral_complexities/">Moral Complexities</a></p></body></html>